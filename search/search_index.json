{
    "docs": [
        {
            "location": "/", 
            "text": "TensorFlow 1.0 \u5b98\u65b9\u6587\u6863\u4e2d\u6587\u7ffb\u8bd1\n\n\n\u9996\u5148\u7533\u660e\uff0c\u672c\u6587\u6863\u5e76\u975e\u5b98\u65b9\u6587\u6863\uff0c\u4ec5\u4e3a\u4e2a\u4eba\u5174\u8da3\u800c\u5efa\u7acb\u7684\u3002\u5982\u9700\u67e5\u8be2TensorFlow\u5b98\u65b9\u6587\u6863\uff0c\u8bf7\u81f3https://www.tensorflow.org/\uff0c\u6216\u8005\u5230TensorFlow\u4e2d\u6587\u793e\u533a\uff08http://www.tensorfly.cn/\uff09\u67e5\u8be2\u5b8c\u6574\u7684\u4e2d\u6587\u6587\u6863\u3002\n\n\n\u672c\u6587\u6863\u57fa\u4e8e\nTensorFlow\u5b98\u65b9\u6587\u6863\n \n1.0 \u7248\u672c\n\u8fdb\u884c\u7ffb\u8bd1\uff0c\u5c3d\u91cf\u4e0e\u5b98\u65b9\u7f51\u7ad9\u7684\u6587\u6863\u76ee\u5f55\u4fdd\u6301\u4e00\u81f4\u3002\n\n\n\u6587\u6863\u7ffb\u8bd1\u8fc7\u7a0b\u4e2d\u514b\u9686\u4e86\n\u5b98\u65b9\u6587\u6863\u5e93\n\uff08\u5c3d\u91cf\u4fdd\u6301\u8ddf\u968f\u6700\u65b0\u66f4\u65b0\uff09\uff0c\u540c\u65f6\u4e25\u91cd\u53c2\u8003\u4e86\nTensorFlow\u4e2d\u6587\u793e\u533a\n\u7684\u6587\u6863\uff08\u8be5\u793e\u533a\u7684\u6587\u6863\u4ecd\u4e3a0.5\u7248\uff0c\u8fd9\u4e5f\u662f\u4fc3\u4f7f\u672c\u6587\u6863\u9879\u76ee\u7684\u4e00\u4e2a\u539f\u56e0\uff09\u3002\n\n\n\u672c\u6587\u6863\u4f7f\u7528\nMkDocs\u6587\u6863\u7cfb\u7edf\n\u6784\u5efa\uff0c\u754c\u9762\u4e3b\u9898\u4e3a\nRead the Docs\n\u3002\n\n\n\u672c\u6587\u6863\u9879\u76ee\u6e90\u4ee3\u7801\u90e8\u7f72\u5728\nGithub\n\u4e0a\uff0c\u5982\u6709\u5174\u8da3\u53c2\u4e0e\u8005\u8bf7\u5173\u6ce8\u6211\u7684Github Repo\uff1a\nhttps://github.com/isaron/tfdocs\n\u3002\n\n\n\u6587\u6863\u76ee\u5f55\n\n\n\u5c3d\u91cf\u4e0e\u5b98\u65b9\u7f51\u7ad9\u7684\u6587\u6863\u76ee\u5f55\u4fdd\u6301\u4e00\u81f4\uff0c\u5df2\u7ffb\u8bd1\u5b8c\u6210\u7684\u7ae0\u8282\u4f1a\u53ca\u65f6\u66f4\u65b0\u94fe\u63a5\n\n\n1. \u5b89\u88c5\n\n\n\n\n\u5b89\u88c5\u7efc\u8ff0\n\n\n\u5728Ubuntu\u4e0a\u5b89\u88c5TensorFlow\n\n\n\u5728Mac OS X\u4e0a\u5b89\u88c5TensorFlow\n\n\n\u5728Windows\u4e0a\u5b89\u88c5TensorFlow\n\n\n\u6e90\u4ee3\u7801\u5b89\u88c5TensorFlow\n\n\n\u8fc1\u79fb\u5230TensorFlow 1.0\n\n\n\u5b89\u88c5TensorFlow for Java\n\n\n\u5b89\u88c5TensorFlow for C\n\n\n\u5b89\u88c5TensorFlow for Go\n\n\n\n\n2. \u5f00\u53d1\n\n\n2.1 \u65b0\u624b\u5165\u95e8\n\n\n\n\nTensorFlow\u5feb\u901f\u5165\u95e8\n\n\nMNIST\u5165\u95e8\n\n\nMNIST\u8fdb\u9636\n\n\nTensorFlow \u8fd0\u4f5c\u65b9\u5f0f 101\n\n\ntf.contrib.learn: \u5feb\u901f\u5f00\u59cb\n\n\ntf.contrib.learn: \u521b\u5efa\u8f93\u5165\u51fd\u6570\n\n\nTensorBoard: \u53ef\u89c6\u5316\u5b66\u4e60\n\n\nTensorBoard: \u5185\u5d4c\u53ef\u89c6\u5316\n\n\nTensorBoard: \u56fe\u8868\u53ef\u89c6\u5316\n\n\ntf.contrib.learn: \u65e5\u5fd7\u548c\u76d1\u63a7\u57fa\u7840\n\n\nTensorFlow\u7248\u672c\n\n\n\n\n2.2 \u7a0b\u5e8f\u5458\u624b\u518c\n\n\n\n\n\u8bfb\u53d6\u6570\u636e\n\n\n\u7ebf\u7a0b\u548c\u961f\u5217\n\n\n\u5171\u4eab\u53c2\u6570\n\n\nTensorFlow\u7684\u7248\u672c\u8bed\u4e49\n\n\nTensorFlow\u6570\u636e\u7248\u672c\u5316: GraphDefs and Checkpoints\n\n\nSupervisor: Training Helper for Days-Long Trainings.\n\n\nTensorFlow Debugger (tfdbg) \u547d\u4ee4\u884c\u6307\u5357: MNIST\n\n\nTensorFlow Debugger (tfdbg) \u4e0e tf.contrib.learn \u7ed3\u5408\u4f7f\u7528\n\n\n\u5bfc\u5165\u5bfc\u51faMetaGraph\n\n\n\u5e38\u89c1\u95ee\u9898\n\n\nTensor \u6392\u540d\u3001\u5f62\u72b6\u548c\u7c7b\u578b\n\n\n\u53d8\u91cf\uff1a\u521b\u5efa\u3001\u521d\u59cb\u5316\u3001\u4fdd\u5b58\u548c\u52a0\u8f7d\n\n\n\n\n2.3 \u6559\u7a0b\n\n\n\n\n\u66fc\u5fb7\u5e03\u6d1b\u7279(Mandelbrot)\u96c6\u5408\n\n\n\u504f\u5fae\u5206\u65b9\u7a0b(PDEs)\n\n\n\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\n\n\n\u56fe\u50cf\u8bc6\u522b\n\n\n\u5982\u4f55\u8bad\u7ec3 Inception\u2019s Final Layer for New Categories\n\n\n\u5b57\u8bcd\u7684\u5411\u91cf\u8868\u793a\n\n\n\u9012\u5f52\u795e\u7ecf\u7f51\u7edc\n\n\nSequence-to-Sequence \u6a21\u578b\n\n\nTF Layers \u6307\u5357: \u521b\u5efa\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\n\n\n\u5927\u89c4\u6a21\u7ebf\u6027\u6a21\u578b\u4e0e TensorFlow\n\n\nTensorFlow \u7ebf\u6027\u6a21\u578b\u6307\u5bfc\n\n\nTensorFlow \u5e7f\u5ea6\u4e0e\u6df1\u5ea6\u5b66\u4e60\u6307\u5bfc\n\n\n\u4f7f\u7528 GPU\n\n\n\n\n2.4 \u6027\u80fd\u4f18\u5316\n\n\n\n\n\u603b\u89c8\n\n\nXLA \u6982\u89c8\n\n\n\u5e7f\u64ad\u8bed\u4e49\n\n\n\u5f00\u53d1\u65b0\u7684 XLA \u540e\u7aef\n\n\n\u4f7f\u7528 JIT \u7f16\u8bd1\n\n\n\u8fd0\u7b97\u8bed\u4e49\n\n\nShapes and Layout\n\n\n\u4f7f\u7528 AOT \u7f16\u8bd1\n\n\n\u5982\u4f55\u91cf\u5316\u795e\u7ecf\u7f51\u7edc\n\n\n\n\n3. API r1.0\n\n\n\n\n\u6982\u89c8 r1.0\n\n\nPython API r1.0\n\n\nC++ API r1.0\n\n\nJava API r1.0\n\n\nGo API\n\n\n\n\n4. \u90e8\u7f72\n\n\n\n\n\u5728 Hadoop \u4e0a\u8fd0\u884c TensorFlow\n\n\n\u5206\u5e03\u5f0f\u90e8\u7f72 TensorFlow\n\n\nTensorFlow \u670d\u52a1\n\n\n\n\n5. \u6269\u5c55\n\n\n\n\nTensorFlow \u67b6\u6784\n\n\n\u6dfb\u52a0\u65b0\u7684 Op\n\n\n\u6dfb\u52a0\u81ea\u5b9a\u4e49\u6587\u4ef6\u7cfb\u7edf\u63d2\u4ef6\n\n\nTensorFlow \u7ffb\u8bd1\n\n\n\u81ea\u5b9a\u4e49\u6570\u636e\u8bfb\u53d6\n\n\n\u7528 tf.contrib.learn \u5efa\u7acb\u4f30\u91cf\n\n\nTensorFlow \u6a21\u578b\u6587\u4ef6\u7684\u5de5\u5177\u5f00\u53d1\u8005\u6307\u5357\n\n\n\n\n6. \u8d44\u6e90\n\n\n6.1 \u793e\u533a\n\n\n\n\n\u7f16\u5199 TensorFlow \u6587\u6863\n\n\nTensorFlow \u98ce\u683c\u6307\u5357\n\n\n\n\n6.2 \u5173\u4e8e\n\n\n\n\n\u66f4\u591aTF\u76f8\u5173\u8d44\u6e90\n\n\nTensorFlow \u767d\u76ae\u4e66\n\n\nTensorFlow Uses\n\n\n\n\n7. TensorFlow\u7248\u672c\n\n\n\n\nTensorFlow \u7248\u672c\u5217\u8868\n\n\nmaster\n\n\nr1.0\n\n\nr0.12\n\n\nr0.11\n\n\nr0.10\n\n\n\n\n\u5185\u5bb9\u6765\u6e90\n\n\n\u82f1\u6587\u5b98\u65b9\u7f51\u7ad9\uff1a\n    https://www.tensorflow.org/\n\n\nTensorFlow\u4e2d\u6587\u793e\u533a:\n    http://www.tensorfly.cn\n\n\n\u6781\u5ba2\u5b66\u9662TensorFlow\u6587\u6863\u4e2d\u6587\u7248\u7ffb\u8bd1\u8ba1\u5212\uff1a\n    https://github.com/jikexueyuanwiki/tensorflow-zh", 
            "title": "0. \u9996\u9875"
        }, 
        {
            "location": "/#tensorflow-10", 
            "text": "\u9996\u5148\u7533\u660e\uff0c\u672c\u6587\u6863\u5e76\u975e\u5b98\u65b9\u6587\u6863\uff0c\u4ec5\u4e3a\u4e2a\u4eba\u5174\u8da3\u800c\u5efa\u7acb\u7684\u3002\u5982\u9700\u67e5\u8be2TensorFlow\u5b98\u65b9\u6587\u6863\uff0c\u8bf7\u81f3https://www.tensorflow.org/\uff0c\u6216\u8005\u5230TensorFlow\u4e2d\u6587\u793e\u533a\uff08http://www.tensorfly.cn/\uff09\u67e5\u8be2\u5b8c\u6574\u7684\u4e2d\u6587\u6587\u6863\u3002  \u672c\u6587\u6863\u57fa\u4e8e TensorFlow\u5b98\u65b9\u6587\u6863   1.0 \u7248\u672c \u8fdb\u884c\u7ffb\u8bd1\uff0c\u5c3d\u91cf\u4e0e\u5b98\u65b9\u7f51\u7ad9\u7684\u6587\u6863\u76ee\u5f55\u4fdd\u6301\u4e00\u81f4\u3002  \u6587\u6863\u7ffb\u8bd1\u8fc7\u7a0b\u4e2d\u514b\u9686\u4e86 \u5b98\u65b9\u6587\u6863\u5e93 \uff08\u5c3d\u91cf\u4fdd\u6301\u8ddf\u968f\u6700\u65b0\u66f4\u65b0\uff09\uff0c\u540c\u65f6\u4e25\u91cd\u53c2\u8003\u4e86 TensorFlow\u4e2d\u6587\u793e\u533a \u7684\u6587\u6863\uff08\u8be5\u793e\u533a\u7684\u6587\u6863\u4ecd\u4e3a0.5\u7248\uff0c\u8fd9\u4e5f\u662f\u4fc3\u4f7f\u672c\u6587\u6863\u9879\u76ee\u7684\u4e00\u4e2a\u539f\u56e0\uff09\u3002  \u672c\u6587\u6863\u4f7f\u7528 MkDocs\u6587\u6863\u7cfb\u7edf \u6784\u5efa\uff0c\u754c\u9762\u4e3b\u9898\u4e3a Read the Docs \u3002  \u672c\u6587\u6863\u9879\u76ee\u6e90\u4ee3\u7801\u90e8\u7f72\u5728 Github \u4e0a\uff0c\u5982\u6709\u5174\u8da3\u53c2\u4e0e\u8005\u8bf7\u5173\u6ce8\u6211\u7684Github Repo\uff1a https://github.com/isaron/tfdocs \u3002", 
            "title": "TensorFlow 1.0 \u5b98\u65b9\u6587\u6863\u4e2d\u6587\u7ffb\u8bd1"
        }, 
        {
            "location": "/#_1", 
            "text": "\u5c3d\u91cf\u4e0e\u5b98\u65b9\u7f51\u7ad9\u7684\u6587\u6863\u76ee\u5f55\u4fdd\u6301\u4e00\u81f4\uff0c\u5df2\u7ffb\u8bd1\u5b8c\u6210\u7684\u7ae0\u8282\u4f1a\u53ca\u65f6\u66f4\u65b0\u94fe\u63a5", 
            "title": "\u6587\u6863\u76ee\u5f55"
        }, 
        {
            "location": "/#1", 
            "text": "\u5b89\u88c5\u7efc\u8ff0  \u5728Ubuntu\u4e0a\u5b89\u88c5TensorFlow  \u5728Mac OS X\u4e0a\u5b89\u88c5TensorFlow  \u5728Windows\u4e0a\u5b89\u88c5TensorFlow  \u6e90\u4ee3\u7801\u5b89\u88c5TensorFlow  \u8fc1\u79fb\u5230TensorFlow 1.0  \u5b89\u88c5TensorFlow for Java  \u5b89\u88c5TensorFlow for C  \u5b89\u88c5TensorFlow for Go", 
            "title": "1. \u5b89\u88c5"
        }, 
        {
            "location": "/#2", 
            "text": "", 
            "title": "2. \u5f00\u53d1"
        }, 
        {
            "location": "/#21", 
            "text": "TensorFlow\u5feb\u901f\u5165\u95e8  MNIST\u5165\u95e8  MNIST\u8fdb\u9636  TensorFlow \u8fd0\u4f5c\u65b9\u5f0f 101  tf.contrib.learn: \u5feb\u901f\u5f00\u59cb  tf.contrib.learn: \u521b\u5efa\u8f93\u5165\u51fd\u6570  TensorBoard: \u53ef\u89c6\u5316\u5b66\u4e60  TensorBoard: \u5185\u5d4c\u53ef\u89c6\u5316  TensorBoard: \u56fe\u8868\u53ef\u89c6\u5316  tf.contrib.learn: \u65e5\u5fd7\u548c\u76d1\u63a7\u57fa\u7840  TensorFlow\u7248\u672c", 
            "title": "2.1 \u65b0\u624b\u5165\u95e8"
        }, 
        {
            "location": "/#22", 
            "text": "\u8bfb\u53d6\u6570\u636e  \u7ebf\u7a0b\u548c\u961f\u5217  \u5171\u4eab\u53c2\u6570  TensorFlow\u7684\u7248\u672c\u8bed\u4e49  TensorFlow\u6570\u636e\u7248\u672c\u5316: GraphDefs and Checkpoints  Supervisor: Training Helper for Days-Long Trainings.  TensorFlow Debugger (tfdbg) \u547d\u4ee4\u884c\u6307\u5357: MNIST  TensorFlow Debugger (tfdbg) \u4e0e tf.contrib.learn \u7ed3\u5408\u4f7f\u7528  \u5bfc\u5165\u5bfc\u51faMetaGraph  \u5e38\u89c1\u95ee\u9898  Tensor \u6392\u540d\u3001\u5f62\u72b6\u548c\u7c7b\u578b  \u53d8\u91cf\uff1a\u521b\u5efa\u3001\u521d\u59cb\u5316\u3001\u4fdd\u5b58\u548c\u52a0\u8f7d", 
            "title": "2.2 \u7a0b\u5e8f\u5458\u624b\u518c"
        }, 
        {
            "location": "/#23", 
            "text": "\u66fc\u5fb7\u5e03\u6d1b\u7279(Mandelbrot)\u96c6\u5408  \u504f\u5fae\u5206\u65b9\u7a0b(PDEs)  \u5377\u79ef\u795e\u7ecf\u7f51\u7edc  \u56fe\u50cf\u8bc6\u522b  \u5982\u4f55\u8bad\u7ec3 Inception\u2019s Final Layer for New Categories  \u5b57\u8bcd\u7684\u5411\u91cf\u8868\u793a  \u9012\u5f52\u795e\u7ecf\u7f51\u7edc  Sequence-to-Sequence \u6a21\u578b  TF Layers \u6307\u5357: \u521b\u5efa\u5377\u79ef\u795e\u7ecf\u7f51\u7edc  \u5927\u89c4\u6a21\u7ebf\u6027\u6a21\u578b\u4e0e TensorFlow  TensorFlow \u7ebf\u6027\u6a21\u578b\u6307\u5bfc  TensorFlow \u5e7f\u5ea6\u4e0e\u6df1\u5ea6\u5b66\u4e60\u6307\u5bfc  \u4f7f\u7528 GPU", 
            "title": "2.3 \u6559\u7a0b"
        }, 
        {
            "location": "/#24", 
            "text": "\u603b\u89c8  XLA \u6982\u89c8  \u5e7f\u64ad\u8bed\u4e49  \u5f00\u53d1\u65b0\u7684 XLA \u540e\u7aef  \u4f7f\u7528 JIT \u7f16\u8bd1  \u8fd0\u7b97\u8bed\u4e49  Shapes and Layout  \u4f7f\u7528 AOT \u7f16\u8bd1  \u5982\u4f55\u91cf\u5316\u795e\u7ecf\u7f51\u7edc", 
            "title": "2.4 \u6027\u80fd\u4f18\u5316"
        }, 
        {
            "location": "/#3-api-r10", 
            "text": "\u6982\u89c8 r1.0  Python API r1.0  C++ API r1.0  Java API r1.0  Go API", 
            "title": "3. API r1.0"
        }, 
        {
            "location": "/#4", 
            "text": "\u5728 Hadoop \u4e0a\u8fd0\u884c TensorFlow  \u5206\u5e03\u5f0f\u90e8\u7f72 TensorFlow  TensorFlow \u670d\u52a1", 
            "title": "4. \u90e8\u7f72"
        }, 
        {
            "location": "/#5", 
            "text": "TensorFlow \u67b6\u6784  \u6dfb\u52a0\u65b0\u7684 Op  \u6dfb\u52a0\u81ea\u5b9a\u4e49\u6587\u4ef6\u7cfb\u7edf\u63d2\u4ef6  TensorFlow \u7ffb\u8bd1  \u81ea\u5b9a\u4e49\u6570\u636e\u8bfb\u53d6  \u7528 tf.contrib.learn \u5efa\u7acb\u4f30\u91cf  TensorFlow \u6a21\u578b\u6587\u4ef6\u7684\u5de5\u5177\u5f00\u53d1\u8005\u6307\u5357", 
            "title": "5. \u6269\u5c55"
        }, 
        {
            "location": "/#6", 
            "text": "", 
            "title": "6. \u8d44\u6e90"
        }, 
        {
            "location": "/#61", 
            "text": "\u7f16\u5199 TensorFlow \u6587\u6863  TensorFlow \u98ce\u683c\u6307\u5357", 
            "title": "6.1 \u793e\u533a"
        }, 
        {
            "location": "/#62", 
            "text": "\u66f4\u591aTF\u76f8\u5173\u8d44\u6e90  TensorFlow \u767d\u76ae\u4e66  TensorFlow Uses", 
            "title": "6.2 \u5173\u4e8e"
        }, 
        {
            "location": "/#7-tensorflow", 
            "text": "TensorFlow \u7248\u672c\u5217\u8868  master  r1.0  r0.12  r0.11  r0.10", 
            "title": "7. TensorFlow\u7248\u672c"
        }, 
        {
            "location": "/#_2", 
            "text": "\u82f1\u6587\u5b98\u65b9\u7f51\u7ad9\uff1a\n    https://www.tensorflow.org/  TensorFlow\u4e2d\u6587\u793e\u533a:\n    http://www.tensorfly.cn  \u6781\u5ba2\u5b66\u9662TensorFlow\u6587\u6863\u4e2d\u6587\u7248\u7ffb\u8bd1\u8ba1\u5212\uff1a\n    https://github.com/jikexueyuanwiki/tensorflow-zh", 
            "title": "\u5185\u5bb9\u6765\u6e90"
        }, 
        {
            "location": "/install/", 
            "text": "\u5b89\u88c5 TensorFlow\n\n\n\u6211\u4eec\u5df2\u7ecf\u5728\u4ee5\u4e0b64\u4f4d\u64cd\u4f5c\u7cfb\u7edf\u7684\u7b14\u8bb0\u672c/\u53f0\u5f0f\u673a\u4e0a\u6784\u5efa\u5e76\u6d4b\u8bd5\u4e86TensorFlow\uff1a\n\n\n\n\nMacOS X 10.11(El Capitan)\u6216\u66f4\u9ad8\u7248\u672c\n\n\nUbuntu 14.04\u6216\u66f4\u9ad8\u7248\u672c\n\n\nWindows 7\u6216\u66f4\u9ad8\u7248\u672c\n\n\n\n\n\u867d\u7136\u4f60\u53ef\u4ee5\u5728\u5176\u4ed6\u7cfb\u7edf\u4e0a\u5b89\u88c5TensorFlow\uff0c\u4f46\u76ee\u524d\u6211\u4eec\u53ea\u652f\u6301\u4e0a\u8ff0\u7cfb\u7edf\u914d\u7f6e\uff0c\u5e76\u4e14\u4e5f\u53ea\u89e3\u51b3\u5728\u4e0a\u8ff0\u7cfb\u7edf\u4e0a\u51fa\u73b0\u7684\u95ee\u9898\u3002\n\n\n\u8fd9\u4e00\u7ae0\u8be6\u7ec6\u8bb2\u89e3\u4e86\u5982\u4f55\u5b89\u88c5\u4e00\u4e2a\u53ef\u5feb\u901f\u5f00\u59cb\u7f16\u5199 Python \u5e94\u7528\u7a0b\u5e8f\u7684 TensorFlow \u7248\u672c\uff1a\n\n\n\n\n\u5728 Ubuntu \u4e0a\u5b89\u88c5 TensorFlow\n\n\n\u5728 Mac OS X \u4e0a\u5b89\u88c5 TensorFlow\n\n\n\u5728 Windows \u4e0a\u5b89\u88c5 TensorFlow\n\n\n\u4ece\u6e90\u4ee3\u7801\u5b89\u88c5 TensorFlow\n\n\n\n\n\u4ece 0.n \u7248\u5230 1.0 \u7248\uff0cPython \u8bed\u8a00\u7684 TensorFlow API \u53d1\u751f\u4e86\u5f88\u5927\u7684\u6539\u53d8\u3002\u4e0b\u9762\u7684\u624b\u518c\u8bb2\u89e3\u4e86\u5982\u4f55\u4ece\u65e7\u7248\u672c\u7684 TensorFlow \u5e94\u7528\u7a0b\u5e8f\u8fc1\u79fb\u5230 1.0 \u7248\u672c\uff1a\n\n\n\n\n\u8fc1\u79fb\u5230 TensorFlow 1.0\n\n\n\n\n\u8fd9\u4e00\u7ae0\u540c\u65f6\u8fd8\u8bb2\u89e3\u4e86\u5982\u4f55\u5b89\u88c5\u5176\u5b83\u7f16\u7a0b\u8bed\u8a00\u7684 TensorFlow \u5e93\u6587\u4ef6\u3002\u8fd9\u4e9b API \u5e93\u5217\u4e4b\u6240\u4ee5\u5728\u8fd9\u91cc\uff0c\u4e3b\u8981\u76ee\u7684\u662f\u5728\u4e0d\u540c\u8bed\u8a00\u7f16\u5199\u7684\u5e94\u7528\u7a0b\u5e8f\u4e2d\u90e8\u7f72 TensorFlow \u6a21\u578b\uff0c\u6240\u4ee5\u5e76\u4e0d\u5982 Python API \u7684\u5168\u9762\u3002\n\n\n\n\n\u5b89\u88c5 TensorFlow for Java\n\n\n\u5b89\u88c5 TensorFlow for C\n\n\n\u5b89\u88c5 TensorFlow for Go", 
            "title": "1.1 \u7efc\u8ff0"
        }, 
        {
            "location": "/install/#tensorflow", 
            "text": "\u6211\u4eec\u5df2\u7ecf\u5728\u4ee5\u4e0b64\u4f4d\u64cd\u4f5c\u7cfb\u7edf\u7684\u7b14\u8bb0\u672c/\u53f0\u5f0f\u673a\u4e0a\u6784\u5efa\u5e76\u6d4b\u8bd5\u4e86TensorFlow\uff1a   MacOS X 10.11(El Capitan)\u6216\u66f4\u9ad8\u7248\u672c  Ubuntu 14.04\u6216\u66f4\u9ad8\u7248\u672c  Windows 7\u6216\u66f4\u9ad8\u7248\u672c   \u867d\u7136\u4f60\u53ef\u4ee5\u5728\u5176\u4ed6\u7cfb\u7edf\u4e0a\u5b89\u88c5TensorFlow\uff0c\u4f46\u76ee\u524d\u6211\u4eec\u53ea\u652f\u6301\u4e0a\u8ff0\u7cfb\u7edf\u914d\u7f6e\uff0c\u5e76\u4e14\u4e5f\u53ea\u89e3\u51b3\u5728\u4e0a\u8ff0\u7cfb\u7edf\u4e0a\u51fa\u73b0\u7684\u95ee\u9898\u3002  \u8fd9\u4e00\u7ae0\u8be6\u7ec6\u8bb2\u89e3\u4e86\u5982\u4f55\u5b89\u88c5\u4e00\u4e2a\u53ef\u5feb\u901f\u5f00\u59cb\u7f16\u5199 Python \u5e94\u7528\u7a0b\u5e8f\u7684 TensorFlow \u7248\u672c\uff1a   \u5728 Ubuntu \u4e0a\u5b89\u88c5 TensorFlow  \u5728 Mac OS X \u4e0a\u5b89\u88c5 TensorFlow  \u5728 Windows \u4e0a\u5b89\u88c5 TensorFlow  \u4ece\u6e90\u4ee3\u7801\u5b89\u88c5 TensorFlow   \u4ece 0.n \u7248\u5230 1.0 \u7248\uff0cPython \u8bed\u8a00\u7684 TensorFlow API \u53d1\u751f\u4e86\u5f88\u5927\u7684\u6539\u53d8\u3002\u4e0b\u9762\u7684\u624b\u518c\u8bb2\u89e3\u4e86\u5982\u4f55\u4ece\u65e7\u7248\u672c\u7684 TensorFlow \u5e94\u7528\u7a0b\u5e8f\u8fc1\u79fb\u5230 1.0 \u7248\u672c\uff1a   \u8fc1\u79fb\u5230 TensorFlow 1.0   \u8fd9\u4e00\u7ae0\u540c\u65f6\u8fd8\u8bb2\u89e3\u4e86\u5982\u4f55\u5b89\u88c5\u5176\u5b83\u7f16\u7a0b\u8bed\u8a00\u7684 TensorFlow \u5e93\u6587\u4ef6\u3002\u8fd9\u4e9b API \u5e93\u5217\u4e4b\u6240\u4ee5\u5728\u8fd9\u91cc\uff0c\u4e3b\u8981\u76ee\u7684\u662f\u5728\u4e0d\u540c\u8bed\u8a00\u7f16\u5199\u7684\u5e94\u7528\u7a0b\u5e8f\u4e2d\u90e8\u7f72 TensorFlow \u6a21\u578b\uff0c\u6240\u4ee5\u5e76\u4e0d\u5982 Python API \u7684\u5168\u9762\u3002   \u5b89\u88c5 TensorFlow for Java  \u5b89\u88c5 TensorFlow for C  \u5b89\u88c5 TensorFlow for Go", 
            "title": "\u5b89\u88c5 TensorFlow"
        }, 
        {
            "location": "/install/install_linux/", 
            "text": "\u5728 Ubuntu \u4e0a\u5b89\u88c5 TensorFlow\n\n\n\u672c\u6307\u5357\u89e3\u91ca\u4e86\u5982\u4f55\u5728 Ubuntu \u64cd\u4f5c\u7cfb\u7edf\u5b89\u88c5 TensorFlow\u3002\u8fd9\u4e9b\u5b89\u88c5\u6b65\u9aa4\u548c\u64cd\u4f5c\u6307\u4ee4\u4e5f\u53ef\u80fd\u5728\u5176\u4ed6Linux\u53d8\u4f53\u4e2d\u6709\u6548\uff0c\u4f46\u5b98\u65b9\u53ea\u6d4b\u8bd5\u4e86(\u540c\u65f6\u5b98\u65b9\u4e5f\u53ea\u652f\u6301)\u8fd9\u4e9b\u5b89\u88c5\u6b65\u9aa4\u548c\u64cd\u4f5c\u6307\u4ee4\u5728Ubuntu 14.04\u6216\u66f4\u9ad8\u7248\u672c\u4e2d\u7684\u6709\u6548\u6027\u3002\n\n\n\u786e\u5b9a\u9700\u8981\u5b89\u88c5\u7684 TensorFlow \u7684\u7c7b\u578b\n\n\n\u9009\u62e9\u4ee5\u4e0b\u4e4b\u4e00\u7c7b\u578b\u7684 TensorFlow \u6765\u5b89\u88c5:\n\n\n\n\n\u4ec5\u652f\u6301 CPU \u8fd0\u7b97\u7684 TensorFlow\n\u3002\u5982\u679c\u7cfb\u7edf\u4e2d\u6ca1\u6709NVIDIA\u00ae GPU\uff0c\u90a3\u4e48\u5fc5\u987b\u5b89\u88c5\u8fd9\u4e2a\u7248\u672c\u3002\u8fd9\u4e2a\u7248\u672c\u7684TensorFlow\u4e00\u822c\u6765\u8bf4\u66f4\u5bb9\u6613\u5b89\u88c5\uff08\u53ea\u9700\u89815\u523010\u5206\u949f\uff09\uff0c\u56e0\u6b64\uff0c\u5373\u4f7f\u4f60\u7684\u7cfb\u7edf\u4e2d\u6709NVIDIA\u00ae GPU\uff0c\u6211\u4eec\u4e5f\u5efa\u8bae\u9996\u5148\u5b89\u88c5\u8fd9\u4e2a\u7248\u672c\u3002\n\n\n\u652f\u6301 GPU \u8fd0\u7b97\u7684 TensorFlow\n\u3002TensorFlow\u7a0b\u5e8f\u4e00\u822c\u8fd0\u884c\u5728GPU\u4e0a\u6bd4\u8fd0\u884c\u5728CPU\u4e0a\u8981\u5feb\u5f88\u591a\u3002\u56e0\u6b64\uff0c\u5982\u679c\u7cfb\u7edf\u4e2d\u6709NVIDIA\u00ae GPU\u540c\u65f6\u4e5f\u6ee1\u8db3\u5982\u4e0b\u6240\u793a\u7684\u5148\u51b3\u6761\u4ef6\uff0c\u5e76\u4e14\u9700\u8981\u8fd0\u884c\u6027\u80fd\u5173\u952e\u578b\u5e94\u7528\u7a0b\u5e8f\uff0c\u90a3\u4e48\u8fd8\u662f\u5b89\u88c5\u8fd9\u4e2a\u7248\u672c\u5427\u3002\n\n\n\n\n\n\n\u8fd0\u884c\u652f\u6301 GPU \u8fd0\u7b97\u7684 TensorFlow \u5fc5\u987b\u6ee1\u8db3\u7684\u5148\u51b3\u6761\u4ef6\n\n\n\u9700\u8981\u5b89\u88c5 GPU \u652f\u6301\u7684 TensorFlow\u3001\u5e76\u4e14\u671f\u671b\u80fd\u591f\u5b9e\u73b0\u672c\u6307\u5357\u4e2d\u6240\u63cf\u8ff0\u7684\u5404\u79cd\u5e94\u7528\u573a\u666f\uff0c\u90a3\u4e48\u60a8\u7684\u7cfb\u7edf\u4e2d\u9996\u5148\u5fc5\u987b\u5b89\u88c5\u4e0b\u9762\u8fd9\u4e9b NVIDIA \u8f6f\u4ef6\uff1a\n\n\n\n\nCUDA\u00ae Toolkit 8.0. \u8be6\u7ec6\u7684\u4ecb\u7ecd\uff0c\u8bf7\u53c2\u8003\n    \nNVIDIA\ns documentation\n\u3002\n    \u786e\u4fdd\u6309\u7167 NVIDIA \u7684\u6587\u6863\u6dfb\u52a0\u76f8\u5173\u7684 Cuda \u8def\u5f84\u5230 \nLD_LIBRARY_PATH\n \u73af\u5883\u53d8\u91cf\u91cc\u3002\n\n\nCUDA Toolkit 8.0 \u76f8\u5173\u7684 NVIDIA \u9a71\u52a8\u3002\n\n\ncuDNN v5.1. \u8be6\u7ec6\u7684\u4ecb\u7ecd\uff0c\u8bf7\u53c2\u8003\n    \nNVIDIA\ns documentation\n\u3002\n    \u786e\u4fdd\u6309\u7167 NVIDIA \u7684\u6587\u6863\u521b\u5efa \nCUDA_HOME\n \u73af\u5883\u53d8\u91cf\u3002\n\n\n\u5177\u6709 CUDA Compute Capability 3.0 \u4ee5\u4e0a\u652f\u6301\u7684 GPU. \u53d7\u652f\u6301\u7684 GPU \u5217\u8868\u8bf7\u53c2\u8003\n    \nNVIDIA documentation\n\u3002\n\n\n\n\nlibcupti-dev\uff08NVIDIA CUDA Profile Tools Interface\uff09\u5f00\u53d1\u5e93\u63d0\u4f9b\u4e86\u5bf9\u9ad8\u7ea7\u5206\u6790\u7684\u652f\u6301\u3002\u8981\u5b89\u88c5\u8fd9\u4e2a\u5e93\uff0c\u53ef\u4ee5\u4f7f\u7528\u5982\u4e0b\u547d\u4ee4\uff1a\n\n\n\n$ \nsudo apt-get install libcupti-dev\n\n\n\n\n\n\n\n\n\u5982\u679c\u66fe\u7ecf\u5b89\u88c5\u8fc7\u4e0a\u9762\u63d0\u5230\u7684\u8f6f\u4ef6\u5305\u7684\u65e9\u671f\u7248\u672c\uff0c\u90a3\u4e48\u8bf7\u5347\u7ea7\u5230\u6307\u5b9a\u7684\u7248\u672c\u3002\u786e\u5b9e\u5347\u7ea7\u4e0d\u4e86\uff0c\u4e5f\u8fd8\u662f\u53ef\u4ee5\u8fd0\u884c GPU \u7684\u652f\u6301 TensorFlow \u7684,\u4f46\u9700\u8981\u6ee1\u8db3\u4ee5\u4e0b\u51e0\u70b9\uff1a\n\n\n\n\n\u6309\u7167\u6587\u6863\u201c\n\u4ece\u6e90\u4ee3\u7801\u5b89\u88c5 TensorFlow\n\u201d\u5b8c\u6210 TensorFlow \u7684\u5b89\u88c5\u3002\n\n\n\u5b89\u88c5\u6216\u8005\u5347\u7ea7\u5982\u4e0b\u7684 NVIDIA \u8f6f\u4ef6\u5230\u6307\u5b9a\u7248\u672c:\n\n\nCUDA toolkit 7.0 \u53ca\u4ee5\u4e0a\n\n\ncuDNN v3 \u53ca\u4ee5\u4e0a\n\n\n\u5177\u6709 CUDA Compute Capability 3.0 \u53ca\u4ee5\u4e0a\u652f\u6301\u7684 GPU\u3002\n\n\n\n\n\n\n\n\n\u786e\u5b9a\u5982\u4f55\u5b89\u88c5 TensorFlow\n\n\n\u60a8\u9700\u8981\u4ece\u4e0b\u9762\u51e0\u79cd\u53d7\u652f\u6301\u7684\u5b89\u88c5\u65b9\u5f0f\u4e2d\u6311\u4e00\u79cd\u6765\u5b89\u88c5 TensorFlow\uff1a\n\n\n\n\nvirtualenv\n\n\nnative\n pip\n\n\nDocker\n\n\nAnaconda\n\n\n\u8fd8\u6709\u4ece\u6e90\u4ee3\u7801\u5b89\u88c5\uff0c\u8fd9\u4e2a\u6709\u4e00\u4e2a\n\u5355\u72ec\u7684\u6587\u6863\n\u3002\n\n\n\n\n(\u5b98\u65b9)\u5f3a\u70c8\u5efa\u8bae\u91c7\u7528\u7b2c\u4e00\u79cd\u65b9\u6cd5\uff1avirtualenv\u3002\n\n\nVirtualenv\n\u662f\u4e00\u4e2a\u865a\u62df\u7684Python\u73af\u5883\uff0c\u7528\u4ee5\u9694\u79bb\u540c\u4e00\u53f0\u8bbe\u5907\u4e0a\u7684Python\u5f00\u53d1\u548c\u8fd0\u884c\u73af\u5883\uff0c\u4f7fPython\u7a0b\u5e8f\u4e0d\u5e72\u6270\u5176\u5b83Python\u7a0b\u5e8f\u7684\u8fd0\u884c\uff0c\u540c\u65f6\u4e5f\u4e0d\u88ab\u5176\u4ed6Python\u7a0b\u5e8f\u6240\u5f71\u54cd\u3002\u5728\u57fa\u4e8evirtualenv\u7684\u5b89\u88c5\u8fc7\u7a0b\u4e2d\uff0c\u4f60\u4e0d\u4ec5\u4f1a\u5b89\u88c5TensorFlow\u3001\u540c\u65f6\u4e5f\u4f1a\u5b89\u88c5TensorFlow\u9700\u8981\u7684\u6240\u6709\u8f6f\u4ef6\u5305\uff08\u6240\u4ee5\uff0c\u7528\u8fd9\u79cd\u65b9\u6cd5\u5b89\u88c5TensorFlow\u771f\u7684\u662f\u975e\u5e38\u5bb9\u6613\u7684\uff09\u3002\u8981\u8ba9TensorFlow\u5f00\u59cb\u5de5\u4f5c\uff0c\u4f60\u9700\u8981\u505a\u7684\u4ec5\u4ec5\u662f\u201c\u6fc0\u6d3b\uff08activate\uff09\u201d\u865a\u62df\u73af\u5883\u5c31\u53ef\u4ee5\u4e86\u3002\u603b\u4e4b\uff0cvirtualenv\u63d0\u4f9b\u4e86\u5b89\u5168\u5b89\u88c5\u548c\u8fd0\u884cTensorFlow\u7684\u53ef\u9760\u673a\u5236\u3002\n\n\n\u4e0d\u901a\u8fc7\u4efb\u4f55\u5bb9\u5668\u7cfb\u7edf\uff0c\u800c\u662f\u76f4\u63a5\u901a\u8fc7\u672c\u5730pip\u547d\u4ee4\u5b89\u88c5TensorFlow\u3002 \n\u5bf9\u4e8e\u5e0c\u671b\u5728\u591a\u7528\u6237\u7cfb\u7edf\u73af\u5883\u4e2d\u5feb\u901f\u90e8\u7f72TensorFlow\u7684\u7cfb\u7edf\u7ba1\u7406\u5458\u4eec\uff0c\u6211\u4eec\u63a8\u8350\u4f7f\u7528\u672c\u5730pip\u5b89\u88c5\u7684\u65b9\u5f0f\u3002\n \u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c\u7531\u4e8e\u672c\u5730pip\u547d\u4ee4\u7684\u5b89\u88c5\u8fc7\u7a0b\u5e76\u6ca1\u6709\u88ab\u9694\u79bb\u5728\u4efb\u4f55\u7684\u5bb9\u5668\u73af\u5883\u4e2d\uff0c\u6240\u4ee5\u53ef\u80fd\u4f1a\u5e72\u6270\u540c\u4e00\u7cfb\u7edf\u91cc\u5176\u4ed6\u7684\u57fa\u4e8epython\u7684\u5b89\u88c5\u8fc7\u7a0b\u3002\u4f46\u662f\uff0c\u5982\u679c\u4f60\u4e86\u89e3pip\u4ee5\u53caPython\u73af\u5883\u7684\u8bdd\uff0c\u540c\u6837\u5c31\u4f1a\u77e5\u9053\uff0c\u57fa\u4e8e\u672c\u5730pip\u7684\u5b89\u88c5\u901a\u5e38\u53ea\u9700\u8981\u4e00\u4e2a\u547d\u4ee4\u3002\n\n\nDocker\u5728\u4f60\u7684\u8bbe\u5907\u4e0a\u4e3aTensorFlow\u5efa\u7acb\u4e86\u5b8c\u5168\u9694\u79bb\u7684\u73af\u5883\u3002\u9884\u5b89\u88c5\u4e86\u8f6f\u4ef6\u5305\u7684Docker\u5bb9\u5668\u4e2d\uff0c\u5305\u542b\u4e86TensorFlow\u672c\u8eab\u53ca\u5176\u6240\u6709\u7684\u4f9d\u8d56\u9879\u3002\u8bf7\u6ce8\u610f\uff0cDocker\u6620\u50cf\u53ef\u80fd\u4f1a\u5f88\u5927(\u51e0\u767eMB)\u3002\u5982\u679c\u4f60\u5e0c\u671b\u5728\u4e00\u4e2a\u89c4\u6a21\u6bd4\u8f83\u5927\u3001\u800c\u4e14\u5df2\u7ecf\u4f7f\u7528\u4e86Docker\u7684\u5e94\u7528\u67b6\u6784\u4e2d\u5efa\u7acbTensorFlow\uff0c\u90a3\u4e48\u4f60\u53ef\u4ee5\u9009\u62e9\u57fa\u4e8eDocker\u7684\u5b89\u88c5\u3002\n\n\n\u5728Anaconda\u4e2d\uff0c\u4f60\u53ef\u4ee5\u4f7f\u7528\nconda\n\u6765\u521b\u5efa\u865a\u62df\u73af\u5883\u3002\u7136\u800c\uff0c\u5bf9\u4e8eAnaconda\u8ba1\u7b97\u73af\u5883\uff0c\u6211\u4eec\u8fd8\u662f\u5efa\u8bae\u4f7f\u7528\npip install\n\u547d\u4ee4\uff0c\u800c\u4e0d\u662f\nconda install\n\u547d\u4ee4\u6765\u5b89\u88c5TensorFlow\u3002\n\n\n\u6ce8\u610f\uff1a\nconda\u5b89\u88c5\u5305\u662f\u7531\u793e\u533a\u652f\u6301\u7684\uff0c\u800c\u4e0d\u662f\u5b98\u65b9\u652f\u6301\u7684\u3002\u4e5f\u5c31\u662f\u8bf4\uff0cTensorFlow\u56e2\u961f\u65e2\u4e0d\u6d4b\u8bd5\u4e5f\u4e0d\u7ef4\u62a4conda\u5305\u3002\u5176\u4e2d\u53ef\u80fd\u7684\u98ce\u9669\u81ea\u62c5\u3002\n\n\n\n\n\u57fa\u4e8e virtualenv \u5b89\u88c5\n\n\n\u91c7\u53d6\u4ee5\u4e0b\u6b65\u9aa4\u6765\u57fa\u4e8eVirtualenv\u5b89\u88c5TensorFlow\uff1a\n\n\n\n\n\n\n\u901a\u8fc7\u4ee5\u4e0b\u547d\u4ee4\u6765\u5b89\u88c5pip\u548cvirtualenv\uff1a\n\n\n$ \nsudo apt-get install python-pip python-dev python-virtualenv\n # for Python 2.7\n $ \nsudo apt-get install python3-pip python3-dev python-virtualenv\n # for Python 3.n\n\n\n\n\n\n\n\u901a\u8fc7\u4ee5\u4e0b\u547d\u4ee4\u6765\u521b\u5efa\u4e00\u4e2avirtualenv\u73af\u5883\uff1a\n\n\n$ \nvirtualenv \nsystem-site-packages\n \ntargetDirectory\n # for Python 2.7\n $ \nvirtualenv \nsystem-site-packages -p python3\n \ntargetDirectory\n # for Python 3.n\n\n\ntargetDirectory\n \u6307\u5b9a\u4e86 virtualenv \u76ee\u5f55\u6240\u5728\uff0c\ntargetDirectory\n \u7684\u9ed8\u8ba4\u503c\u662f \n~/tensorflow\n\uff0c\u5f53\u7136\u4f60\u53ef\u4ee5\u9009\u62e9\u4efb\u4f55\u76ee\u5f55\u3002\n\n\n\n\n\n\nActivate the virtualenv environment by issuing one of the following\n     commands:\n\n\n$ \nsource ~/tensorflow/bin/activate\n # bash, sh, ksh, or zsh\n $ \nsource ~/tensorflow/bin/activate.csh\n  # csh or tcsh\n\n\nThe preceding \nsource\n command should change your prompt\n to the following:\n\n\n(tensorflow)$ \n\n\n\n\n\n\nEnsure pip \u22658.1 is installed:\n\n\n(tensorflow)$ \neasy_install -U pip\n\n\n\n\n\n\nIssue one of the following commands to install TensorFlow in the active\n     virtualenv environment:\n\n\n(tensorflow)$ \npip install \nupgrade tensorflow\n      # for Python 2.7\n (tensorflow)$ \npip3 install \nupgrade tensorflow\n     # for Python 3.n\n (tensorflow)$ \npip install \nupgrade tensorflow-gpu\n  # for Python 2.7 and GPU\n (tensorflow)$ \npip3 install \nupgrade tensorflow-gpu\n # for Python 3.n and GPU\n\n\nIf the preceding command succeeds, skip Step 5. If the preceding\n command fails, perform Step 5.\n\n\n\n\n\n\n(Optional) If Step 4 failed (typically because you invoked a pip version\n     lower than 8.1), install TensorFlow in the active virtualenv environment\n     by issuing a command of the following format:\n\n\n(tensorflow)$ \npip install \nupgrade\n \ntfBinaryURL\n   # Python 2.7\n (tensorflow)$ \npip3 install \nupgrade\n \ntfBinaryURL\n  # Python 3.n \n\n\nwhere \ntfBinaryURL\n identifies the URL of the\n TensorFlow Python package. The appropriate value of\n \ntfBinaryURL\ndepends on the operating system,\n Python version, and GPU support. Find the appropriate value for\n \ntfBinaryURL\n for your system\n \nhere\n.  For example, if you\n are installing TensorFlow for Linux, Python 3.4, and CPU-only support,\n issue the following command to install TensorFlow in the active\n virtualenv environment:\n\n\n(tensorflow)$ \npip3 install \nupgrade \\\n https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-1.3.0-cp34-cp34m-linux_x86_64.whl\n\n\n\n\n\n\nIf you encounter installation problems, see\n\nCommon Installation Problems\n.\n\n\nNext Steps\n\n\nAfter installing TensorFlow,\n\nvalidate the installation\n.\n\n\nNote that you must activate the virtualenv environment each time you\nuse TensorFlow. If the virtualenv environment is not currently active,\ninvoke one of the following commands:\n\n\n$ \nsource ~/tensorflow/bin/activate\n      # bash, sh, ksh, or zsh\n$ \nsource ~/tensorflow/bin/activate.csh\n  # csh or tcsh\n\n\n\nWhen the virtualenv environment is active, you may run\nTensorFlow programs from this shell.  Your prompt will become\nthe following to indicate that your tensorflow environment is active:\n\n\n(tensorflow)$ \n\n\n\nWhen you are done using TensorFlow, you may deactivate the\nenvironment by invoking the \ndeactivate\n function as follows:\n\n\n(tensorflow)$ \ndeactivate\n \n\n\n\nThe prompt will revert back to your default prompt (as defined by the\n\nPS1\n environment variable).\n\n\nUninstalling TensorFlow\n\n\nTo uninstall TensorFlow, simply remove the tree you created.\nFor example:\n\n\n$ \nrm -r\n \ntargetDirectory\n \n\n\n\n\n\nInstalling with native pip\n\n\nYou may install TensorFlow through pip, choosing between a simple\ninstallation procedure or a more complex one.\n\n\nNote:\n The\n\nREQUIRED_PACKAGES section of setup.py\n\nlists the TensorFlow packages that pip will install or upgrade.\n\n\nPrerequisite: Python and Pip\n\n\nPython is automatically installed on Ubuntu.  Take a moment to confirm\n(by issuing a \npython -V\n command) that one of the following Python\nversions is already installed on your system:\n\n\n\n\nPython 2.7\n\n\nPython 3.3+\n\n\n\n\nThe pip or pip3 package manager is \nusually\n installed on Ubuntu.  Take a\nmoment to confirm (by issuing a \npip -V\n or \npip3 -V\n command)\nthat pip or pip3 is installed.  We strongly recommend version 8.1 or higher\nof pip or pip3.  If Version 8.1 or later is not installed, issue the\nfollowing command, which will either install or upgrade to the latest\npip version:\n\n\n$ \nsudo apt-get install python-pip python-dev\n   # for Python 2.7\n$ \nsudo apt-get install python3-pip python3-dev\n # for Python 3.n\n\n\n\n\nInstall TensorFlow\n\n\nAssuming the prerequisite software is installed on your Linux host,\ntake the following steps:\n\n\n\n\n\n\nInstall TensorFlow by invoking \none\n of the following commands:\n\n\n$ \npip install tensorflow\n      # Python 2.7; CPU support (no GPU support)\n $ \npip3 install tensorflow\n     # Python 3.n; CPU support (no GPU support)\n $ \npip install tensorflow-gpu\n  # Python 2.7;  GPU support\n $ \npip3 install tensorflow-gpu\n # Python 3.n; GPU support \n\n\nIf the preceding command runs to completion, you should now\n \nvalidate your installation\n.\n\n\n\n\n\n\n(Optional.) If Step 1 failed, install the latest version of TensorFlow\n     by issuing a command of the following format:\n\n\n$ \nsudo pip  install \nupgrade\n \ntfBinaryURL\n   # Python 2.7\n $ \nsudo pip3 install \nupgrade\n \ntfBinaryURL\n   # Python 3.n \n\n\nwhere \ntfBinaryURL\n identifies the URL of the\n TensorFlow Python package. The appropriate value of\n \ntfBinaryURL\n depends on the operating system,\n Python version, and GPU support. Find the appropriate value for\n \ntfBinaryURL\n\n \nhere\n.  For example, to\n install TensorFlow for Linux, Python 3.4, and CPU-only support, issue\n the following command:\n\n\n\n $ \nsudo pip3 install \nupgrade \\\n https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-1.3.0-cp34-cp34m-linux_x86_64.whl\n\n \n\n\nIf this step fails, see\n \nCommon Installation Problems\n.\n\n\n\n\n\n\nNext Steps\n\n\nAfter installing TensorFlow, \nvalidate your installation\n.\n\n\nUninstalling TensorFlow\n\n\nTo uninstall TensorFlow, issue one of following commands:\n\n\n\n$ \nsudo pip uninstall tensorflow\n  # for Python 2.7\n$ \nsudo pip3 uninstall tensorflow\n # for Python 3.n\n\n\n\n\n\n\nInstalling with Docker\n\n\nTake the following steps to install TensorFlow through Docker:\n\n\n\n\nInstall Docker on your machine as described in the\n     \nDocker documentation\n.\n\n\nOptionally, create a Linux group called \ndocker\n to allow\n     launching containers without sudo as described in the\n     \nDocker documentation\n.\n     (If you don\nt do this step, you\nll have to use sudo each time\n     you invoke Docker.)\n\n\nTo install a version of TensorFlow that supports GPUs, you must first\n     install \nnvidia-docker\n, which\n     is stored in github.\n\n\nLaunch a Docker container that contains one of the\n     \nTensorFlow binary images\n.\n\n\n\n\nThe remainder of this section explains how to launch a Docker container.\n\n\nCPU-only\n\n\nTo launch a Docker container with CPU-only support (that is, without\nGPU support), enter a command of the following format:\n\n\n\n$ docker run -it \n-p hostPort:containerPort TensorFlowCPUImage\n\n\n\n\n\nwhere:\n\n\n\n\n-p hostPort:containerPort\n is optional.\n    If you plan to run TensorFlow programs from the shell, omit this option.\n    If you plan to run TensorFlow programs as Jupyter notebooks, set both\n    \nhostPort\n and \ncontainerPort\n\n    to \n8888\n.  If you\nd like to run TensorBoard inside the container,\n    add a second \n-p\n flag, setting both \nhostPort\n and \ncontainerPort\n\n    to 6006.\n\n\n\n\nTensorFlowCPUImage\n is required. It identifies the Docker\n    container. Specify one of the following values:\n\n\n\n\ngcr.io/tensorflow/tensorflow\n, which is the TensorFlow CPU binary image.\n\n\ngcr.io/tensorflow/tensorflow:latest-devel\n, which is the latest\n  TensorFlow CPU Binary image plus source code.\n\n\ngcr.io/tensorflow/tensorflow:\nversion\n, which is the\n  specified version (for example, 1.1.0rc1) of TensorFlow CPU binary image.\n\n\ngcr.io/tensorflow/tensorflow:\nversion\n-devel\n, which is\n  the specified version (for example, 1.1.0rc1) of the TensorFlow GPU\n  binary image plus source code.\n\n\n\n\ngcr.io\n is the Google Container Registry. Note that some\nTensorFlow images are also available at\n\ndockerhub\n.\n\n\n\n\n\n\nFor example, the following command launches the latest TensorFlow CPU binary image\nin a Docker container from which you can run TensorFlow programs in a shell:\n\n\n\n$ \ndocker run -it gcr.io/tensorflow/tensorflow bash\n\n\n\n\n\nThe following command also launches the latest TensorFlow CPU binary image in a\nDocker container. However, in this Docker container, you can run TensorFlow\nprograms in a Jupyter notebook:\n\n\n\n$ \ndocker run -it -p 8888:8888 gcr.io/tensorflow/tensorflow\n\n\n\n\n\nDocker will download the TensorFlow binary image the first time you launch it.\n\n\nGPU support\n\n\nPrior to installing TensorFlow with GPU support, ensure that your system meets all\n\nNVIDIA software requirements\n.  To launch a Docker container\nwith NVidia GPU support, enter a command of the following format:\n\n\n\n$ \nnvidia-docker run -it\n \n-p hostPort:containerPort TensorFlowGPUImage\n\n\n\n\n\nwhere:\n\n\n\n\n-p hostPort:containerPort\n is optional. If you plan\n    to run TensorFlow programs from the shell, omit this option. If you plan\n    to run TensorFlow programs as Jupyter notebooks, set both\n    \nhostPort\n and \ncontainerPort\n to \n8888\n.\n\n\nTensorFlowGPUImage\n specifies the Docker container. You must\n    specify one of the following values:\n\n\ngcr.io/tensorflow/tensorflow:latest-gpu\n, which is the latest\n  TensorFlow GPU binary image.\n\n\ngcr.io/tensorflow/tensorflow:latest-devel-gpu\n, which is\n  the latest TensorFlow GPU Binary image plus source code.\n\n\ngcr.io/tensorflow/tensorflow:\nversion\n-gpu\n, which is the\n  specified version (for example, 0.12.1) of the TensorFlow GPU\n  binary image.\n\n\ngcr.io/tensorflow/tensorflow:\nversion\n-devel-gpu\n, which is\n  the specified version (for example, 0.12.1) of the TensorFlow GPU\n  binary image plus source code.\n\n\n\n\n\n\n\n\nWe recommend installing one of the \nlatest\n versions. For example, the\nfollowing command launches the latest TensorFlow GPU binary image in a\nDocker container from which you can run TensorFlow programs in a shell:\n\n\n\n$ \nnvidia-docker run -it gcr.io/tensorflow/tensorflow:latest-gpu bash\n\n\n\n\n\nThe following command also launches the latest TensorFlow GPU binary image\nin a Docker container. In this Docker container, you can run TensorFlow\nprograms in a Jupyter notebook:\n\n\n\n$ \nnvidia-docker run -it -p 8888:8888 gcr.io/tensorflow/tensorflow:latest-gpu\n\n\n\n\n\nThe following command installs an older TensorFlow version (0.12.1):\n\n\n\n$ \nnvidia-docker run -it -p 8888:8888 gcr.io/tensorflow/tensorflow:0.12.1-gpu\n\n\n\n\n\nDocker will download the TensorFlow binary image the first time you launch it.\nFor more details see the\n\nTensorFlow docker readme\n.\n\n\nNext Steps\n\n\nYou should now\n\nvalidate your installation\n.\n\n\n\n\nInstalling with Anaconda\n\n\nTake the following steps to install TensorFlow in an Anaconda environment:\n\n\n\n\n\n\nFollow the instructions on the\n     \nAnaconda download site\n\n     to download and install Anaconda.\n\n\n\n\n\n\nCreate a conda environment named \ntensorflow\n to run a version\n     of Python by invoking the following command:\n\n\n$ \nconda create -n tensorflow\n\n\n\n\n\n\nActivate the conda environment by issuing the following command:\n\n\n$ \nsource activate tensorflow\n\n (tensorflow)$  # Your prompt should change \n\n\n\n\n\n\nIssue a command of the following format to install\n     TensorFlow inside your conda environment:\n\n\n(tensorflow)$ \npip install \nignore-installed \nupgrade\n \ntfBinaryURL\n\n\nwhere \ntfBinaryURL\n is the\n \nURL of the TensorFlow Python package\n.\n For example, the following command installs the CPU-only version of\n TensorFlow for Python 3.4:\n\n\n\n (tensorflow)$ \npip install \nignore-installed \nupgrade \\\n https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-1.3.0-cp34-cp34m-linux_x86_64.whl\n\n\n\n\n\n\n\n\nValidate your installation\n\n\nTo validate your TensorFlow installation, do the following:\n\n\n\n\nEnsure that your environment is prepared to run TensorFlow programs.\n\n\nRun a short TensorFlow program.\n\n\n\n\nPrepare your environment\n\n\nIf you installed on native pip, virtualenv, or Anaconda, then\ndo the following:\n\n\n\n\nStart a terminal.\n\n\nIf you installed with virtualenv or Anaconda, activate your container.\n\n\nIf you installed TensorFlow source code, navigate to any\n     directory \nexcept\n one containing TensorFlow source code.\n\n\n\n\nIf you installed through Docker, start a Docker container\nfrom which you can run bash. For example:\n\n\n\n$ \ndocker run -it gcr.io/tensorflow/tensorflow bash\n\n\n\n\n\nRun a short TensorFlow program\n\n\nInvoke python from your shell as follows:\n\n\n$ \npython\n\n\n\nEnter the following short program inside the python interactive shell:\n\n\n# Python\nimport tensorflow as tf\nhello = tf.constant('Hello, TensorFlow!')\nsess = tf.Session()\nprint(sess.run(hello))\n\n\n\n\nIf the system outputs the following, then you are ready to begin writing\nTensorFlow programs:\n\n\nHello, TensorFlow!\n\n\n\nIf you are new to TensorFlow, see @{$get_started/get_started$Getting Started with TensorFlow}.\n\n\nIf the system outputs an error message instead of a greeting, see \nCommon\ninstallation problems\n.\n\n\nCommon installation problems\n\n\nWe are relying on Stack Overflow to document TensorFlow installation problems\nand their remedies.  The following table contains links to Stack Overflow\nanswers for some common installation problems.\nIf you encounter an error message or other\ninstallation problem not listed in the following table, search for it\non Stack Overflow.  If Stack Overflow doesn\nt show the error message,\nask a new question about it on Stack Overflow and specify\nthe \ntensorflow\n tag.\n\n\n\n\n \nStack Overflow Link\n \nError Message\n \n\n\n\n\n  \n36159194\n\n  \nImportError: libcudart.so.\nVersion\n: cannot open shared object file:\n  No such file or directory\n\n\n\n\n\n\n  \n41991101\n\n  \nImportError: libcudnn.\nVersion\n: cannot open shared object file:\n  No such file or directory\n\n\n\n\n\n\n  \n36371137\n and\n  \nhere\n\n  \nlibprotobuf ERROR google/protobuf/src/google/protobuf/io/coded_stream.cc:207] A\n  protocol message was rejected because it was too big (more than 67108864 bytes).\n  To increase the limit (or to disable these warnings), see\n  CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.\n\n\n\n\n\n\n  \n35252888\n\n  \nError importing tensorflow. Unless you are using bazel, you should\n  not try to import tensorflow from its source directory; please exit the\n  tensorflow source tree, and relaunch your python interpreter from\n  there.\n\n\n\n\n\n\n  \n33623453\n\n  \nIOError: [Errno 2] No such file or directory:\n  '/tmp/pip-o6Tpui-build/setup.py'\n\n\n\n\n\n\n  \n42006320\n\n  \nImportError: Traceback (most recent call last):\n  File \".../tensorflow/core/framework/graph_pb2.py\", line 6, in \n\n  from google.protobuf import descriptor as _descriptor\n  ImportError: cannot import name 'descriptor'\n\n  \n\n\n\n\n\n\n  \n35190574\n \n\n  \nSSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify\n  failed\n\n\n\n\n\n\n  \n42009190\n\n  \n\n  Installing collected packages: setuptools, protobuf, wheel, numpy, tensorflow\n  Found existing installation: setuptools 1.1.6\n  Uninstalling setuptools-1.1.6:\n  Exception:\n  ...\n  [Errno 1] Operation not permitted:\n  '/tmp/pip-a1DXRT-uninstall/.../lib/python/_markerlib' \n\n\n\n\n\n\n  \n36933958\n\n  \n\n  ...\n  Installing collected packages: setuptools, protobuf, wheel, numpy, tensorflow\n  Found existing installation: setuptools 1.1.6\n  Uninstalling setuptools-1.1.6:\n  Exception:\n  ...\n  [Errno 1] Operation not permitted:\n  '/tmp/pip-a1DXRT-uninstall/System/Library/Frameworks/Python.framework/\n   Versions/2.7/Extras/lib/python/_markerlib'\n\n  \n\n\n\n\n\n\n\n\n\n\nThe URL of the TensorFlow Python package\n\n\nA few installation mechanisms require the URL of the TensorFlow Python package.\nThe value you specify depends on three factors:\n\n\n\n\noperating system\n\n\nPython version\n\n\nCPU only vs. GPU support\n\n\n\n\nThis section documents the relevant values for Linux installations.\n\n\nPython 2.7\n\n\nCPU only:\n\n\n\nhttps://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-1.3.0-cp27-none-linux_x86_64.whl\n\n\n\n\nGPU support:\n\n\n\nhttps://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-1.3.0-cp27-none-linux_x86_64.whl\n\n\n\n\nNote that GPU support requires the NVIDIA hardware and software described in\n\nNVIDIA requirements to run TensorFlow with GPU support\n.\n\n\nPython 3.4\n\n\nCPU only:\n\n\n\nhttps://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-1.3.0-cp34-cp34m-linux_x86_64.whl\n\n\n\n\nGPU support:\n\n\n\nhttps://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-1.3.0-cp34-cp34m-linux_x86_64.whl\n\n\n\n\nNote that GPU support requires the NVIDIA hardware and software described in\n\nNVIDIA requirements to run TensorFlow with GPU support\n.\n\n\nPython 3.5\n\n\nCPU only:\n\n\n\nhttps://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-1.3.0-cp35-cp35m-linux_x86_64.whl\n\n\n\n\nGPU support:\n\n\n\nhttps://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-1.3.0-cp35-cp35m-linux_x86_64.whl\n\n\n\n\nNote that GPU support requires the NVIDIA hardware and software described in\n\nNVIDIA requirements to run TensorFlow with GPU support\n.\n\n\nPython 3.6\n\n\nCPU only:\n\n\n\nhttps://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-1.3.0-cp36-cp36m-linux_x86_64.whl\n\n\n\n\nGPU support:\n\n\n\nhttps://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-1.3.0-cp36-cp36m-linux_x86_64.whl\n\n\n\n\nNote that GPU support requires the NVIDIA hardware and software described in\n\nNVIDIA requirements to run TensorFlow with GPU support\n.\n\n\n\n\nProtobuf pip package 3.1\n\n\nYou can skip this section unless you are seeing problems related\nto the protobuf pip package.\n\n\nNOTE:\n If your TensorFlow programs are running slowly, you might\nhave a problem related to the protobuf pip package.\n\n\nThe TensorFlow pip package depends on protobuf pip package version 3.1. The\nprotobuf pip package downloaded from PyPI (when invoking\n\npip install protobuf\n) is a Python-only library containing\nPython implementations of proto serialization/deserialization that can run\n\n10x-50x slower\n than the C++ implementation. Protobuf also supports a\nbinary extension for the Python package that contains fast\nC++ based proto parsing.  This extension is not available in the\nstandard Python-only pip package.  We have created a custom binary\npip package for protobuf that contains the binary extension. To install\nthe custom binary protobuf pip package, invoke one of the following commands:\n\n\n\n\nfor Python 2.7:\n\n\n\n\n\n  $ \npip install \nupgrade \\\n  https://storage.googleapis.com/tensorflow/linux/cpu/protobuf-3.1.0-cp27-none-linux_x86_64.whl\n\n\n\n\nfor Python 3.5:\n\n\n\n\n\n  $ \npip3 install \nupgrade \\\n  https://storage.googleapis.com/tensorflow/linux/cpu/protobuf-3.1.0-cp35-none-linux_x86_64.whl\n\n\nInstalling this protobuf package will overwrite the existing protobuf package.\nNote that the binary pip package already has support for protobufs\nlarger than 64MB, which should fix errors such as these:\n\n\n[libprotobuf ERROR google/protobuf/src/google/protobuf/io/coded_stream.cc:207]\nA protocol message was rejected because it was too big (more than 67108864 bytes).\nTo increase the limit (or to disable these warnings), see\nCodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.", 
            "title": "1.2 \u5728Ubuntu\u4e0a\u5b89\u88c5TensorFlow"
        }, 
        {
            "location": "/install/install_linux/#ubuntu-tensorflow", 
            "text": "\u672c\u6307\u5357\u89e3\u91ca\u4e86\u5982\u4f55\u5728 Ubuntu \u64cd\u4f5c\u7cfb\u7edf\u5b89\u88c5 TensorFlow\u3002\u8fd9\u4e9b\u5b89\u88c5\u6b65\u9aa4\u548c\u64cd\u4f5c\u6307\u4ee4\u4e5f\u53ef\u80fd\u5728\u5176\u4ed6Linux\u53d8\u4f53\u4e2d\u6709\u6548\uff0c\u4f46\u5b98\u65b9\u53ea\u6d4b\u8bd5\u4e86(\u540c\u65f6\u5b98\u65b9\u4e5f\u53ea\u652f\u6301)\u8fd9\u4e9b\u5b89\u88c5\u6b65\u9aa4\u548c\u64cd\u4f5c\u6307\u4ee4\u5728Ubuntu 14.04\u6216\u66f4\u9ad8\u7248\u672c\u4e2d\u7684\u6709\u6548\u6027\u3002", 
            "title": "\u5728 Ubuntu \u4e0a\u5b89\u88c5 TensorFlow"
        }, 
        {
            "location": "/install/install_linux/#tensorflow", 
            "text": "\u9009\u62e9\u4ee5\u4e0b\u4e4b\u4e00\u7c7b\u578b\u7684 TensorFlow \u6765\u5b89\u88c5:   \u4ec5\u652f\u6301 CPU \u8fd0\u7b97\u7684 TensorFlow \u3002\u5982\u679c\u7cfb\u7edf\u4e2d\u6ca1\u6709NVIDIA\u00ae GPU\uff0c\u90a3\u4e48\u5fc5\u987b\u5b89\u88c5\u8fd9\u4e2a\u7248\u672c\u3002\u8fd9\u4e2a\u7248\u672c\u7684TensorFlow\u4e00\u822c\u6765\u8bf4\u66f4\u5bb9\u6613\u5b89\u88c5\uff08\u53ea\u9700\u89815\u523010\u5206\u949f\uff09\uff0c\u56e0\u6b64\uff0c\u5373\u4f7f\u4f60\u7684\u7cfb\u7edf\u4e2d\u6709NVIDIA\u00ae GPU\uff0c\u6211\u4eec\u4e5f\u5efa\u8bae\u9996\u5148\u5b89\u88c5\u8fd9\u4e2a\u7248\u672c\u3002  \u652f\u6301 GPU \u8fd0\u7b97\u7684 TensorFlow \u3002TensorFlow\u7a0b\u5e8f\u4e00\u822c\u8fd0\u884c\u5728GPU\u4e0a\u6bd4\u8fd0\u884c\u5728CPU\u4e0a\u8981\u5feb\u5f88\u591a\u3002\u56e0\u6b64\uff0c\u5982\u679c\u7cfb\u7edf\u4e2d\u6709NVIDIA\u00ae GPU\u540c\u65f6\u4e5f\u6ee1\u8db3\u5982\u4e0b\u6240\u793a\u7684\u5148\u51b3\u6761\u4ef6\uff0c\u5e76\u4e14\u9700\u8981\u8fd0\u884c\u6027\u80fd\u5173\u952e\u578b\u5e94\u7528\u7a0b\u5e8f\uff0c\u90a3\u4e48\u8fd8\u662f\u5b89\u88c5\u8fd9\u4e2a\u7248\u672c\u5427\u3002", 
            "title": "\u786e\u5b9a\u9700\u8981\u5b89\u88c5\u7684 TensorFlow \u7684\u7c7b\u578b"
        }, 
        {
            "location": "/install/install_linux/#gpu-tensorflow", 
            "text": "\u9700\u8981\u5b89\u88c5 GPU \u652f\u6301\u7684 TensorFlow\u3001\u5e76\u4e14\u671f\u671b\u80fd\u591f\u5b9e\u73b0\u672c\u6307\u5357\u4e2d\u6240\u63cf\u8ff0\u7684\u5404\u79cd\u5e94\u7528\u573a\u666f\uff0c\u90a3\u4e48\u60a8\u7684\u7cfb\u7edf\u4e2d\u9996\u5148\u5fc5\u987b\u5b89\u88c5\u4e0b\u9762\u8fd9\u4e9b NVIDIA \u8f6f\u4ef6\uff1a   CUDA\u00ae Toolkit 8.0. \u8be6\u7ec6\u7684\u4ecb\u7ecd\uff0c\u8bf7\u53c2\u8003\n     NVIDIA s documentation \u3002\n    \u786e\u4fdd\u6309\u7167 NVIDIA \u7684\u6587\u6863\u6dfb\u52a0\u76f8\u5173\u7684 Cuda \u8def\u5f84\u5230  LD_LIBRARY_PATH  \u73af\u5883\u53d8\u91cf\u91cc\u3002  CUDA Toolkit 8.0 \u76f8\u5173\u7684 NVIDIA \u9a71\u52a8\u3002  cuDNN v5.1. \u8be6\u7ec6\u7684\u4ecb\u7ecd\uff0c\u8bf7\u53c2\u8003\n     NVIDIA s documentation \u3002\n    \u786e\u4fdd\u6309\u7167 NVIDIA \u7684\u6587\u6863\u521b\u5efa  CUDA_HOME  \u73af\u5883\u53d8\u91cf\u3002  \u5177\u6709 CUDA Compute Capability 3.0 \u4ee5\u4e0a\u652f\u6301\u7684 GPU. \u53d7\u652f\u6301\u7684 GPU \u5217\u8868\u8bf7\u53c2\u8003\n     NVIDIA documentation \u3002   libcupti-dev\uff08NVIDIA CUDA Profile Tools Interface\uff09\u5f00\u53d1\u5e93\u63d0\u4f9b\u4e86\u5bf9\u9ad8\u7ea7\u5206\u6790\u7684\u652f\u6301\u3002\u8981\u5b89\u88c5\u8fd9\u4e2a\u5e93\uff0c\u53ef\u4ee5\u4f7f\u7528\u5982\u4e0b\u547d\u4ee4\uff1a  \n$  sudo apt-get install libcupti-dev     \u5982\u679c\u66fe\u7ecf\u5b89\u88c5\u8fc7\u4e0a\u9762\u63d0\u5230\u7684\u8f6f\u4ef6\u5305\u7684\u65e9\u671f\u7248\u672c\uff0c\u90a3\u4e48\u8bf7\u5347\u7ea7\u5230\u6307\u5b9a\u7684\u7248\u672c\u3002\u786e\u5b9e\u5347\u7ea7\u4e0d\u4e86\uff0c\u4e5f\u8fd8\u662f\u53ef\u4ee5\u8fd0\u884c GPU \u7684\u652f\u6301 TensorFlow \u7684,\u4f46\u9700\u8981\u6ee1\u8db3\u4ee5\u4e0b\u51e0\u70b9\uff1a   \u6309\u7167\u6587\u6863\u201c \u4ece\u6e90\u4ee3\u7801\u5b89\u88c5 TensorFlow \u201d\u5b8c\u6210 TensorFlow \u7684\u5b89\u88c5\u3002  \u5b89\u88c5\u6216\u8005\u5347\u7ea7\u5982\u4e0b\u7684 NVIDIA \u8f6f\u4ef6\u5230\u6307\u5b9a\u7248\u672c:  CUDA toolkit 7.0 \u53ca\u4ee5\u4e0a  cuDNN v3 \u53ca\u4ee5\u4e0a  \u5177\u6709 CUDA Compute Capability 3.0 \u53ca\u4ee5\u4e0a\u652f\u6301\u7684 GPU\u3002", 
            "title": "\u8fd0\u884c\u652f\u6301 GPU \u8fd0\u7b97\u7684 TensorFlow \u5fc5\u987b\u6ee1\u8db3\u7684\u5148\u51b3\u6761\u4ef6"
        }, 
        {
            "location": "/install/install_linux/#tensorflow_1", 
            "text": "\u60a8\u9700\u8981\u4ece\u4e0b\u9762\u51e0\u79cd\u53d7\u652f\u6301\u7684\u5b89\u88c5\u65b9\u5f0f\u4e2d\u6311\u4e00\u79cd\u6765\u5b89\u88c5 TensorFlow\uff1a   virtualenv  native  pip  Docker  Anaconda  \u8fd8\u6709\u4ece\u6e90\u4ee3\u7801\u5b89\u88c5\uff0c\u8fd9\u4e2a\u6709\u4e00\u4e2a \u5355\u72ec\u7684\u6587\u6863 \u3002   (\u5b98\u65b9)\u5f3a\u70c8\u5efa\u8bae\u91c7\u7528\u7b2c\u4e00\u79cd\u65b9\u6cd5\uff1avirtualenv\u3002  Virtualenv \u662f\u4e00\u4e2a\u865a\u62df\u7684Python\u73af\u5883\uff0c\u7528\u4ee5\u9694\u79bb\u540c\u4e00\u53f0\u8bbe\u5907\u4e0a\u7684Python\u5f00\u53d1\u548c\u8fd0\u884c\u73af\u5883\uff0c\u4f7fPython\u7a0b\u5e8f\u4e0d\u5e72\u6270\u5176\u5b83Python\u7a0b\u5e8f\u7684\u8fd0\u884c\uff0c\u540c\u65f6\u4e5f\u4e0d\u88ab\u5176\u4ed6Python\u7a0b\u5e8f\u6240\u5f71\u54cd\u3002\u5728\u57fa\u4e8evirtualenv\u7684\u5b89\u88c5\u8fc7\u7a0b\u4e2d\uff0c\u4f60\u4e0d\u4ec5\u4f1a\u5b89\u88c5TensorFlow\u3001\u540c\u65f6\u4e5f\u4f1a\u5b89\u88c5TensorFlow\u9700\u8981\u7684\u6240\u6709\u8f6f\u4ef6\u5305\uff08\u6240\u4ee5\uff0c\u7528\u8fd9\u79cd\u65b9\u6cd5\u5b89\u88c5TensorFlow\u771f\u7684\u662f\u975e\u5e38\u5bb9\u6613\u7684\uff09\u3002\u8981\u8ba9TensorFlow\u5f00\u59cb\u5de5\u4f5c\uff0c\u4f60\u9700\u8981\u505a\u7684\u4ec5\u4ec5\u662f\u201c\u6fc0\u6d3b\uff08activate\uff09\u201d\u865a\u62df\u73af\u5883\u5c31\u53ef\u4ee5\u4e86\u3002\u603b\u4e4b\uff0cvirtualenv\u63d0\u4f9b\u4e86\u5b89\u5168\u5b89\u88c5\u548c\u8fd0\u884cTensorFlow\u7684\u53ef\u9760\u673a\u5236\u3002  \u4e0d\u901a\u8fc7\u4efb\u4f55\u5bb9\u5668\u7cfb\u7edf\uff0c\u800c\u662f\u76f4\u63a5\u901a\u8fc7\u672c\u5730pip\u547d\u4ee4\u5b89\u88c5TensorFlow\u3002  \u5bf9\u4e8e\u5e0c\u671b\u5728\u591a\u7528\u6237\u7cfb\u7edf\u73af\u5883\u4e2d\u5feb\u901f\u90e8\u7f72TensorFlow\u7684\u7cfb\u7edf\u7ba1\u7406\u5458\u4eec\uff0c\u6211\u4eec\u63a8\u8350\u4f7f\u7528\u672c\u5730pip\u5b89\u88c5\u7684\u65b9\u5f0f\u3002  \u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c\u7531\u4e8e\u672c\u5730pip\u547d\u4ee4\u7684\u5b89\u88c5\u8fc7\u7a0b\u5e76\u6ca1\u6709\u88ab\u9694\u79bb\u5728\u4efb\u4f55\u7684\u5bb9\u5668\u73af\u5883\u4e2d\uff0c\u6240\u4ee5\u53ef\u80fd\u4f1a\u5e72\u6270\u540c\u4e00\u7cfb\u7edf\u91cc\u5176\u4ed6\u7684\u57fa\u4e8epython\u7684\u5b89\u88c5\u8fc7\u7a0b\u3002\u4f46\u662f\uff0c\u5982\u679c\u4f60\u4e86\u89e3pip\u4ee5\u53caPython\u73af\u5883\u7684\u8bdd\uff0c\u540c\u6837\u5c31\u4f1a\u77e5\u9053\uff0c\u57fa\u4e8e\u672c\u5730pip\u7684\u5b89\u88c5\u901a\u5e38\u53ea\u9700\u8981\u4e00\u4e2a\u547d\u4ee4\u3002  Docker\u5728\u4f60\u7684\u8bbe\u5907\u4e0a\u4e3aTensorFlow\u5efa\u7acb\u4e86\u5b8c\u5168\u9694\u79bb\u7684\u73af\u5883\u3002\u9884\u5b89\u88c5\u4e86\u8f6f\u4ef6\u5305\u7684Docker\u5bb9\u5668\u4e2d\uff0c\u5305\u542b\u4e86TensorFlow\u672c\u8eab\u53ca\u5176\u6240\u6709\u7684\u4f9d\u8d56\u9879\u3002\u8bf7\u6ce8\u610f\uff0cDocker\u6620\u50cf\u53ef\u80fd\u4f1a\u5f88\u5927(\u51e0\u767eMB)\u3002\u5982\u679c\u4f60\u5e0c\u671b\u5728\u4e00\u4e2a\u89c4\u6a21\u6bd4\u8f83\u5927\u3001\u800c\u4e14\u5df2\u7ecf\u4f7f\u7528\u4e86Docker\u7684\u5e94\u7528\u67b6\u6784\u4e2d\u5efa\u7acbTensorFlow\uff0c\u90a3\u4e48\u4f60\u53ef\u4ee5\u9009\u62e9\u57fa\u4e8eDocker\u7684\u5b89\u88c5\u3002  \u5728Anaconda\u4e2d\uff0c\u4f60\u53ef\u4ee5\u4f7f\u7528 conda \u6765\u521b\u5efa\u865a\u62df\u73af\u5883\u3002\u7136\u800c\uff0c\u5bf9\u4e8eAnaconda\u8ba1\u7b97\u73af\u5883\uff0c\u6211\u4eec\u8fd8\u662f\u5efa\u8bae\u4f7f\u7528 pip install \u547d\u4ee4\uff0c\u800c\u4e0d\u662f conda install \u547d\u4ee4\u6765\u5b89\u88c5TensorFlow\u3002  \u6ce8\u610f\uff1a conda\u5b89\u88c5\u5305\u662f\u7531\u793e\u533a\u652f\u6301\u7684\uff0c\u800c\u4e0d\u662f\u5b98\u65b9\u652f\u6301\u7684\u3002\u4e5f\u5c31\u662f\u8bf4\uff0cTensorFlow\u56e2\u961f\u65e2\u4e0d\u6d4b\u8bd5\u4e5f\u4e0d\u7ef4\u62a4conda\u5305\u3002\u5176\u4e2d\u53ef\u80fd\u7684\u98ce\u9669\u81ea\u62c5\u3002", 
            "title": "\u786e\u5b9a\u5982\u4f55\u5b89\u88c5 TensorFlow"
        }, 
        {
            "location": "/install/install_linux/#virtualenv", 
            "text": "\u91c7\u53d6\u4ee5\u4e0b\u6b65\u9aa4\u6765\u57fa\u4e8eVirtualenv\u5b89\u88c5TensorFlow\uff1a    \u901a\u8fc7\u4ee5\u4e0b\u547d\u4ee4\u6765\u5b89\u88c5pip\u548cvirtualenv\uff1a  $  sudo apt-get install python-pip python-dev python-virtualenv  # for Python 2.7\n $  sudo apt-get install python3-pip python3-dev python-virtualenv  # for Python 3.n    \u901a\u8fc7\u4ee5\u4e0b\u547d\u4ee4\u6765\u521b\u5efa\u4e00\u4e2avirtualenv\u73af\u5883\uff1a  $  virtualenv  system-site-packages   targetDirectory  # for Python 2.7\n $  virtualenv  system-site-packages -p python3   targetDirectory  # for Python 3.n  targetDirectory  \u6307\u5b9a\u4e86 virtualenv \u76ee\u5f55\u6240\u5728\uff0c targetDirectory  \u7684\u9ed8\u8ba4\u503c\u662f  ~/tensorflow \uff0c\u5f53\u7136\u4f60\u53ef\u4ee5\u9009\u62e9\u4efb\u4f55\u76ee\u5f55\u3002    Activate the virtualenv environment by issuing one of the following\n     commands:  $  source ~/tensorflow/bin/activate  # bash, sh, ksh, or zsh\n $  source ~/tensorflow/bin/activate.csh   # csh or tcsh  The preceding  source  command should change your prompt\n to the following:  (tensorflow)$     Ensure pip \u22658.1 is installed:  (tensorflow)$  easy_install -U pip    Issue one of the following commands to install TensorFlow in the active\n     virtualenv environment:  (tensorflow)$  pip install  upgrade tensorflow       # for Python 2.7\n (tensorflow)$  pip3 install  upgrade tensorflow      # for Python 3.n\n (tensorflow)$  pip install  upgrade tensorflow-gpu   # for Python 2.7 and GPU\n (tensorflow)$  pip3 install  upgrade tensorflow-gpu  # for Python 3.n and GPU  If the preceding command succeeds, skip Step 5. If the preceding\n command fails, perform Step 5.    (Optional) If Step 4 failed (typically because you invoked a pip version\n     lower than 8.1), install TensorFlow in the active virtualenv environment\n     by issuing a command of the following format:  (tensorflow)$  pip install  upgrade   tfBinaryURL    # Python 2.7\n (tensorflow)$  pip3 install  upgrade   tfBinaryURL   # Python 3.n   where  tfBinaryURL  identifies the URL of the\n TensorFlow Python package. The appropriate value of\n  tfBinaryURL depends on the operating system,\n Python version, and GPU support. Find the appropriate value for\n  tfBinaryURL  for your system\n  here .  For example, if you\n are installing TensorFlow for Linux, Python 3.4, and CPU-only support,\n issue the following command to install TensorFlow in the active\n virtualenv environment:  (tensorflow)$  pip3 install  upgrade \\\n https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-1.3.0-cp34-cp34m-linux_x86_64.whl    If you encounter installation problems, see Common Installation Problems .", 
            "title": "\u57fa\u4e8e virtualenv \u5b89\u88c5"
        }, 
        {
            "location": "/install/install_linux/#next-steps", 
            "text": "After installing TensorFlow, validate the installation .  Note that you must activate the virtualenv environment each time you\nuse TensorFlow. If the virtualenv environment is not currently active,\ninvoke one of the following commands:  $  source ~/tensorflow/bin/activate       # bash, sh, ksh, or zsh\n$  source ~/tensorflow/bin/activate.csh   # csh or tcsh  When the virtualenv environment is active, you may run\nTensorFlow programs from this shell.  Your prompt will become\nthe following to indicate that your tensorflow environment is active:  (tensorflow)$   When you are done using TensorFlow, you may deactivate the\nenvironment by invoking the  deactivate  function as follows:  (tensorflow)$  deactivate    The prompt will revert back to your default prompt (as defined by the PS1  environment variable).", 
            "title": "Next Steps"
        }, 
        {
            "location": "/install/install_linux/#uninstalling-tensorflow", 
            "text": "To uninstall TensorFlow, simply remove the tree you created.\nFor example:  $  rm -r   targetDirectory", 
            "title": "Uninstalling TensorFlow"
        }, 
        {
            "location": "/install/install_linux/#installing-with-native-pip", 
            "text": "You may install TensorFlow through pip, choosing between a simple\ninstallation procedure or a more complex one.  Note:  The REQUIRED_PACKAGES section of setup.py \nlists the TensorFlow packages that pip will install or upgrade.", 
            "title": "Installing with native pip"
        }, 
        {
            "location": "/install/install_linux/#prerequisite-python-and-pip", 
            "text": "Python is automatically installed on Ubuntu.  Take a moment to confirm\n(by issuing a  python -V  command) that one of the following Python\nversions is already installed on your system:   Python 2.7  Python 3.3+   The pip or pip3 package manager is  usually  installed on Ubuntu.  Take a\nmoment to confirm (by issuing a  pip -V  or  pip3 -V  command)\nthat pip or pip3 is installed.  We strongly recommend version 8.1 or higher\nof pip or pip3.  If Version 8.1 or later is not installed, issue the\nfollowing command, which will either install or upgrade to the latest\npip version:  $  sudo apt-get install python-pip python-dev    # for Python 2.7\n$  sudo apt-get install python3-pip python3-dev  # for Python 3.n", 
            "title": "Prerequisite: Python and Pip"
        }, 
        {
            "location": "/install/install_linux/#install-tensorflow", 
            "text": "Assuming the prerequisite software is installed on your Linux host,\ntake the following steps:    Install TensorFlow by invoking  one  of the following commands:  $  pip install tensorflow       # Python 2.7; CPU support (no GPU support)\n $  pip3 install tensorflow      # Python 3.n; CPU support (no GPU support)\n $  pip install tensorflow-gpu   # Python 2.7;  GPU support\n $  pip3 install tensorflow-gpu  # Python 3.n; GPU support   If the preceding command runs to completion, you should now\n  validate your installation .    (Optional.) If Step 1 failed, install the latest version of TensorFlow\n     by issuing a command of the following format:  $  sudo pip  install  upgrade   tfBinaryURL    # Python 2.7\n $  sudo pip3 install  upgrade   tfBinaryURL    # Python 3.n   where  tfBinaryURL  identifies the URL of the\n TensorFlow Python package. The appropriate value of\n  tfBinaryURL  depends on the operating system,\n Python version, and GPU support. Find the appropriate value for\n  tfBinaryURL \n  here .  For example, to\n install TensorFlow for Linux, Python 3.4, and CPU-only support, issue\n the following command:  \n $  sudo pip3 install  upgrade \\\n https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-1.3.0-cp34-cp34m-linux_x86_64.whl \n   If this step fails, see\n  Common Installation Problems .", 
            "title": "Install TensorFlow"
        }, 
        {
            "location": "/install/install_linux/#next-steps_1", 
            "text": "After installing TensorFlow,  validate your installation .", 
            "title": "Next Steps"
        }, 
        {
            "location": "/install/install_linux/#uninstalling-tensorflow_1", 
            "text": "To uninstall TensorFlow, issue one of following commands:  \n$  sudo pip uninstall tensorflow   # for Python 2.7\n$  sudo pip3 uninstall tensorflow  # for Python 3.n", 
            "title": "Uninstalling TensorFlow"
        }, 
        {
            "location": "/install/install_linux/#installing-with-docker", 
            "text": "Take the following steps to install TensorFlow through Docker:   Install Docker on your machine as described in the\n      Docker documentation .  Optionally, create a Linux group called  docker  to allow\n     launching containers without sudo as described in the\n      Docker documentation .\n     (If you don t do this step, you ll have to use sudo each time\n     you invoke Docker.)  To install a version of TensorFlow that supports GPUs, you must first\n     install  nvidia-docker , which\n     is stored in github.  Launch a Docker container that contains one of the\n      TensorFlow binary images .   The remainder of this section explains how to launch a Docker container.", 
            "title": "Installing with Docker"
        }, 
        {
            "location": "/install/install_linux/#cpu-only", 
            "text": "To launch a Docker container with CPU-only support (that is, without\nGPU support), enter a command of the following format:  \n$ docker run -it  -p hostPort:containerPort TensorFlowCPUImage   where:   -p hostPort:containerPort  is optional.\n    If you plan to run TensorFlow programs from the shell, omit this option.\n    If you plan to run TensorFlow programs as Jupyter notebooks, set both\n     hostPort  and  containerPort \n    to  8888 .  If you d like to run TensorBoard inside the container,\n    add a second  -p  flag, setting both  hostPort  and  containerPort \n    to 6006.   TensorFlowCPUImage  is required. It identifies the Docker\n    container. Specify one of the following values:   gcr.io/tensorflow/tensorflow , which is the TensorFlow CPU binary image.  gcr.io/tensorflow/tensorflow:latest-devel , which is the latest\n  TensorFlow CPU Binary image plus source code.  gcr.io/tensorflow/tensorflow: version , which is the\n  specified version (for example, 1.1.0rc1) of TensorFlow CPU binary image.  gcr.io/tensorflow/tensorflow: version -devel , which is\n  the specified version (for example, 1.1.0rc1) of the TensorFlow GPU\n  binary image plus source code.   gcr.io  is the Google Container Registry. Note that some\nTensorFlow images are also available at dockerhub .    For example, the following command launches the latest TensorFlow CPU binary image\nin a Docker container from which you can run TensorFlow programs in a shell:  \n$  docker run -it gcr.io/tensorflow/tensorflow bash   The following command also launches the latest TensorFlow CPU binary image in a\nDocker container. However, in this Docker container, you can run TensorFlow\nprograms in a Jupyter notebook:  \n$  docker run -it -p 8888:8888 gcr.io/tensorflow/tensorflow   Docker will download the TensorFlow binary image the first time you launch it.", 
            "title": "CPU-only"
        }, 
        {
            "location": "/install/install_linux/#gpu-support", 
            "text": "Prior to installing TensorFlow with GPU support, ensure that your system meets all NVIDIA software requirements .  To launch a Docker container\nwith NVidia GPU support, enter a command of the following format:  \n$  nvidia-docker run -it   -p hostPort:containerPort TensorFlowGPUImage   where:   -p hostPort:containerPort  is optional. If you plan\n    to run TensorFlow programs from the shell, omit this option. If you plan\n    to run TensorFlow programs as Jupyter notebooks, set both\n     hostPort  and  containerPort  to  8888 .  TensorFlowGPUImage  specifies the Docker container. You must\n    specify one of the following values:  gcr.io/tensorflow/tensorflow:latest-gpu , which is the latest\n  TensorFlow GPU binary image.  gcr.io/tensorflow/tensorflow:latest-devel-gpu , which is\n  the latest TensorFlow GPU Binary image plus source code.  gcr.io/tensorflow/tensorflow: version -gpu , which is the\n  specified version (for example, 0.12.1) of the TensorFlow GPU\n  binary image.  gcr.io/tensorflow/tensorflow: version -devel-gpu , which is\n  the specified version (for example, 0.12.1) of the TensorFlow GPU\n  binary image plus source code.     We recommend installing one of the  latest  versions. For example, the\nfollowing command launches the latest TensorFlow GPU binary image in a\nDocker container from which you can run TensorFlow programs in a shell:  \n$  nvidia-docker run -it gcr.io/tensorflow/tensorflow:latest-gpu bash   The following command also launches the latest TensorFlow GPU binary image\nin a Docker container. In this Docker container, you can run TensorFlow\nprograms in a Jupyter notebook:  \n$  nvidia-docker run -it -p 8888:8888 gcr.io/tensorflow/tensorflow:latest-gpu   The following command installs an older TensorFlow version (0.12.1):  \n$  nvidia-docker run -it -p 8888:8888 gcr.io/tensorflow/tensorflow:0.12.1-gpu   Docker will download the TensorFlow binary image the first time you launch it.\nFor more details see the TensorFlow docker readme .", 
            "title": "GPU support"
        }, 
        {
            "location": "/install/install_linux/#next-steps_2", 
            "text": "You should now validate your installation .", 
            "title": "Next Steps"
        }, 
        {
            "location": "/install/install_linux/#installing-with-anaconda", 
            "text": "Take the following steps to install TensorFlow in an Anaconda environment:    Follow the instructions on the\n      Anaconda download site \n     to download and install Anaconda.    Create a conda environment named  tensorflow  to run a version\n     of Python by invoking the following command:  $  conda create -n tensorflow    Activate the conda environment by issuing the following command:  $  source activate tensorflow \n (tensorflow)$  # Your prompt should change     Issue a command of the following format to install\n     TensorFlow inside your conda environment:  (tensorflow)$  pip install  ignore-installed  upgrade   tfBinaryURL  where  tfBinaryURL  is the\n  URL of the TensorFlow Python package .\n For example, the following command installs the CPU-only version of\n TensorFlow for Python 3.4:  \n (tensorflow)$  pip install  ignore-installed  upgrade \\\n https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-1.3.0-cp34-cp34m-linux_x86_64.whl", 
            "title": "Installing with Anaconda"
        }, 
        {
            "location": "/install/install_linux/#validate-your-installation", 
            "text": "To validate your TensorFlow installation, do the following:   Ensure that your environment is prepared to run TensorFlow programs.  Run a short TensorFlow program.", 
            "title": "Validate your installation"
        }, 
        {
            "location": "/install/install_linux/#prepare-your-environment", 
            "text": "If you installed on native pip, virtualenv, or Anaconda, then\ndo the following:   Start a terminal.  If you installed with virtualenv or Anaconda, activate your container.  If you installed TensorFlow source code, navigate to any\n     directory  except  one containing TensorFlow source code.   If you installed through Docker, start a Docker container\nfrom which you can run bash. For example:  \n$  docker run -it gcr.io/tensorflow/tensorflow bash", 
            "title": "Prepare your environment"
        }, 
        {
            "location": "/install/install_linux/#run-a-short-tensorflow-program", 
            "text": "Invoke python from your shell as follows:  $  python  Enter the following short program inside the python interactive shell:  # Python\nimport tensorflow as tf\nhello = tf.constant('Hello, TensorFlow!')\nsess = tf.Session()\nprint(sess.run(hello))  If the system outputs the following, then you are ready to begin writing\nTensorFlow programs:  Hello, TensorFlow!  If you are new to TensorFlow, see @{$get_started/get_started$Getting Started with TensorFlow}.  If the system outputs an error message instead of a greeting, see  Common\ninstallation problems .", 
            "title": "Run a short TensorFlow program"
        }, 
        {
            "location": "/install/install_linux/#common-installation-problems", 
            "text": "We are relying on Stack Overflow to document TensorFlow installation problems\nand their remedies.  The following table contains links to Stack Overflow\nanswers for some common installation problems.\nIf you encounter an error message or other\ninstallation problem not listed in the following table, search for it\non Stack Overflow.  If Stack Overflow doesn t show the error message,\nask a new question about it on Stack Overflow and specify\nthe  tensorflow  tag.     Stack Overflow Link   Error Message    \n   36159194 \n   ImportError: libcudart.so. Version : cannot open shared object file:\n  No such file or directory   \n   41991101 \n   ImportError: libcudnn. Version : cannot open shared object file:\n  No such file or directory   \n   36371137  and\n   here \n   libprotobuf ERROR google/protobuf/src/google/protobuf/io/coded_stream.cc:207] A\n  protocol message was rejected because it was too big (more than 67108864 bytes).\n  To increase the limit (or to disable these warnings), see\n  CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.   \n   35252888 \n   Error importing tensorflow. Unless you are using bazel, you should\n  not try to import tensorflow from its source directory; please exit the\n  tensorflow source tree, and relaunch your python interpreter from\n  there.   \n   33623453 \n   IOError: [Errno 2] No such file or directory:\n  '/tmp/pip-o6Tpui-build/setup.py'   \n   42006320 \n   ImportError: Traceback (most recent call last):\n  File \".../tensorflow/core/framework/graph_pb2.py\", line 6, in  \n  from google.protobuf import descriptor as _descriptor\n  ImportError: cannot import name 'descriptor' \n     \n   35190574   \n   SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify\n  failed   \n   42009190 \n   \n  Installing collected packages: setuptools, protobuf, wheel, numpy, tensorflow\n  Found existing installation: setuptools 1.1.6\n  Uninstalling setuptools-1.1.6:\n  Exception:\n  ...\n  [Errno 1] Operation not permitted:\n  '/tmp/pip-a1DXRT-uninstall/.../lib/python/_markerlib'    \n   36933958 \n   \n  ...\n  Installing collected packages: setuptools, protobuf, wheel, numpy, tensorflow\n  Found existing installation: setuptools 1.1.6\n  Uninstalling setuptools-1.1.6:\n  Exception:\n  ...\n  [Errno 1] Operation not permitted:\n  '/tmp/pip-a1DXRT-uninstall/System/Library/Frameworks/Python.framework/\n   Versions/2.7/Extras/lib/python/_markerlib'", 
            "title": "Common installation problems"
        }, 
        {
            "location": "/install/install_linux/#the-url-of-the-tensorflow-python-package", 
            "text": "A few installation mechanisms require the URL of the TensorFlow Python package.\nThe value you specify depends on three factors:   operating system  Python version  CPU only vs. GPU support   This section documents the relevant values for Linux installations.", 
            "title": "The URL of the TensorFlow Python package"
        }, 
        {
            "location": "/install/install_linux/#python-27", 
            "text": "CPU only:  \nhttps://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-1.3.0-cp27-none-linux_x86_64.whl  GPU support:  \nhttps://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-1.3.0-cp27-none-linux_x86_64.whl  Note that GPU support requires the NVIDIA hardware and software described in NVIDIA requirements to run TensorFlow with GPU support .", 
            "title": "Python 2.7"
        }, 
        {
            "location": "/install/install_linux/#python-34", 
            "text": "CPU only:  \nhttps://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-1.3.0-cp34-cp34m-linux_x86_64.whl  GPU support:  \nhttps://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-1.3.0-cp34-cp34m-linux_x86_64.whl  Note that GPU support requires the NVIDIA hardware and software described in NVIDIA requirements to run TensorFlow with GPU support .", 
            "title": "Python 3.4"
        }, 
        {
            "location": "/install/install_linux/#python-35", 
            "text": "CPU only:  \nhttps://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-1.3.0-cp35-cp35m-linux_x86_64.whl  GPU support:  \nhttps://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-1.3.0-cp35-cp35m-linux_x86_64.whl  Note that GPU support requires the NVIDIA hardware and software described in NVIDIA requirements to run TensorFlow with GPU support .", 
            "title": "Python 3.5"
        }, 
        {
            "location": "/install/install_linux/#python-36", 
            "text": "CPU only:  \nhttps://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-1.3.0-cp36-cp36m-linux_x86_64.whl  GPU support:  \nhttps://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-1.3.0-cp36-cp36m-linux_x86_64.whl  Note that GPU support requires the NVIDIA hardware and software described in NVIDIA requirements to run TensorFlow with GPU support .", 
            "title": "Python 3.6"
        }, 
        {
            "location": "/install/install_linux/#protobuf-pip-package-31", 
            "text": "You can skip this section unless you are seeing problems related\nto the protobuf pip package.  NOTE:  If your TensorFlow programs are running slowly, you might\nhave a problem related to the protobuf pip package.  The TensorFlow pip package depends on protobuf pip package version 3.1. The\nprotobuf pip package downloaded from PyPI (when invoking pip install protobuf ) is a Python-only library containing\nPython implementations of proto serialization/deserialization that can run 10x-50x slower  than the C++ implementation. Protobuf also supports a\nbinary extension for the Python package that contains fast\nC++ based proto parsing.  This extension is not available in the\nstandard Python-only pip package.  We have created a custom binary\npip package for protobuf that contains the binary extension. To install\nthe custom binary protobuf pip package, invoke one of the following commands:   for Python 2.7:   \n  $  pip install  upgrade \\\n  https://storage.googleapis.com/tensorflow/linux/cpu/protobuf-3.1.0-cp27-none-linux_x86_64.whl   for Python 3.5:   \n  $  pip3 install  upgrade \\\n  https://storage.googleapis.com/tensorflow/linux/cpu/protobuf-3.1.0-cp35-none-linux_x86_64.whl  Installing this protobuf package will overwrite the existing protobuf package.\nNote that the binary pip package already has support for protobufs\nlarger than 64MB, which should fix errors such as these:  [libprotobuf ERROR google/protobuf/src/google/protobuf/io/coded_stream.cc:207]\nA protocol message was rejected because it was too big (more than 67108864 bytes).\nTo increase the limit (or to disable these warnings), see\nCodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.", 
            "title": "Protobuf pip package 3.1"
        }, 
        {
            "location": "/install/install_mac/", 
            "text": "Installing TensorFlow on Mac OS X\n\n\nThis guide explains how to install TensorFlow on Mac OS X.\n\n\nNote: As of version 1.2, TensorFlow no longer provides GPU support on Mac OS X.\n\n\nDetermine how to install TensorFlow\n\n\nYou must pick the mechanism by which you install TensorFlow. The supported choices are as follows:\n\n\n\n\nvirtualenv\n\n\nnative\n pip\n\n\nDocker\n\n\ninstalling from sources, which is documented in\n    \na separate guide\n.\n\n\n\n\nWe recommend the virtualenv installation.\n\n\nVirtualenv\n\nis a virtual Python environment isolated from other Python development,\nincapable of interfering with or being affected by other Python programs\non the same machine.  During the virtualenv installation process,\nyou will install not only TensorFlow but also all the packages that\nTensorFlow requires.  (This is actually pretty easy.)\nTo start working with TensorFlow, you simply need to \nactivate\n the\nvirtual environment.  All in all, virtualenv provides a safe and\nreliable mechanism for installing and running TensorFlow.\n\n\nNative pip installs TensorFlow directly on your system without going through\nany container or virtual environment system. Since a native pip installation\nis not walled-off, the pip installation might interfere with or be influenced\nby other Python-based installations on your system. Furthermore, you might need\nto disable System Integrity Protection (SIP) in order to install through native\npip.  However, if you understand SIP, pip, and your Python environment, a\nnative pip installation is relatively easy to perform.\n\n\nDocker\n completely isolates the TensorFlow installation\nfrom pre-existing packages on your machine. The Docker container contains\nTensorFlow and all its dependencies. Note that the Docker image can be quite\nlarge (hundreds of MBs). You might choose the Docker installation if you are\nincorporating TensorFlow into a larger application architecture that\nalready uses Docker.\n\n\nIn Anaconda, you may use conda to create a virtual environment.\nHowever, within Anaconda, we recommend installing TensorFlow with the\n\npip install\n command, not with the \nconda install\n command.\n\n\nNOTE:\n The conda package is community supported, not officially supported.\nThat is, the TensorFlow team neither tests nor maintains the conda package.\nUse that package at your own risk.\n\n\nInstalling with virtualenv\n\n\nTake the following steps to install TensorFlow with Virtualenv:\n\n\n\n\n\n\nStart a terminal (a shell). You\nll perform all subsequent steps\n     in this shell.\n\n\n\n\n\n\nInstall pip and virtualenv by issuing the following commands:\n\n\n $ \nsudo easy_install pip\n\n $ \nsudo pip install \nupgrade virtualenv\n \n\n\n\n\n\n\nCreate a virtualenv environment by issuing a command of one\n     of the following formats:\n\n\n $ \nvirtualenv \nsystem-site-packages\n \ntargetDirectory\n # for Python 2.7\n $ \nvirtualenv \nsystem-site-packages -p python3\n \ntargetDirectory\n # for Python 3.n\n \n\n\nwhere \ntargetDirectory\n identifies the top of the virtualenv tree.\n Our instructions assume that \ntargetDirectory\n\n is \n~/tensorflow\n, but you may choose any directory.\n\n\n\n\n\n\nActivate the virtualenv environment by issuing one of the\n     following commands:\n\n\n$ \nsource ~/tensorflow/bin/activate\n      # If using bash, sh, ksh, or zsh\n$ \nsource ~/tensorflow/bin/activate.csh\n  # If using csh or tcsh \n\n\nThe preceding \nsource\n command should change your prompt to the following:\n\n\n (tensorflow)$ \n\n\n\n\n\n\nEnsure pip \u22658.1 is installed:\n\n\n (tensorflow)$ \neasy_install -U pip\n\n\n\n\n\n\nIssue one of the following commands to install TensorFlow and all the\n     packages that TensorFlow requires into the active Virtualenv environment:\n\n\n (tensorflow)$ \npip install \nupgrade tensorflow\n      # for Python 2.7\n (tensorflow)$ \npip3 install \nupgrade tensorflow\n     # for Python 3.n\n\n\n\n\n\n\nOptional. If Step 6 failed (typically because you invoked a pip version\n     lower than 8.1), install TensorFlow in the active\n     virtualenv environment by issuing a command of the following format:\n\n\n $ \npip install \nupgrade\n \ntfBinaryURL\n   # Python 2.7\n $ \npip3 install \nupgrade\n \ntfBinaryURL\n  # Python 3.n \n\n\nwhere \ntfBinaryURL\n identifies the URL\n of the TensorFlow Python package. The appropriate value of\n \ntfBinaryURL\n depends on the operating system and\n Python version. Find the appropriate value for\n \ntfBinaryURL\n for your system\n \nhere\n.\n For example, if you are installing TensorFlow for Mac OS X,\n Python 2.7, the command to install\n TensorFlow in the active Virtualenv is as follows:\n\n\n $ \npip3 install \nupgrade \\\n https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-1.3.0-py2-none-any.whl\n\n\n\n\n\n\nIf you encounter installation problems, see\n\nCommon Installation Problems\n.\n\n\nNext Steps\n\n\nAfter installing TensorFlow,\n\nvalidate your installation\n\nto confirm that the installation worked properly.\n\n\nNote that you must activate the virtualenv environment each time you\nuse TensorFlow in a new shell.  If the virtualenv environment is not\ncurrently active (that is, the prompt is not \n(tensorflow)\n, invoke\none of the following commands:\n\n\n$ \nsource ~/tensorflow/bin/activate\n      # bash, sh, ksh, or zsh\n$ \nsource ~/tensorflow/bin/activate.csh\n  # csh or tcsh \n\n\n\nYour prompt will transform to the following to indicate that your\ntensorflow environment is active:\n\n\n (tensorflow)$ \n\n\n\nWhen the virtualenv environment is active, you may run\nTensorFlow programs from this shell.\n\n\nWhen you are done using TensorFlow, you may deactivate the\nenvironment by issuing the following command:\n\n\n (tensorflow)$ \ndeactivate\n \n\n\n\nThe prompt will revert back to your default prompt (as defined by \nPS1\n).\n\n\nUninstalling TensorFlow\n\n\nIf you want to uninstall TensorFlow, simply remove the tree you created. For example:\n\n\n $ \nrm -r ~/tensorflow\n \n\n\n\nInstalling with native pip\n\n\nWe have uploaded the TensorFlow binaries to PyPI.\nTherefore, you can install TensorFlow through pip.\n\n\nThe\n\nREQUIRED_PACKAGES section of setup.py\n\nlists the packages that pip will install or upgrade.\n\n\nPrerequisite: Python\n\n\nIn order to install TensorFlow, your system must contain one of the following Python versions:\n\n\n\n\nPython 2.7\n\n\nPython 3.3+\n\n\n\n\nIf your system does not already have one of the preceding Python versions,\n\ninstall\n it now.\n\n\nWhen installing Python, you might need to disable\nSystem Integrity Protection (SIP) to permit any entity other than\nMac App Store to install software.\n\n\nPrerequisite: pip\n\n\nPip\n installs\nand manages software packages written in Python. If you intend to install\nwith native pip, then one of the following flavors of pip must be\ninstalled on your system:\n\n\n\n\npip\n, for Python 2.7\n\n\npip3\n, for Python 3.n.\n\n\n\n\npip\n or \npip3\n was probably installed on your system when you\ninstalled Python.  To determine whether pip or pip3 is actually\ninstalled on your system, issue one of the following commands:\n\n\n$ \npip -V\n  # for Python 2.7\n$ \npip3 -V\n # for Python 3.n \n\n\n\nWe strongly recommend pip or pip3 version 8.1 or higher in order\nto install TensorFlow.  If pip or pip3 8.1 or later is not\ninstalled, issue the following commands to install or upgrade:\n\n\n$ \nsudo easy_install --upgrade pip\n\n$ \nsudo easy_install --upgrade six\n \n\n\n\nInstall TensorFlow\n\n\nAssuming the prerequisite software is installed on your Mac,\ntake the following steps:\n\n\n\n\n\n\nInstall TensorFlow by invoking \none\n of the following commands:\n\n\n $ \npip install tensorflow\n      # Python 2.7; CPU support\n $ \npip3 install tensorflow\n     # Python 3.n; CPU support\n\n\nIf the preceding command runs to completion, you should now\n \nvalidate your installation\n.\n\n\n\n\n\n\n(Optional.) If Step 1 failed, install the latest version of TensorFlow\n     by issuing a command of the following format:\n\n\n $ \nsudo pip  install \nupgrade\n \ntfBinaryURL\n   # Python 2.7\n $ \nsudo pip3 install \nupgrade\n \ntfBinaryURL\n   # Python 3.n \n\n\nwhere \ntfBinaryURL\n identifies the URL of the TensorFlow Python\n package. The appropriate value of \ntfBinaryURL\n depends on the\n operating system and Python version. Find the appropriate\n value for \ntfBinaryURL\n\n \nhere\n.  For example, if\n you are installing TensorFlow for Mac OS and Python 2.7\n issue the following command:\n\n\n $ \nsudo pip3 install \nupgrade \\\n https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-1.3.0-py2-none-any.whl\n \n\n\nIf the preceding command fails, see\n \ninstallation problems\n.\n\n\n\n\n\n\nNext Steps\n\n\nAfter installing TensorFlow,\n\nvalidate your installation\n\nto confirm that the installation worked properly.\n\n\nUninstalling TensorFlow\n\n\nTo uninstall TensorFlow, issue one of following commands:\n\n\n$ \npip uninstall tensorflow\n\n$ \npip3 uninstall tensorflow\n \n\n\n\nInstalling with Docker\n\n\nFollow these steps to install TensorFlow through Docker.\n\n\n\n\n\n\nInstall Docker on your machine as described in the\n     \nDocker documentation\n.\n\n\n\n\n\n\nLaunch a Docker container that contains one of the TensorFlow\n     binary images.\n\n\n\n\n\n\nThe remainder of this section explains how to launch a Docker container.\n\n\nTo launch a Docker container that holds the TensorFlow binary image,\nenter a command of the following format:\n\n\n $ \ndocker run -it \n-p hostPort:containerPort\n TensorFlowImage\n \n\n\n\nwhere:\n\n\n\n\n-p hostPort:containerPort\n is optional. If you\nd like to run\n    TensorFlow programs from the shell, omit this option. If you\nd like\n    to run TensorFlow programs from Jupyter notebook,  set both\n    \nhostPort\n and \ncontainerPort\n to \n8888\n.\n    If you\nd like to run TensorBoard inside the container, add\n    a second \n-p\n flag, setting both \nhostPort\n and \ncontainerPort\n\n    to 6006.\n\n\nTensorFlowImage\n is required. It identifies the Docker container.\n    You must specify one of the following values:\n\n\ngcr.io/tensorflow/tensorflow\n: TensorFlow binary image.\n\n\ngcr.io/tensorflow/tensorflow:latest-devel\n: TensorFlow\n  Binary image plus source code.\n\n\n\n\n\n\n\n\ngcr.io\n is the Google Container Registry. Note that some\nTensorFlow images are also available at\n\ndockerhub\n.\n\n\nFor example, the following command launches a TensorFlow CPU binary image\nin a Docker container from which you can run TensorFlow programs in a shell:\n\n\n$ \ndocker run -it gcr.io/tensorflow/tensorflow bash\n\n\n\nThe following command also launches a TensorFlow CPU binary image in a\nDocker container. However, in this Docker container, you can run\nTensorFlow programs in a Jupyter notebook:\n\n\n$ \ndocker run -it -p 8888:8888 gcr.io/tensorflow/tensorflow\n\n\n\nDocker will download the TensorFlow binary image the first time you launch it.\n\n\nNext Steps\n\n\nYou should now\n\nvalidate your installation\n.\n\n\nInstalling with Anaconda\n\n\nThe Anaconda installation is community supported, not officially supported.\n\n\nTake the following steps to install TensorFlow in an Anaconda environment:\n\n\n\n\n\n\nFollow the instructions on the\n     \nAnaconda download site\n\n     to download and install Anaconda.\n\n\n\n\n\n\nCreate a conda environment named \ntensorflow\n\n     by invoking the following command:\n\n\n$ \nconda create -n tensorflow\n\n\n\n\n\n\nActivate the conda environment by issuing the following command:\n\n\n$ \nsource activate tensorflow\n\n (tensorflow)$  # Your prompt should change\n\n\n\n\n\n\nIssue a command of the following format to install\n     TensorFlow inside your conda environment:\n\n\n(tensorflow)\n$ pip install \nignore-installed \nupgrade\n \nTF_PYTHON_URL\n\n\nwhere \nTF_PYTHON_URL\n is the\n \nURL of the TensorFlow Python package\n.\n For example, the following command installs the CPU-only version of\n TensorFlow for Python 2.7:\n\n\n (tensorflow)$ \npip install \nignore-installed \nupgrade \\\n https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-1.3.0-py2-none-any.whl\n\n\n\n\n\n\n\n\nValidate your installation\n\n\nTo validate your TensorFlow installation, do the following:\n\n\n\n\nEnsure that your environment is prepared to run TensorFlow programs.\n\n\nRun a short TensorFlow program.\n\n\n\n\nPrepare your environment\n\n\nIf you installed on native pip, virtualenv, or Anaconda, then\ndo the following:\n\n\n\n\nStart a terminal.\n\n\nIf you installed with virtualenv or Anaconda, activate your container.\n\n\nIf you installed TensorFlow source code, navigate to any\n     directory \nexcept\n one containing TensorFlow source code.\n\n\n\n\nIf you installed through Docker, start a Docker container that runs bash.\nFor example:\n\n\n$ \ndocker run -it gcr.io/tensorflow/tensorflow bash\n\n\n\nRun a short TensorFlow program\n\n\nInvoke python from your shell as follows:\n\n\n$ \npython\n\n\n\nEnter the following short program inside the python interactive shell:\n\n\n# Python\nimport tensorflow as tf\nhello = tf.constant('Hello, TensorFlow!')\nsess = tf.Session()\nprint(sess.run(hello))\n\n\n\n\nIf the system outputs the following, then you are ready to begin\nwriting TensorFlow programs:\n\n\nHello, TensorFlow!\n\n\n\nIf you are new to TensorFlow, see\n@{$get_started/get_started$Getting Started with TensorFlow}.\n\n\nIf the system outputs an error message instead of a greeting, see\n\nCommon installation problems\n.\n\n\nCommon installation problems\n\n\nWe are relying on Stack Overflow to document TensorFlow installation problems\nand their remedies.  The following table contains links to Stack Overflow\nanswers for some common installation problems.\nIf you encounter an error message or other\ninstallation problem not listed in the following table, search for it\non Stack Overflow.  If Stack Overflow doesn\nt show the error message,\nask a new question about it on Stack Overflow and specify\nthe \ntensorflow\n tag.\n\n\n\n\n \nStack Overflow Link\n \nError Message\n \n\n\n\n\n  \n42006320\n\n  \nImportError: Traceback (most recent call last):\nFile \".../tensorflow/core/framework/graph_pb2.py\", line 6, in \n\nfrom google.protobuf import descriptor as _descriptor\nImportError: cannot import name 'descriptor'\n\n  \n\n\n\n\n\n\n  \n33623453\n\n  \nIOError: [Errno 2] No such file or directory:\n  '/tmp/pip-o6Tpui-build/setup.py'\n\n\n\n\n\n\n  \n35190574\n \n\n  \nSSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify\n  failed\n\n\n\n\n\n\n  \n42009190\n\n  \n\n  Installing collected packages: setuptools, protobuf, wheel, numpy, tensorflow\n  Found existing installation: setuptools 1.1.6\n  Uninstalling setuptools-1.1.6:\n  Exception:\n  ...\n  [Errno 1] Operation not permitted:\n  '/tmp/pip-a1DXRT-uninstall/.../lib/python/_markerlib' \n\n\n\n\n\n\n  \n33622019\n\n  \nImportError: No module named copyreg\n\n\n\n\n\n\n  \n37810228\n\n  \nDuring a \npip install\n operation, the system returns:\n  \nOSError: [Errno 1] Operation not permitted\n\n  \n\n\n\n\n\n\n  \n33622842\n\n  \nAn \nimport tensorflow\n statement triggers an error such as the\n  following:\nTraceback (most recent call last):\n  File \"\n\", line 1, in \n\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/__init__.py\",\n    line 4, in \n\n    from tensorflow.python import *\n    ...\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/core/framework/tensor_shape_pb2.py\",\n    line 22, in \n\n    serialized_pb=_b('\\n,tensorflow/core/framework/tensor_shape.proto\\x12\\ntensorflow\\\"d\\n\\x10TensorShapeProto\\x12-\\n\\x03\\x64im\\x18\\x02\n      \\x03(\\x0b\\x32\n      .tensorflow.TensorShapeProto.Dim\\x1a!\\n\\x03\\x44im\\x12\\x0c\\n\\x04size\\x18\\x01\n      \\x01(\\x03\\x12\\x0c\\n\\x04name\\x18\\x02 \\x01(\\tb\\x06proto3')\n  TypeError: __init__() got an unexpected keyword argument 'syntax'\n\n  \n\n\n\n\n\n\n\n  \n42075397\n\n  \nA \npip install\n command triggers the following error:\n\n...\n\nYou have not agreed to the Xcode license agreements, please run\n'xcodebuild -license' (for user-level acceptance) or\n'sudo xcodebuild -license' (for system-wide acceptance) from within a\nTerminal window to review and agree to the Xcode license agreements.\n...\n\n  File \"numpy/core/setup.py\", line 653, in get_mathlib_info\n\n    raise RuntimeError(\"Broken toolchain: cannot link a simple C program\")\n\nRuntimeError: Broken toolchain: cannot link a simple C program\n\n\n\n\n\n\n\n\n\n\n\nThe URL of the TensorFlow Python package\n\n\nA few installation mechanisms require the URL of the TensorFlow Python package.\nThe value you specify depends on three factors:\n\n\n\n\noperating system\n\n\nPython version\n\n\n\n\nThis section documents the relevant values for Mac OS installations.\n\n\nPython 2.7\n\n\n\nhttps://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-1.3.0-py2-none-any.whl\n\n\n\n\nPython 3.4, 3.5, or 3.6\n\n\n\nhttps://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-1.3.0-py3-none-any.whl\n\n\n\n\n\n\nProtobuf pip package 3.1\n\n\nYou can skip this section unless you are seeing problems related\nto the protobuf pip package.\n\n\nNOTE:\n If your TensorFlow programs are running slowly, you might\nhave a problem related to the protobuf pip package.\n\n\nThe TensorFlow pip package depends on protobuf pip package version 3.1. The\nprotobuf pip package downloaded from PyPI (when invoking\n\npip install protobuf\n) is a Python-only library containing\nPython implementations of proto serialization/deserialization that can run\n\n10x-50x slower\n than the C++ implementation. Protobuf also supports a\nbinary extension for the Python package that contains fast\nC++ based proto parsing.  This extension is not available in the\nstandard Python-only pip package.  We have created a custom binary\npip package for protobuf that contains the binary extension. To install\nthe custom binary protobuf pip package, invoke one of the following commands:\n\n\n\n\n\n\nfor Python 2.7:\n\n\n$ \npip install \nupgrade \\\nhttps://storage.googleapis.com/tensorflow/mac/cpu/protobuf-3.1.0-cp27-none-macosx_10_11_x86_64.whl\n\n\n\n\n\n\nfor Python 3.n:\n\n\n$ \npip3 install \nupgrade \\\nhttps://storage.googleapis.com/tensorflow/mac/cpu/protobuf-3.1.0-cp35-none-macosx_10_11_x86_64.whl\n\n\n\n\n\n\nInstalling this protobuf package will overwrite the existing protobuf package.\nNote that the binary pip package already has support for protobufs\nlarger than 64MB, which should fix errors such as these:\n\n\n[libprotobuf ERROR google/protobuf/src/google/protobuf/io/coded_stream.cc:207]\nA protocol message was rejected because it was too big (more than 67108864 bytes).\nTo increase the limit (or to disable these warnings), see\nCodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.", 
            "title": "1.3 \u5728Mac OS X\u4e0a\u5b89\u88c5TensorFlow"
        }, 
        {
            "location": "/install/install_mac/#installing-tensorflow-on-mac-os-x", 
            "text": "This guide explains how to install TensorFlow on Mac OS X.  Note: As of version 1.2, TensorFlow no longer provides GPU support on Mac OS X.", 
            "title": "Installing TensorFlow on Mac OS X"
        }, 
        {
            "location": "/install/install_mac/#determine-how-to-install-tensorflow", 
            "text": "You must pick the mechanism by which you install TensorFlow. The supported choices are as follows:   virtualenv  native  pip  Docker  installing from sources, which is documented in\n     a separate guide .   We recommend the virtualenv installation.  Virtualenv \nis a virtual Python environment isolated from other Python development,\nincapable of interfering with or being affected by other Python programs\non the same machine.  During the virtualenv installation process,\nyou will install not only TensorFlow but also all the packages that\nTensorFlow requires.  (This is actually pretty easy.)\nTo start working with TensorFlow, you simply need to  activate  the\nvirtual environment.  All in all, virtualenv provides a safe and\nreliable mechanism for installing and running TensorFlow.  Native pip installs TensorFlow directly on your system without going through\nany container or virtual environment system. Since a native pip installation\nis not walled-off, the pip installation might interfere with or be influenced\nby other Python-based installations on your system. Furthermore, you might need\nto disable System Integrity Protection (SIP) in order to install through native\npip.  However, if you understand SIP, pip, and your Python environment, a\nnative pip installation is relatively easy to perform.  Docker  completely isolates the TensorFlow installation\nfrom pre-existing packages on your machine. The Docker container contains\nTensorFlow and all its dependencies. Note that the Docker image can be quite\nlarge (hundreds of MBs). You might choose the Docker installation if you are\nincorporating TensorFlow into a larger application architecture that\nalready uses Docker.  In Anaconda, you may use conda to create a virtual environment.\nHowever, within Anaconda, we recommend installing TensorFlow with the pip install  command, not with the  conda install  command.  NOTE:  The conda package is community supported, not officially supported.\nThat is, the TensorFlow team neither tests nor maintains the conda package.\nUse that package at your own risk.", 
            "title": "Determine how to install TensorFlow"
        }, 
        {
            "location": "/install/install_mac/#installing-with-virtualenv", 
            "text": "Take the following steps to install TensorFlow with Virtualenv:    Start a terminal (a shell). You ll perform all subsequent steps\n     in this shell.    Install pip and virtualenv by issuing the following commands:   $  sudo easy_install pip \n $  sudo pip install  upgrade virtualenv      Create a virtualenv environment by issuing a command of one\n     of the following formats:   $  virtualenv  system-site-packages   targetDirectory  # for Python 2.7\n $  virtualenv  system-site-packages -p python3   targetDirectory  # for Python 3.n\n   where  targetDirectory  identifies the top of the virtualenv tree.\n Our instructions assume that  targetDirectory \n is  ~/tensorflow , but you may choose any directory.    Activate the virtualenv environment by issuing one of the\n     following commands:  $  source ~/tensorflow/bin/activate       # If using bash, sh, ksh, or zsh\n$  source ~/tensorflow/bin/activate.csh   # If using csh or tcsh   The preceding  source  command should change your prompt to the following:   (tensorflow)$     Ensure pip \u22658.1 is installed:   (tensorflow)$  easy_install -U pip    Issue one of the following commands to install TensorFlow and all the\n     packages that TensorFlow requires into the active Virtualenv environment:   (tensorflow)$  pip install  upgrade tensorflow       # for Python 2.7\n (tensorflow)$  pip3 install  upgrade tensorflow      # for Python 3.n    Optional. If Step 6 failed (typically because you invoked a pip version\n     lower than 8.1), install TensorFlow in the active\n     virtualenv environment by issuing a command of the following format:   $  pip install  upgrade   tfBinaryURL    # Python 2.7\n $  pip3 install  upgrade   tfBinaryURL   # Python 3.n   where  tfBinaryURL  identifies the URL\n of the TensorFlow Python package. The appropriate value of\n  tfBinaryURL  depends on the operating system and\n Python version. Find the appropriate value for\n  tfBinaryURL  for your system\n  here .\n For example, if you are installing TensorFlow for Mac OS X,\n Python 2.7, the command to install\n TensorFlow in the active Virtualenv is as follows:   $  pip3 install  upgrade \\\n https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-1.3.0-py2-none-any.whl    If you encounter installation problems, see Common Installation Problems .", 
            "title": "Installing with virtualenv"
        }, 
        {
            "location": "/install/install_mac/#next-steps", 
            "text": "After installing TensorFlow, validate your installation \nto confirm that the installation worked properly.  Note that you must activate the virtualenv environment each time you\nuse TensorFlow in a new shell.  If the virtualenv environment is not\ncurrently active (that is, the prompt is not  (tensorflow) , invoke\none of the following commands:  $  source ~/tensorflow/bin/activate       # bash, sh, ksh, or zsh\n$  source ~/tensorflow/bin/activate.csh   # csh or tcsh   Your prompt will transform to the following to indicate that your\ntensorflow environment is active:   (tensorflow)$   When the virtualenv environment is active, you may run\nTensorFlow programs from this shell.  When you are done using TensorFlow, you may deactivate the\nenvironment by issuing the following command:   (tensorflow)$  deactivate    The prompt will revert back to your default prompt (as defined by  PS1 ).", 
            "title": "Next Steps"
        }, 
        {
            "location": "/install/install_mac/#uninstalling-tensorflow", 
            "text": "If you want to uninstall TensorFlow, simply remove the tree you created. For example:   $  rm -r ~/tensorflow", 
            "title": "Uninstalling TensorFlow"
        }, 
        {
            "location": "/install/install_mac/#installing-with-native-pip", 
            "text": "We have uploaded the TensorFlow binaries to PyPI.\nTherefore, you can install TensorFlow through pip.  The REQUIRED_PACKAGES section of setup.py \nlists the packages that pip will install or upgrade.", 
            "title": "Installing with native pip"
        }, 
        {
            "location": "/install/install_mac/#prerequisite-python", 
            "text": "In order to install TensorFlow, your system must contain one of the following Python versions:   Python 2.7  Python 3.3+   If your system does not already have one of the preceding Python versions, install  it now.  When installing Python, you might need to disable\nSystem Integrity Protection (SIP) to permit any entity other than\nMac App Store to install software.", 
            "title": "Prerequisite: Python"
        }, 
        {
            "location": "/install/install_mac/#prerequisite-pip", 
            "text": "Pip  installs\nand manages software packages written in Python. If you intend to install\nwith native pip, then one of the following flavors of pip must be\ninstalled on your system:   pip , for Python 2.7  pip3 , for Python 3.n.   pip  or  pip3  was probably installed on your system when you\ninstalled Python.  To determine whether pip or pip3 is actually\ninstalled on your system, issue one of the following commands:  $  pip -V   # for Python 2.7\n$  pip3 -V  # for Python 3.n   We strongly recommend pip or pip3 version 8.1 or higher in order\nto install TensorFlow.  If pip or pip3 8.1 or later is not\ninstalled, issue the following commands to install or upgrade:  $  sudo easy_install --upgrade pip \n$  sudo easy_install --upgrade six", 
            "title": "Prerequisite: pip"
        }, 
        {
            "location": "/install/install_mac/#install-tensorflow", 
            "text": "Assuming the prerequisite software is installed on your Mac,\ntake the following steps:    Install TensorFlow by invoking  one  of the following commands:   $  pip install tensorflow       # Python 2.7; CPU support\n $  pip3 install tensorflow      # Python 3.n; CPU support  If the preceding command runs to completion, you should now\n  validate your installation .    (Optional.) If Step 1 failed, install the latest version of TensorFlow\n     by issuing a command of the following format:   $  sudo pip  install  upgrade   tfBinaryURL    # Python 2.7\n $  sudo pip3 install  upgrade   tfBinaryURL    # Python 3.n   where  tfBinaryURL  identifies the URL of the TensorFlow Python\n package. The appropriate value of  tfBinaryURL  depends on the\n operating system and Python version. Find the appropriate\n value for  tfBinaryURL \n  here .  For example, if\n you are installing TensorFlow for Mac OS and Python 2.7\n issue the following command:   $  sudo pip3 install  upgrade \\\n https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-1.3.0-py2-none-any.whl    If the preceding command fails, see\n  installation problems .", 
            "title": "Install TensorFlow"
        }, 
        {
            "location": "/install/install_mac/#next-steps_1", 
            "text": "After installing TensorFlow, validate your installation \nto confirm that the installation worked properly.", 
            "title": "Next Steps"
        }, 
        {
            "location": "/install/install_mac/#uninstalling-tensorflow_1", 
            "text": "To uninstall TensorFlow, issue one of following commands:  $  pip uninstall tensorflow \n$  pip3 uninstall tensorflow", 
            "title": "Uninstalling TensorFlow"
        }, 
        {
            "location": "/install/install_mac/#installing-with-docker", 
            "text": "Follow these steps to install TensorFlow through Docker.    Install Docker on your machine as described in the\n      Docker documentation .    Launch a Docker container that contains one of the TensorFlow\n     binary images.    The remainder of this section explains how to launch a Docker container.  To launch a Docker container that holds the TensorFlow binary image,\nenter a command of the following format:   $  docker run -it  -p hostPort:containerPort  TensorFlowImage    where:   -p hostPort:containerPort  is optional. If you d like to run\n    TensorFlow programs from the shell, omit this option. If you d like\n    to run TensorFlow programs from Jupyter notebook,  set both\n     hostPort  and  containerPort  to  8888 .\n    If you d like to run TensorBoard inside the container, add\n    a second  -p  flag, setting both  hostPort  and  containerPort \n    to 6006.  TensorFlowImage  is required. It identifies the Docker container.\n    You must specify one of the following values:  gcr.io/tensorflow/tensorflow : TensorFlow binary image.  gcr.io/tensorflow/tensorflow:latest-devel : TensorFlow\n  Binary image plus source code.     gcr.io  is the Google Container Registry. Note that some\nTensorFlow images are also available at dockerhub .  For example, the following command launches a TensorFlow CPU binary image\nin a Docker container from which you can run TensorFlow programs in a shell:  $  docker run -it gcr.io/tensorflow/tensorflow bash  The following command also launches a TensorFlow CPU binary image in a\nDocker container. However, in this Docker container, you can run\nTensorFlow programs in a Jupyter notebook:  $  docker run -it -p 8888:8888 gcr.io/tensorflow/tensorflow  Docker will download the TensorFlow binary image the first time you launch it.", 
            "title": "Installing with Docker"
        }, 
        {
            "location": "/install/install_mac/#next-steps_2", 
            "text": "You should now validate your installation .", 
            "title": "Next Steps"
        }, 
        {
            "location": "/install/install_mac/#installing-with-anaconda", 
            "text": "The Anaconda installation is community supported, not officially supported.  Take the following steps to install TensorFlow in an Anaconda environment:    Follow the instructions on the\n      Anaconda download site \n     to download and install Anaconda.    Create a conda environment named  tensorflow \n     by invoking the following command:  $  conda create -n tensorflow    Activate the conda environment by issuing the following command:  $  source activate tensorflow \n (tensorflow)$  # Your prompt should change    Issue a command of the following format to install\n     TensorFlow inside your conda environment:  (tensorflow) $ pip install  ignore-installed  upgrade   TF_PYTHON_URL  where  TF_PYTHON_URL  is the\n  URL of the TensorFlow Python package .\n For example, the following command installs the CPU-only version of\n TensorFlow for Python 2.7:   (tensorflow)$  pip install  ignore-installed  upgrade \\\n https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-1.3.0-py2-none-any.whl", 
            "title": "Installing with Anaconda"
        }, 
        {
            "location": "/install/install_mac/#validate-your-installation", 
            "text": "To validate your TensorFlow installation, do the following:   Ensure that your environment is prepared to run TensorFlow programs.  Run a short TensorFlow program.", 
            "title": "Validate your installation"
        }, 
        {
            "location": "/install/install_mac/#prepare-your-environment", 
            "text": "If you installed on native pip, virtualenv, or Anaconda, then\ndo the following:   Start a terminal.  If you installed with virtualenv or Anaconda, activate your container.  If you installed TensorFlow source code, navigate to any\n     directory  except  one containing TensorFlow source code.   If you installed through Docker, start a Docker container that runs bash.\nFor example:  $  docker run -it gcr.io/tensorflow/tensorflow bash", 
            "title": "Prepare your environment"
        }, 
        {
            "location": "/install/install_mac/#run-a-short-tensorflow-program", 
            "text": "Invoke python from your shell as follows:  $  python  Enter the following short program inside the python interactive shell:  # Python\nimport tensorflow as tf\nhello = tf.constant('Hello, TensorFlow!')\nsess = tf.Session()\nprint(sess.run(hello))  If the system outputs the following, then you are ready to begin\nwriting TensorFlow programs:  Hello, TensorFlow!  If you are new to TensorFlow, see\n@{$get_started/get_started$Getting Started with TensorFlow}.  If the system outputs an error message instead of a greeting, see Common installation problems .", 
            "title": "Run a short TensorFlow program"
        }, 
        {
            "location": "/install/install_mac/#common-installation-problems", 
            "text": "We are relying on Stack Overflow to document TensorFlow installation problems\nand their remedies.  The following table contains links to Stack Overflow\nanswers for some common installation problems.\nIf you encounter an error message or other\ninstallation problem not listed in the following table, search for it\non Stack Overflow.  If Stack Overflow doesn t show the error message,\nask a new question about it on Stack Overflow and specify\nthe  tensorflow  tag.     Stack Overflow Link   Error Message    \n   42006320 \n   ImportError: Traceback (most recent call last):\nFile \".../tensorflow/core/framework/graph_pb2.py\", line 6, in  \nfrom google.protobuf import descriptor as _descriptor\nImportError: cannot import name 'descriptor' \n     \n   33623453 \n   IOError: [Errno 2] No such file or directory:\n  '/tmp/pip-o6Tpui-build/setup.py'   \n   35190574   \n   SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify\n  failed   \n   42009190 \n   \n  Installing collected packages: setuptools, protobuf, wheel, numpy, tensorflow\n  Found existing installation: setuptools 1.1.6\n  Uninstalling setuptools-1.1.6:\n  Exception:\n  ...\n  [Errno 1] Operation not permitted:\n  '/tmp/pip-a1DXRT-uninstall/.../lib/python/_markerlib'    \n   33622019 \n   ImportError: No module named copyreg   \n   37810228 \n   During a  pip install  operation, the system returns:\n   OSError: [Errno 1] Operation not permitted \n     \n   33622842 \n   An  import tensorflow  statement triggers an error such as the\n  following: Traceback (most recent call last):\n  File \" \", line 1, in  \n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/__init__.py\",\n    line 4, in  \n    from tensorflow.python import *\n    ...\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/core/framework/tensor_shape_pb2.py\",\n    line 22, in  \n    serialized_pb=_b('\\n,tensorflow/core/framework/tensor_shape.proto\\x12\\ntensorflow\\\"d\\n\\x10TensorShapeProto\\x12-\\n\\x03\\x64im\\x18\\x02\n      \\x03(\\x0b\\x32\n      .tensorflow.TensorShapeProto.Dim\\x1a!\\n\\x03\\x44im\\x12\\x0c\\n\\x04size\\x18\\x01\n      \\x01(\\x03\\x12\\x0c\\n\\x04name\\x18\\x02 \\x01(\\tb\\x06proto3')\n  TypeError: __init__() got an unexpected keyword argument 'syntax' \n     \n   42075397 \n   A  pip install  command triggers the following error: ... \nYou have not agreed to the Xcode license agreements, please run\n'xcodebuild -license' (for user-level acceptance) or\n'sudo xcodebuild -license' (for system-wide acceptance) from within a\nTerminal window to review and agree to the Xcode license agreements.\n... \n  File \"numpy/core/setup.py\", line 653, in get_mathlib_info\n\n    raise RuntimeError(\"Broken toolchain: cannot link a simple C program\")\n\nRuntimeError: Broken toolchain: cannot link a simple C program", 
            "title": "Common installation problems"
        }, 
        {
            "location": "/install/install_mac/#the-url-of-the-tensorflow-python-package", 
            "text": "A few installation mechanisms require the URL of the TensorFlow Python package.\nThe value you specify depends on three factors:   operating system  Python version   This section documents the relevant values for Mac OS installations.", 
            "title": "The URL of the TensorFlow Python package"
        }, 
        {
            "location": "/install/install_mac/#python-27", 
            "text": "https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-1.3.0-py2-none-any.whl", 
            "title": "Python 2.7"
        }, 
        {
            "location": "/install/install_mac/#python-34-35-or-36", 
            "text": "https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-1.3.0-py3-none-any.whl", 
            "title": "Python 3.4, 3.5, or 3.6"
        }, 
        {
            "location": "/install/install_mac/#protobuf-pip-package-31", 
            "text": "You can skip this section unless you are seeing problems related\nto the protobuf pip package.  NOTE:  If your TensorFlow programs are running slowly, you might\nhave a problem related to the protobuf pip package.  The TensorFlow pip package depends on protobuf pip package version 3.1. The\nprotobuf pip package downloaded from PyPI (when invoking pip install protobuf ) is a Python-only library containing\nPython implementations of proto serialization/deserialization that can run 10x-50x slower  than the C++ implementation. Protobuf also supports a\nbinary extension for the Python package that contains fast\nC++ based proto parsing.  This extension is not available in the\nstandard Python-only pip package.  We have created a custom binary\npip package for protobuf that contains the binary extension. To install\nthe custom binary protobuf pip package, invoke one of the following commands:    for Python 2.7:  $  pip install  upgrade \\\nhttps://storage.googleapis.com/tensorflow/mac/cpu/protobuf-3.1.0-cp27-none-macosx_10_11_x86_64.whl    for Python 3.n:  $  pip3 install  upgrade \\\nhttps://storage.googleapis.com/tensorflow/mac/cpu/protobuf-3.1.0-cp35-none-macosx_10_11_x86_64.whl    Installing this protobuf package will overwrite the existing protobuf package.\nNote that the binary pip package already has support for protobufs\nlarger than 64MB, which should fix errors such as these:  [libprotobuf ERROR google/protobuf/src/google/protobuf/io/coded_stream.cc:207]\nA protocol message was rejected because it was too big (more than 67108864 bytes).\nTo increase the limit (or to disable these warnings), see\nCodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.", 
            "title": "Protobuf pip package 3.1"
        }, 
        {
            "location": "/install/install_windows/", 
            "text": "Installing TensorFlow on Windows\n\n\nThis guide explains how to install TensorFlow on Windows.\n\n\nDetermine which TensorFlow to install\n\n\nYou must choose one of the following types of TensorFlow to install:\n\n\n\n\nTensorFlow with CPU support only\n. If your system does not have a\n    NVIDIA\u00ae GPU, you must install this version. Note that this version of\n    TensorFlow is typically much easier to install (typically,\n    in 5 or 10 minutes), so even if you have an NVIDIA GPU, we recommend\n    installing this version first.\n\n\nTensorFlow with GPU support\n. TensorFlow programs typically run\n    significantly faster on a GPU than on a CPU. Therefore, if your\n    system has a NVIDIA\u00ae GPU meeting the prerequisites shown below\n    and you need to run performance-critical applications, you should\n    ultimately install this version.\n\n\n\n\nRequirements to run TensorFlow with GPU support\n\n\nIf you are installing TensorFlow with GPU support using one of the mechanisms\ndescribed in this guide, then the following NVIDIA software must be\ninstalled on your system:\n\n\n\n\nCUDA\u00ae Toolkit 8.0. For details, see\n    \nNVIDIA\ns\n    documentation\n\n    Ensure that you append the relevant Cuda pathnames to the \n%PATH%\n\n    environment variable as described in the NVIDIA documentation.\n\n\nThe NVIDIA drivers associated with CUDA Toolkit 8.0.\n\n\ncuDNN v5.1. For details, see\n    \nNVIDIA\ns documentation\n.\n    Note that cuDNN is typically installed in a different location from the\n    other CUDA DLLs. Ensure that you add the directory where you installed\n    the cuDNN DLL to your \n%PATH%\n environment variable.\n\n\nGPU card with CUDA Compute Capability 3.0 or higher.  See\n    \nNVIDIA documentation\n for a\n    list of supported GPU cards.\n\n\n\n\nIf you have a different version of one of the preceding packages, please\nchange to the specified versions.  In particular, the cuDNN version\nmust match exactly: TensorFlow will not load if it cannot find \ncuDNN64_5.dll\n.\nTo use a different version of cuDNN, you must build from source.\n\n\nDetermine how to install TensorFlow\n\n\nYou must pick the mechanism by which you install TensorFlow. The\nsupported choices are as follows:\n\n\n\n\nnative\n pip\n\n\nAnaconda\n\n\n\n\nNative pip installs TensorFlow directly on your system without going\nthrough a virtual environment.  Since a native pip installation is not\nwalled-off in a separate container, the pip installation might interfere\nwith other Python-based installations on your system. However, if you\nunderstand pip and your Python environment, a native pip installation\noften entails only a single command! Furthermore, if you install with\nnative pip, users can run TensorFlow programs from any directory on\nthe system.\n\n\nIn Anaconda, you may use conda to create a virtual environment.\nHowever, within Anaconda, we recommend installing TensorFlow with the\n\npip install\n command, not with the \nconda install\n command.\n\n\nNOTE:\n The conda package is community supported, not officially supported.\nThat is, the TensorFlow team neither tests nor maintains this conda package.\nUse that package at your own risk.\n\n\nInstalling with native pip\n\n\nIf the following version of Python is not installed on your machine,\ninstall it now:\n\n\n\n\nPython 3.5.x 64-bit from python.org\n\n\n\n\nTensorFlow only supports version 3.5.x of Python on Windows.\nNote that Python 3.5.x comes with the pip3 package manager, which is the\nprogram you\nll use to install TensorFlow.\n\n\nTo install TensorFlow, start a terminal. Then issue the appropriate\n\npip3 install\n command in that terminal.  To install the CPU-only\nversion of TensorFlow, enter the following command:\n\n\nC:\\> \npip3 install --upgrade tensorflow\n\n\n\nTo install the GPU version of TensorFlow, enter the following command:\n\n\nC:\\> \npip3 install --upgrade tensorflow-gpu\n\n\n\nInstalling with Anaconda\n\n\nThe Anaconda installation is community supported, not officially supported.\n\n\nTake the following steps to install TensorFlow in an Anaconda environment:\n\n\n\n\n\n\nFollow the instructions on the\n     \nAnaconda download site\n\n     to download and install Anaconda.\n\n\n\n\n\n\nCreate a conda environment named \ntensorflow\n\n     by invoking the following command:\n\n\nC:> \nconda create -n tensorflow python=3.5\n \n\n\n\n\n\n\nActivate the conda environment by issuing the following command:\n\n\nC:> \nactivate tensorflow\n\n (tensorflow)C:>  # Your prompt should change \n\n\n\n\n\n\nIssue the appropriate command to install TensorFlow inside your conda\n     environment. To install the CPU-only version of TensorFlow, enter the\n     following command:\n\n\n(tensorflow)C:> \npip install \nignore-installed \nupgrade https://storage.googleapis.com/tensorflow/windows/cpu/tensorflow-1.3.0-cp35-cp35m-win_amd64.whl\n \n\n\nTo install the GPU version of TensorFlow, enter the following command\n (on a single line):\n\n\n(tensorflow)C:> \npip install \nignore-installed \nupgrade https://storage.googleapis.com/tensorflow/windows/gpu/tensorflow_gpu-1.3.0-cp35-cp35m-win_amd64.whl\n \n\n\n\n\n\n\nValidate your installation\n\n\nStart a terminal.\n\n\nIf you installed through Anaconda, activate your Anaconda environment.\n\n\nInvoke python from your shell as follows:\n\n\n$ \npython\n\n\n\nEnter the following short program inside the python interactive shell:\n\n\n import tensorflow as tf\n\n hello = tf.constant('Hello, TensorFlow!')\n\n sess = tf.Session()\n\n print(sess.run(hello))\n\n\n\n\nIf the system outputs the following, then you are ready to begin writing\nTensorFlow programs:\n\n\nHello, TensorFlow!\n\n\n\nIf you are new to TensorFlow, see @{$get_started/get_started$Getting Started with\nTensorFlow}.\n\n\nIf the system outputs an error message instead of a greeting, see \nCommon\ninstallation problems\n.\n\n\nCommon installation problems\n\n\nWe are relying on Stack Overflow to document TensorFlow installation problems\nand their remedies.  The following table contains links to Stack Overflow\nanswers for some common installation problems.\nIf you encounter an error message or other\ninstallation problem not listed in the following table, search for it\non Stack Overflow.  If Stack Overflow doesn\nt show the error message,\nask a new question about it on Stack Overflow and specify\nthe \ntensorflow\n tag.\n\n\n\n\n \nStack Overflow Link\n \nError Message\n \n\n\n\n\n  \n41007279\n\n  \n\n  \n[...\\stream_executor\\dso_loader.cc] Couldn't open CUDA library nvcuda.dll\n\n  \n\n\n\n\n\n\n  \n41007279\n\n  \n\n  \n[...\\stream_executor\\cuda\\cuda_dnn.cc] Unable to load cuDNN DSO\n\n  \n\n\n\n\n\n\n  \n42006320\n\n  \nImportError: Traceback (most recent call last):\nFile \"...\\tensorflow\\core\\framework\\graph_pb2.py\", line 6, in \n\nfrom google.protobuf import descriptor as _descriptor\nImportError: cannot import name 'descriptor'\n\n  \n\n\n\n\n\n\n  \n42011070\n\n  \nNo module named \"pywrap_tensorflow\"\n\n\n\n\n\n\n  \n42217532\n\n  \n\n  \nOpKernel ('op: \"BestSplits\" device_type: \"CPU\"') for unknown op: BestSplits\n\n  \n\n\n\n\n\n\n  \n43134753\n\n  \n\n  \nThe TensorFlow library wasn't compiled to use SSE instructions", 
            "title": "1.4 \u5728Windows\u4e0a\u5b89\u88c5TensorFlow"
        }, 
        {
            "location": "/install/install_windows/#installing-tensorflow-on-windows", 
            "text": "This guide explains how to install TensorFlow on Windows.", 
            "title": "Installing TensorFlow on Windows"
        }, 
        {
            "location": "/install/install_windows/#determine-which-tensorflow-to-install", 
            "text": "You must choose one of the following types of TensorFlow to install:   TensorFlow with CPU support only . If your system does not have a\n    NVIDIA\u00ae GPU, you must install this version. Note that this version of\n    TensorFlow is typically much easier to install (typically,\n    in 5 or 10 minutes), so even if you have an NVIDIA GPU, we recommend\n    installing this version first.  TensorFlow with GPU support . TensorFlow programs typically run\n    significantly faster on a GPU than on a CPU. Therefore, if your\n    system has a NVIDIA\u00ae GPU meeting the prerequisites shown below\n    and you need to run performance-critical applications, you should\n    ultimately install this version.", 
            "title": "Determine which TensorFlow to install"
        }, 
        {
            "location": "/install/install_windows/#requirements-to-run-tensorflow-with-gpu-support", 
            "text": "If you are installing TensorFlow with GPU support using one of the mechanisms\ndescribed in this guide, then the following NVIDIA software must be\ninstalled on your system:   CUDA\u00ae Toolkit 8.0. For details, see\n     NVIDIA s\n    documentation \n    Ensure that you append the relevant Cuda pathnames to the  %PATH% \n    environment variable as described in the NVIDIA documentation.  The NVIDIA drivers associated with CUDA Toolkit 8.0.  cuDNN v5.1. For details, see\n     NVIDIA s documentation .\n    Note that cuDNN is typically installed in a different location from the\n    other CUDA DLLs. Ensure that you add the directory where you installed\n    the cuDNN DLL to your  %PATH%  environment variable.  GPU card with CUDA Compute Capability 3.0 or higher.  See\n     NVIDIA documentation  for a\n    list of supported GPU cards.   If you have a different version of one of the preceding packages, please\nchange to the specified versions.  In particular, the cuDNN version\nmust match exactly: TensorFlow will not load if it cannot find  cuDNN64_5.dll .\nTo use a different version of cuDNN, you must build from source.", 
            "title": "Requirements to run TensorFlow with GPU support"
        }, 
        {
            "location": "/install/install_windows/#determine-how-to-install-tensorflow", 
            "text": "You must pick the mechanism by which you install TensorFlow. The\nsupported choices are as follows:   native  pip  Anaconda   Native pip installs TensorFlow directly on your system without going\nthrough a virtual environment.  Since a native pip installation is not\nwalled-off in a separate container, the pip installation might interfere\nwith other Python-based installations on your system. However, if you\nunderstand pip and your Python environment, a native pip installation\noften entails only a single command! Furthermore, if you install with\nnative pip, users can run TensorFlow programs from any directory on\nthe system.  In Anaconda, you may use conda to create a virtual environment.\nHowever, within Anaconda, we recommend installing TensorFlow with the pip install  command, not with the  conda install  command.  NOTE:  The conda package is community supported, not officially supported.\nThat is, the TensorFlow team neither tests nor maintains this conda package.\nUse that package at your own risk.", 
            "title": "Determine how to install TensorFlow"
        }, 
        {
            "location": "/install/install_windows/#installing-with-native-pip", 
            "text": "If the following version of Python is not installed on your machine,\ninstall it now:   Python 3.5.x 64-bit from python.org   TensorFlow only supports version 3.5.x of Python on Windows.\nNote that Python 3.5.x comes with the pip3 package manager, which is the\nprogram you ll use to install TensorFlow.  To install TensorFlow, start a terminal. Then issue the appropriate pip3 install  command in that terminal.  To install the CPU-only\nversion of TensorFlow, enter the following command:  C:\\>  pip3 install --upgrade tensorflow  To install the GPU version of TensorFlow, enter the following command:  C:\\>  pip3 install --upgrade tensorflow-gpu", 
            "title": "Installing with native pip"
        }, 
        {
            "location": "/install/install_windows/#installing-with-anaconda", 
            "text": "The Anaconda installation is community supported, not officially supported.  Take the following steps to install TensorFlow in an Anaconda environment:    Follow the instructions on the\n      Anaconda download site \n     to download and install Anaconda.    Create a conda environment named  tensorflow \n     by invoking the following command:  C:>  conda create -n tensorflow python=3.5      Activate the conda environment by issuing the following command:  C:>  activate tensorflow \n (tensorflow)C:>  # Your prompt should change     Issue the appropriate command to install TensorFlow inside your conda\n     environment. To install the CPU-only version of TensorFlow, enter the\n     following command:  (tensorflow)C:>  pip install  ignore-installed  upgrade https://storage.googleapis.com/tensorflow/windows/cpu/tensorflow-1.3.0-cp35-cp35m-win_amd64.whl    To install the GPU version of TensorFlow, enter the following command\n (on a single line):  (tensorflow)C:>  pip install  ignore-installed  upgrade https://storage.googleapis.com/tensorflow/windows/gpu/tensorflow_gpu-1.3.0-cp35-cp35m-win_amd64.whl", 
            "title": "Installing with Anaconda"
        }, 
        {
            "location": "/install/install_windows/#validate-your-installation", 
            "text": "Start a terminal.  If you installed through Anaconda, activate your Anaconda environment.  Invoke python from your shell as follows:  $  python  Enter the following short program inside the python interactive shell:   import tensorflow as tf  hello = tf.constant('Hello, TensorFlow!')  sess = tf.Session()  print(sess.run(hello))  If the system outputs the following, then you are ready to begin writing\nTensorFlow programs:  Hello, TensorFlow!  If you are new to TensorFlow, see @{$get_started/get_started$Getting Started with\nTensorFlow}.  If the system outputs an error message instead of a greeting, see  Common\ninstallation problems .", 
            "title": "Validate your installation"
        }, 
        {
            "location": "/install/install_windows/#common-installation-problems", 
            "text": "We are relying on Stack Overflow to document TensorFlow installation problems\nand their remedies.  The following table contains links to Stack Overflow\nanswers for some common installation problems.\nIf you encounter an error message or other\ninstallation problem not listed in the following table, search for it\non Stack Overflow.  If Stack Overflow doesn t show the error message,\nask a new question about it on Stack Overflow and specify\nthe  tensorflow  tag.     Stack Overflow Link   Error Message    \n   41007279 \n   \n   [...\\stream_executor\\dso_loader.cc] Couldn't open CUDA library nvcuda.dll \n     \n   41007279 \n   \n   [...\\stream_executor\\cuda\\cuda_dnn.cc] Unable to load cuDNN DSO \n     \n   42006320 \n   ImportError: Traceback (most recent call last):\nFile \"...\\tensorflow\\core\\framework\\graph_pb2.py\", line 6, in  \nfrom google.protobuf import descriptor as _descriptor\nImportError: cannot import name 'descriptor' \n     \n   42011070 \n   No module named \"pywrap_tensorflow\"   \n   42217532 \n   \n   OpKernel ('op: \"BestSplits\" device_type: \"CPU\"') for unknown op: BestSplits \n     \n   43134753 \n   \n   The TensorFlow library wasn't compiled to use SSE instructions", 
            "title": "Common installation problems"
        }, 
        {
            "location": "/install/install_sources/", 
            "text": "Installing TensorFlow from Sources\n\n\nThis guide explains how to build TensorFlow sources into a TensorFlow\nbinary and how to install that TensorFlow binary.  Note that we provide\nwell-tested, pre-built TensorFlow binaries for Linux, Mac, and Windows\nsystems. In addition, there are pre-built TensorFlow\n\ndocker images\n.\nSo, don\nt build a TensorFlow binary yourself unless you are very\ncomfortable building complex packages from source and dealing with\nthe inevitable aftermath should things not go exactly as documented.\n\n\nIf the last paragraph didn\nt scare you off, welcome.  This guide explains\nhow to build TensorFlow on the following operating systems:\n\n\n\n\nUbuntu\n\n\nMac OS X\n\n\n\n\nWe don\nt officially support building TensorFlow on Windows; however, you may try\nto build TensorFlow on Windows if you don\nt mind using the highly experimental\n\nBazel on Windows\n\nor\n\nTensorFlow CMake build\n.\n\n\nDetermine which TensorFlow to install\n\n\nYou must choose one of the following types of TensorFlow to build and\ninstall:\n\n\n\n\nTensorFlow with CPU support only\n. If your system does not have a\n  NVIDIA\u00ae GPU, build and install this version. Note that this version of\n  TensorFlow is typically easier to build and install, so even if you\n  have an NVIDIA GPU, we recommend building and installing this version\n  first.\n\n\n\n\nTensorFlow with GPU support\n. TensorFlow programs typically run\n  significantly faster on a GPU than on a CPU. Therefore, if your system\n  has a NVIDIA GPU and you need to run performance-critical applications,\n  you should ultimately build and install this version.\n  Beyond the NVIDIA GPU itself, your system must also fulfill the NVIDIA\n  software requirements described in one of the following documents:\n\n\n\n\n\n\n@{$install_linux#NVIDIARequirements$Installing TensorFlow on Ubuntu}\n\n\n\n\n@{$install_mac#NVIDIARequirements$Installing TensorFlow on Mac OS}\n\n\n\n\nClone the TensorFlow repository\n\n\nStart the process of building TensorFlow by cloning a TensorFlow\nrepository.\n\n\nTo clone \nthe latest\n TensorFlow repository, issue the following command:\n\n\n$ \ngit clone https://github.com/tensorflow/tensorflow\n \n\n\n\nThe preceding \ngit clone\n command creates a subdirectory\nnamed \ntensorflow\n.  After cloning, you may optionally build a\n\nspecific branch\n (such as a release branch) by invoking the\nfollowing commands:\n\n\n\n$ \ncd tensorflow\n\n$ \ngit checkout\n \nBranch\n # where \nBranch\n is the desired branch\n\n\n\n\nFor example, to work with the \nr1.0\n release instead of the master release,\nissue the following command:\n\n\n$ \ngit checkout r1.0\n\n\n\nNext, you must prepare your environment for\n\nLinux\n\nor\n\nMac OS\n\n\n\n\nPrepare environment for Linux\n\n\nBefore building TensorFlow on Linux, install the following build\ntools on your system:\n\n\n\n\nbazel\n\n\nTensorFlow Python dependencies\n\n\noptionally, NVIDIA packages to support TensorFlow for GPU.\n\n\n\n\nInstall Bazel\n\n\nIf bazel is not installed on your system, install it now by following\n\nthese directions\n.\n\n\nInstall TensorFlow Python dependencies\n\n\nTo install TensorFlow, you must install the following packages:\n\n\n\n\nnumpy\n, which is a numerical processing package that TensorFlow requires.\n\n\ndev\n, which enables adding extensions to Python.\n\n\npip\n, which enables you to install and manage certain Python packages.\n\n\nwheel\n, which enables you to manage Python compressed packages in\n    the wheel (.whl) format.\n\n\n\n\nTo install these packages for Python 2.7, issue the following command:\n\n\n\n$ \nsudo apt-get install python-numpy python-dev python-pip python-wheel\n\n\n\n\n\nTo install these packages for Python 3.n, issue the following command:\n\n\n\n$ \nsudo apt-get install python3-numpy python3-dev python3-pip python3-wheel\n\n\n\n\n\nOptional: install TensorFlow for GPU prerequisites\n\n\nIf you are building TensorFlow without GPU support, skip this section.\n\n\nThe following NVIDIA \nhardware\n must be installed on your system:\n\n\n\n\nGPU card with CUDA Compute Capability 3.0 or higher.  See\n    \nNVIDIA documentation\n\n    for a list of supported GPU cards.\n\n\n\n\nThe following NVIDIA \nsoftware\n must be installed on your system:\n\n\n\n\nNVIDIA\ns Cuda Toolkit (\n= 7.0). We recommend version 8.0.\n    For details, see\n    \nNVIDIA\ns documentation\n.\n    Ensure that you append the relevant Cuda pathnames to the\n    \nLD_LIBRARY_PATH\n environment variable as described in the\n    NVIDIA documentation.\n\n\nThe NVIDIA drivers associated with NVIDIA\ns Cuda Toolkit.\n\n\ncuDNN (\n= v3). We recommend version 5.1. For details, see\n    \nNVIDIA\ns documentation\n,\n    particularly the description of appending the appropriate pathname\n    to your \nLD_LIBRARY_PATH\n environment variable.\n\n\n\n\nFinally, you must also install \nlibcupti-dev\n by invoking the following\ncommand:\n\n\n $ \nsudo apt-get install libcupti-dev\n \n\n\n\nNext\n\n\nAfter preparing the environment, you must now\n\nconfigure the installation\n.\n\n\n\n\nPrepare environment for Mac OS\n\n\nBefore building TensorFlow, you must install the following on your system:\n\n\n\n\nbazel\n\n\nTensorFlow Python dependencies.\n\n\noptionally, NVIDIA packages to support TensorFlow for GPU.\n\n\n\n\nInstall bazel\n\n\nIf bazel is not installed on your system, install it now by following\n\nthese directions\n.\n\n\nInstall python dependencies\n\n\nTo install TensorFlow, you must install the following packages:\n\n\n\n\nsix\n\n\nnumpy, which is a numerical processing package that TensorFlow requires.\n\n\nwheel, which enables you to manage Python compressed packages\n    in the wheel (.whl) format.\n\n\nautograd, for dynamic differentiation\n\n\n\n\nYou may install the python dependencies using pip. If you don\nt have pip\non your machine, we recommend using homebrew to install Python and pip as\n\ndocumented here\n.\nIf you follow these instructions, you will not need to disable SIP.\n\n\nAfter installing pip, invoke the following commands:\n\n\n $ \nsudo pip install six numpy wheel autograd\n \n\n\n\nOptional: install TensorFlow for GPU prerequisites\n\n\nIf you do not have brew installed, install it by following\n\nthese instructions\n.\n\n\nAfter installing brew, install GNU coreutils by issuing the following command:\n\n\n$ \nbrew install coreutils\n\n\n\nIf you want to compile tensorflow and have XCode 7.3 and CUDA 7.5 installed,\nnote that Xcode 7.3 is not yet compatible with CUDA 7.5.  To remedy this\nproblem, do either of the following:\n\n\n\n\nUpgrade to CUDA 8.0.\n\n\n\n\nDownload Xcode 7.2 and select it as your default by issuing the following\n    command:\n\n\n $ \nsudo xcode-select -s /Application/Xcode-7.2/Xcode.app\n\n\n\n\n\n\nNOTE:\n Your system must fulfill the NVIDIA software requirements described\nin one of the following documents:\n\n\n\n\n@{$install_linux#NVIDIARequirements$Installing TensorFlow on Linux}\n\n\n@{$install_mac#NVIDIARequirements$Installing TensorFlow on Mac OS}\n\n\n\n\n\n\nConfigure the installation\n\n\nThe root of the source tree contains a bash script named\n\nconfigure\n. This script asks you to identify the pathname of all\nrelevant TensorFlow dependencies and specify other build configuration options\nsuch as compiler flags. You must run this script \nprior\n to\ncreating the pip package and installing TensorFlow.\n\n\nIf you wish to build TensorFlow with GPU, \nconfigure\n will ask\nyou to specify the version numbers of Cuda and cuDNN. If several\nversions of Cuda or cuDNN are installed on your system, explicitly select\nthe desired version instead of relying on the default.\n\n\nOne of the questions that \nconfigure\n will ask is as follows:\n\n\n\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native]\n\n\n\n\nThis question refers to a later phase in which you\nll use bazel to\n\nbuild the pip package\n.  We recommend\naccepting the default (\n-march=native\n), which will\noptimize the generated code for your local machine\ns CPU type.  However,\nif you are building TensorFlow on one CPU type but will run TensorFlow on\na different CPU type, then consider specifying a more specific optimization\nflag as described in \nthe gcc\ndocumentation\n.\n\n\nHere is an example execution of the \nconfigure\n script.  Note that your\nown input will likely differ from our sample input:\n\n\n\n$ \ncd tensorflow\n  # cd to the top-level directory created\n$ \n./configure\n\nPlease specify the location of python. [Default is /usr/bin/python]: \n/usr/bin/python2.7\n\nFound possible Python library paths:\n  /usr/local/lib/python2.7/dist-packages\n  /usr/lib/python2.7/dist-packages\nPlease input the desired Python library path to use.  Default is [/usr/lib/python2.7/dist-packages]\n\nUsing python library path: /usr/local/lib/python2.7/dist-packages\nDo you wish to build TensorFlow with MKL support? [y/N]\nNo MKL support will be enabled for TensorFlow\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native]:\nDo you wish to use jemalloc as the malloc implementation? [Y/n]\njemalloc enabled\nDo you wish to build TensorFlow with Google Cloud Platform support? [y/N]\nNo Google Cloud Platform support will be enabled for TensorFlow\nDo you wish to build TensorFlow with Hadoop File System support? [y/N]\nNo Hadoop File System support will be enabled for TensorFlow\nDo you wish to build TensorFlow with the XLA just-in-time compiler (experimental)? [y/N]\nNo XLA support will be enabled for TensorFlow\nDo you wish to build TensorFlow with VERBS support? [y/N]\nNo VERBS support will be enabled for TensorFlow\nDo you wish to build TensorFlow with OpenCL support? [y/N]\nNo OpenCL support will be enabled for TensorFlow\nDo you wish to build TensorFlow with CUDA support? [y/N] \nY\n\nCUDA support will be enabled for TensorFlow\nDo you want to use clang as CUDA compiler? [y/N]\nnvcc will be used as CUDA compiler\nPlease specify the Cuda SDK version you want to use, e.g. 7.0. [Leave empty to default to CUDA 8.0]: \n8.0\n\nPlease specify the location where CUDA 8.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]:\nPlease specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]:\nPlease specify the cuDNN version you want to use. [Leave empty to default to cuDNN 6.0]: \n6\n\nPlease specify the location where cuDNN 6 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]:\nPlease specify a list of comma-separated Cuda compute capabilities you want to build with.\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.\nPlease note that each additional compute capability significantly increases your build time and binary size.\n[Default is: \"3.5,5.2\"]: \n3.0\n\nDo you wish to build TensorFlow with MPI support? [y/N]\nMPI support will not be enabled for TensorFlow\nConfiguration finished\n\n\n\n\nIf you told \nconfigure\n to build for GPU support, then \nconfigure\n\nwill create a canonical set of symbolic links to the Cuda libraries\non your system.  Therefore, every time you change the Cuda library paths,\nyou must rerun the \nconfigure\n script before re-invoking\nthe \nbazel build\n command.\n\n\nNote the following:\n\n\n\n\nAlthough it is possible to build both Cuda and non-Cuda configs\n    under the same source tree, we recommend running \nbazel clean\n when\n    switching between these two configurations in the same source tree.\n\n\nIf you don\nt run the \nconfigure\n script \nbefore\n running the\n    \nbazel build\n command, the \nbazel build\n command will fail.\n\n\n\n\nBuild the pip package\n\n\nTo build a pip package for TensorFlow with CPU-only support,\nyou would typically invoke the following command:\n\n\n\n$ \nbazel build --config=opt //tensorflow/tools/pip_package:build_pip_package\n\n\n\n\n\nTo build a pip package for TensorFlow with GPU support,\ninvoke the following command:\n\n\n$ \nbazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\n \n\n\n\nNOTE on gcc 5 or later:\n the binary pip packages available on the\nTensorFlow website are built with gcc 4, which uses the older ABI. To\nmake your build compatible with the older ABI, you need to add\n\n--cxxopt=\"-D_GLIBCXX_USE_CXX11_ABI=0\"\n to your \nbazel build\n command.\nABI compatibility allows custom ops built against the TensorFlow pip package\nto continue to work against your built package.\n\n\nTip:\n By default, building TensorFlow from sources consumes\na lot of RAM.  If RAM is an issue on your system, you may limit RAM usage\nby specifying \nlocal_resources 2048,.5,1.0\n while\ninvoking \nbazel\n.\n\n\nThe \nbazel build\n command builds a script named\n\nbuild_pip_package\n.  Running this script as follows will build\na \n.whl\n file within the \n/tmp/tensorflow_pkg\n directory:\n\n\n\n$ \nbazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg\n\n\n\n\n\nInstall the pip package\n\n\nInvoke \npip install\n to install that pip package.\nThe filename of the \n.whl\n file depends on your platform.\nFor example, the following command will install the pip package\n\n\nfor TensorFlow 1.3.0 on Linux:\n\n\n\n$ \nsudo pip install /tmp/tensorflow_pkg/tensorflow-1.3.0-py2-none-any.whl\n\n\n\n\n\nValidate your installation\n\n\nValidate your TensorFlow installation by doing the following:\n\n\nStart a terminal.\n\n\nChange directory (\ncd\n) to any directory on your system other than the\n\ntensorflow\n subdirectory from which you invoked the \nconfigure\n command.\n\n\nInvoke python:\n\n\n$ \npython\n\n\n\nEnter the following short program inside the python interactive shell:\n\n\n# Python\nimport tensorflow as tf\nhello = tf.constant('Hello, TensorFlow!')\nsess = tf.Session()\nprint(sess.run(hello))\n\n\n\n\nIf the system outputs the following, then you are ready to begin writing\nTensorFlow programs:\n\n\nHello, TensorFlow!\n\n\n\nIf you are new to TensorFlow, see @{$get_started/get_started$Getting Started with\nTensorFlow}.\n\n\nIf the system outputs an error message instead of a greeting, see \nCommon\ninstallation problems\n.\n\n\nCommon installation problems\n\n\nThe installation problems you encounter typically depend on the\noperating system.  See the \nCommon installation problems\n section\nof one of the following guides:\n\n\n\n\n@{$install_linux#CommonInstallationProblems$Installing TensorFlow on Linux}\n\n\n@{$install_mac#CommonInstallationProblems$Installing TensorFlow on Mac OS}\n\n\n@{$install_windows#CommonInstallationProblems$Installing TensorFlow on Windows}\n\n\n\n\nBeyond the errors documented in those two guides, the following table\nnotes additional errors specific to building TensorFlow.  Note that we\nare relying on Stack Overflow as the repository for build and installation\nproblems.  If you encounter an error message not listed in the preceding\ntwo guides or in the following table, search for it on Stack Overflow.  If\nStack Overflow doesn\nt show the error message, ask a new question on\nStack Overflow and specify the \ntensorflow\n tag.\n\n\n\n\n \nStack Overflow Link\n \nError Message\n \n\n\n\n\n  \n41293077\n\n  \nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow\n  library wasn't compiled to use SSE4.1 instructions, but these are available on\n  your machine and could speed up CPU computations.\n\n\n\n\n\n\n  \n42013316\n\n  \nImportError: libcudart.so.8.0: cannot open shared object file:\n  No such file or directory\n\n\n\n\n\n\n  \n42013316\n\n  \nImportError: libcudnn.5: cannot open shared object file:\n  No such file or directory\n\n\n\n\n\n\n  \n35953210\n\n  \nInvoking `python` or `ipython` generates the following error:\n  \nImportError: cannot import name pywrap_tensorflow", 
            "title": "1.5 \u6e90\u4ee3\u7801\u5b89\u88c5TensorFlow"
        }, 
        {
            "location": "/install/install_sources/#installing-tensorflow-from-sources", 
            "text": "This guide explains how to build TensorFlow sources into a TensorFlow\nbinary and how to install that TensorFlow binary.  Note that we provide\nwell-tested, pre-built TensorFlow binaries for Linux, Mac, and Windows\nsystems. In addition, there are pre-built TensorFlow docker images .\nSo, don t build a TensorFlow binary yourself unless you are very\ncomfortable building complex packages from source and dealing with\nthe inevitable aftermath should things not go exactly as documented.  If the last paragraph didn t scare you off, welcome.  This guide explains\nhow to build TensorFlow on the following operating systems:   Ubuntu  Mac OS X   We don t officially support building TensorFlow on Windows; however, you may try\nto build TensorFlow on Windows if you don t mind using the highly experimental Bazel on Windows \nor TensorFlow CMake build .", 
            "title": "Installing TensorFlow from Sources"
        }, 
        {
            "location": "/install/install_sources/#determine-which-tensorflow-to-install", 
            "text": "You must choose one of the following types of TensorFlow to build and\ninstall:   TensorFlow with CPU support only . If your system does not have a\n  NVIDIA\u00ae GPU, build and install this version. Note that this version of\n  TensorFlow is typically easier to build and install, so even if you\n  have an NVIDIA GPU, we recommend building and installing this version\n  first.   TensorFlow with GPU support . TensorFlow programs typically run\n  significantly faster on a GPU than on a CPU. Therefore, if your system\n  has a NVIDIA GPU and you need to run performance-critical applications,\n  you should ultimately build and install this version.\n  Beyond the NVIDIA GPU itself, your system must also fulfill the NVIDIA\n  software requirements described in one of the following documents:    @{$install_linux#NVIDIARequirements$Installing TensorFlow on Ubuntu}   @{$install_mac#NVIDIARequirements$Installing TensorFlow on Mac OS}", 
            "title": "Determine which TensorFlow to install"
        }, 
        {
            "location": "/install/install_sources/#clone-the-tensorflow-repository", 
            "text": "Start the process of building TensorFlow by cloning a TensorFlow\nrepository.  To clone  the latest  TensorFlow repository, issue the following command:  $  git clone https://github.com/tensorflow/tensorflow    The preceding  git clone  command creates a subdirectory\nnamed  tensorflow .  After cloning, you may optionally build a specific branch  (such as a release branch) by invoking the\nfollowing commands:  \n$  cd tensorflow \n$  git checkout   Branch  # where  Branch  is the desired branch  For example, to work with the  r1.0  release instead of the master release,\nissue the following command:  $  git checkout r1.0  Next, you must prepare your environment for Linux \nor Mac OS", 
            "title": "Clone the TensorFlow repository"
        }, 
        {
            "location": "/install/install_sources/#prepare-environment-for-linux", 
            "text": "Before building TensorFlow on Linux, install the following build\ntools on your system:   bazel  TensorFlow Python dependencies  optionally, NVIDIA packages to support TensorFlow for GPU.", 
            "title": "Prepare environment for Linux"
        }, 
        {
            "location": "/install/install_sources/#install-bazel", 
            "text": "If bazel is not installed on your system, install it now by following these directions .", 
            "title": "Install Bazel"
        }, 
        {
            "location": "/install/install_sources/#install-tensorflow-python-dependencies", 
            "text": "To install TensorFlow, you must install the following packages:   numpy , which is a numerical processing package that TensorFlow requires.  dev , which enables adding extensions to Python.  pip , which enables you to install and manage certain Python packages.  wheel , which enables you to manage Python compressed packages in\n    the wheel (.whl) format.   To install these packages for Python 2.7, issue the following command:  \n$  sudo apt-get install python-numpy python-dev python-pip python-wheel   To install these packages for Python 3.n, issue the following command:  \n$  sudo apt-get install python3-numpy python3-dev python3-pip python3-wheel", 
            "title": "Install TensorFlow Python dependencies"
        }, 
        {
            "location": "/install/install_sources/#optional-install-tensorflow-for-gpu-prerequisites", 
            "text": "If you are building TensorFlow without GPU support, skip this section.  The following NVIDIA  hardware  must be installed on your system:   GPU card with CUDA Compute Capability 3.0 or higher.  See\n     NVIDIA documentation \n    for a list of supported GPU cards.   The following NVIDIA  software  must be installed on your system:   NVIDIA s Cuda Toolkit ( = 7.0). We recommend version 8.0.\n    For details, see\n     NVIDIA s documentation .\n    Ensure that you append the relevant Cuda pathnames to the\n     LD_LIBRARY_PATH  environment variable as described in the\n    NVIDIA documentation.  The NVIDIA drivers associated with NVIDIA s Cuda Toolkit.  cuDNN ( = v3). We recommend version 5.1. For details, see\n     NVIDIA s documentation ,\n    particularly the description of appending the appropriate pathname\n    to your  LD_LIBRARY_PATH  environment variable.   Finally, you must also install  libcupti-dev  by invoking the following\ncommand:   $  sudo apt-get install libcupti-dev", 
            "title": "Optional: install TensorFlow for GPU prerequisites"
        }, 
        {
            "location": "/install/install_sources/#next", 
            "text": "After preparing the environment, you must now configure the installation .", 
            "title": "Next"
        }, 
        {
            "location": "/install/install_sources/#prepare-environment-for-mac-os", 
            "text": "Before building TensorFlow, you must install the following on your system:   bazel  TensorFlow Python dependencies.  optionally, NVIDIA packages to support TensorFlow for GPU.", 
            "title": "Prepare environment for Mac OS"
        }, 
        {
            "location": "/install/install_sources/#install-bazel_1", 
            "text": "If bazel is not installed on your system, install it now by following these directions .", 
            "title": "Install bazel"
        }, 
        {
            "location": "/install/install_sources/#install-python-dependencies", 
            "text": "To install TensorFlow, you must install the following packages:   six  numpy, which is a numerical processing package that TensorFlow requires.  wheel, which enables you to manage Python compressed packages\n    in the wheel (.whl) format.  autograd, for dynamic differentiation   You may install the python dependencies using pip. If you don t have pip\non your machine, we recommend using homebrew to install Python and pip as documented here .\nIf you follow these instructions, you will not need to disable SIP.  After installing pip, invoke the following commands:   $  sudo pip install six numpy wheel autograd", 
            "title": "Install python dependencies"
        }, 
        {
            "location": "/install/install_sources/#optional-install-tensorflow-for-gpu-prerequisites_1", 
            "text": "If you do not have brew installed, install it by following these instructions .  After installing brew, install GNU coreutils by issuing the following command:  $  brew install coreutils  If you want to compile tensorflow and have XCode 7.3 and CUDA 7.5 installed,\nnote that Xcode 7.3 is not yet compatible with CUDA 7.5.  To remedy this\nproblem, do either of the following:   Upgrade to CUDA 8.0.   Download Xcode 7.2 and select it as your default by issuing the following\n    command:   $  sudo xcode-select -s /Application/Xcode-7.2/Xcode.app    NOTE:  Your system must fulfill the NVIDIA software requirements described\nin one of the following documents:   @{$install_linux#NVIDIARequirements$Installing TensorFlow on Linux}  @{$install_mac#NVIDIARequirements$Installing TensorFlow on Mac OS}", 
            "title": "Optional: install TensorFlow for GPU prerequisites"
        }, 
        {
            "location": "/install/install_sources/#configure-the-installation", 
            "text": "The root of the source tree contains a bash script named configure . This script asks you to identify the pathname of all\nrelevant TensorFlow dependencies and specify other build configuration options\nsuch as compiler flags. You must run this script  prior  to\ncreating the pip package and installing TensorFlow.  If you wish to build TensorFlow with GPU,  configure  will ask\nyou to specify the version numbers of Cuda and cuDNN. If several\nversions of Cuda or cuDNN are installed on your system, explicitly select\nthe desired version instead of relying on the default.  One of the questions that  configure  will ask is as follows:  \nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native]  This question refers to a later phase in which you ll use bazel to build the pip package .  We recommend\naccepting the default ( -march=native ), which will\noptimize the generated code for your local machine s CPU type.  However,\nif you are building TensorFlow on one CPU type but will run TensorFlow on\na different CPU type, then consider specifying a more specific optimization\nflag as described in  the gcc\ndocumentation .  Here is an example execution of the  configure  script.  Note that your\nown input will likely differ from our sample input:  \n$  cd tensorflow   # cd to the top-level directory created\n$  ./configure \nPlease specify the location of python. [Default is /usr/bin/python]:  /usr/bin/python2.7 \nFound possible Python library paths:\n  /usr/local/lib/python2.7/dist-packages\n  /usr/lib/python2.7/dist-packages\nPlease input the desired Python library path to use.  Default is [/usr/lib/python2.7/dist-packages]\n\nUsing python library path: /usr/local/lib/python2.7/dist-packages\nDo you wish to build TensorFlow with MKL support? [y/N]\nNo MKL support will be enabled for TensorFlow\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native]:\nDo you wish to use jemalloc as the malloc implementation? [Y/n]\njemalloc enabled\nDo you wish to build TensorFlow with Google Cloud Platform support? [y/N]\nNo Google Cloud Platform support will be enabled for TensorFlow\nDo you wish to build TensorFlow with Hadoop File System support? [y/N]\nNo Hadoop File System support will be enabled for TensorFlow\nDo you wish to build TensorFlow with the XLA just-in-time compiler (experimental)? [y/N]\nNo XLA support will be enabled for TensorFlow\nDo you wish to build TensorFlow with VERBS support? [y/N]\nNo VERBS support will be enabled for TensorFlow\nDo you wish to build TensorFlow with OpenCL support? [y/N]\nNo OpenCL support will be enabled for TensorFlow\nDo you wish to build TensorFlow with CUDA support? [y/N]  Y \nCUDA support will be enabled for TensorFlow\nDo you want to use clang as CUDA compiler? [y/N]\nnvcc will be used as CUDA compiler\nPlease specify the Cuda SDK version you want to use, e.g. 7.0. [Leave empty to default to CUDA 8.0]:  8.0 \nPlease specify the location where CUDA 8.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]:\nPlease specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]:\nPlease specify the cuDNN version you want to use. [Leave empty to default to cuDNN 6.0]:  6 \nPlease specify the location where cuDNN 6 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]:\nPlease specify a list of comma-separated Cuda compute capabilities you want to build with.\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.\nPlease note that each additional compute capability significantly increases your build time and binary size.\n[Default is: \"3.5,5.2\"]:  3.0 \nDo you wish to build TensorFlow with MPI support? [y/N]\nMPI support will not be enabled for TensorFlow\nConfiguration finished  If you told  configure  to build for GPU support, then  configure \nwill create a canonical set of symbolic links to the Cuda libraries\non your system.  Therefore, every time you change the Cuda library paths,\nyou must rerun the  configure  script before re-invoking\nthe  bazel build  command.  Note the following:   Although it is possible to build both Cuda and non-Cuda configs\n    under the same source tree, we recommend running  bazel clean  when\n    switching between these two configurations in the same source tree.  If you don t run the  configure  script  before  running the\n     bazel build  command, the  bazel build  command will fail.", 
            "title": "Configure the installation"
        }, 
        {
            "location": "/install/install_sources/#build-the-pip-package", 
            "text": "To build a pip package for TensorFlow with CPU-only support,\nyou would typically invoke the following command:  \n$  bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package   To build a pip package for TensorFlow with GPU support,\ninvoke the following command:  $  bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package    NOTE on gcc 5 or later:  the binary pip packages available on the\nTensorFlow website are built with gcc 4, which uses the older ABI. To\nmake your build compatible with the older ABI, you need to add --cxxopt=\"-D_GLIBCXX_USE_CXX11_ABI=0\"  to your  bazel build  command.\nABI compatibility allows custom ops built against the TensorFlow pip package\nto continue to work against your built package.  Tip:  By default, building TensorFlow from sources consumes\na lot of RAM.  If RAM is an issue on your system, you may limit RAM usage\nby specifying  local_resources 2048,.5,1.0  while\ninvoking  bazel .  The  bazel build  command builds a script named build_pip_package .  Running this script as follows will build\na  .whl  file within the  /tmp/tensorflow_pkg  directory:  \n$  bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg", 
            "title": "Build the pip package"
        }, 
        {
            "location": "/install/install_sources/#install-the-pip-package", 
            "text": "Invoke  pip install  to install that pip package.\nThe filename of the  .whl  file depends on your platform.\nFor example, the following command will install the pip package  for TensorFlow 1.3.0 on Linux:  \n$  sudo pip install /tmp/tensorflow_pkg/tensorflow-1.3.0-py2-none-any.whl", 
            "title": "Install the pip package"
        }, 
        {
            "location": "/install/install_sources/#validate-your-installation", 
            "text": "Validate your TensorFlow installation by doing the following:  Start a terminal.  Change directory ( cd ) to any directory on your system other than the tensorflow  subdirectory from which you invoked the  configure  command.  Invoke python:  $  python  Enter the following short program inside the python interactive shell:  # Python\nimport tensorflow as tf\nhello = tf.constant('Hello, TensorFlow!')\nsess = tf.Session()\nprint(sess.run(hello))  If the system outputs the following, then you are ready to begin writing\nTensorFlow programs:  Hello, TensorFlow!  If you are new to TensorFlow, see @{$get_started/get_started$Getting Started with\nTensorFlow}.  If the system outputs an error message instead of a greeting, see  Common\ninstallation problems .", 
            "title": "Validate your installation"
        }, 
        {
            "location": "/install/install_sources/#common-installation-problems", 
            "text": "The installation problems you encounter typically depend on the\noperating system.  See the  Common installation problems  section\nof one of the following guides:   @{$install_linux#CommonInstallationProblems$Installing TensorFlow on Linux}  @{$install_mac#CommonInstallationProblems$Installing TensorFlow on Mac OS}  @{$install_windows#CommonInstallationProblems$Installing TensorFlow on Windows}   Beyond the errors documented in those two guides, the following table\nnotes additional errors specific to building TensorFlow.  Note that we\nare relying on Stack Overflow as the repository for build and installation\nproblems.  If you encounter an error message not listed in the preceding\ntwo guides or in the following table, search for it on Stack Overflow.  If\nStack Overflow doesn t show the error message, ask a new question on\nStack Overflow and specify the  tensorflow  tag.     Stack Overflow Link   Error Message    \n   41293077 \n   W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow\n  library wasn't compiled to use SSE4.1 instructions, but these are available on\n  your machine and could speed up CPU computations.   \n   42013316 \n   ImportError: libcudart.so.8.0: cannot open shared object file:\n  No such file or directory   \n   42013316 \n   ImportError: libcudnn.5: cannot open shared object file:\n  No such file or directory   \n   35953210 \n   Invoking `python` or `ipython` generates the following error:\n   ImportError: cannot import name pywrap_tensorflow", 
            "title": "Common installation problems"
        }, 
        {
            "location": "/install/migration/", 
            "text": "Transitioning to TensorFlow 1.0\n\n\nThe APIs in TensorFlow 1.0 have changed in ways that are not all backwards\ncompatible.  That is, TensorFlow programs that worked on TensorFlow 0.n won\nt\nnecessarily work on TensorFlow 1.0.  We have made this API changes to ensure an\ninternally-consistent API, and do not plan to make backwards-breaking changes\nthroughout the 1.N lifecycle.\n\n\nThis guide walks you through the major changes in the API and how to\nautomatically upgrade your programs for TensorFlow 1.0.  This guide not\nonly steps you through the changes but also explains why we\nve made them.\n\n\nHow to upgrade\n\n\nIf you would like to automatically  port your code to 1.0, you can try our\n\ntf_upgrade.py\n script. While this script handles many cases, manual changes\nare sometimes necessary.\n  Get this script from our\n\nGitHub tree\n.\n\n\nTo convert a single 0.n TensorFlow source file to 1.0, enter a\ncommand of the following format:\n\n\n\n$ \npython tf_upgrade.py --infile\n \nInputFile\n \n--outfile\n \nOutputFile\n\n\n\n\n\nFor example, the following command converts a 0.n TensorFlow\nprogram named \ntest.py\n to a 1.0 TensorFlow program named \ntest_1.0.py\n:\n\n\n\n$ \npython tf_upgrade.py --infile test.py --outfile test_1.0.py\n\n\n\n\n\nThe \ntf_upgrade.py\n script also generates a file named \nreport.txt\n, which\ndetails all the changes it performed and makes additional suggestions about\nchanges you might need to make manually.\n\n\nTo upgrade a whole directory of 0.n TensorFlow programs to 1.0,\nenter a command having the following format:\n\n\n\n$ \npython tf_upgrade.py --intree\n \nInputDir\n \n--outtree\n \nOutputDir\n\n\n\n\n\nFor example, the following command converts all the 0.n TensorFlow programs\nin the \n/home/user/cool\n directory, creating their 1.0 equivalents in\nthe \n/home/user/cool_1.0\n directory:\n\n\n\n$ \npython tf_upgrade.py --intree /home/user/cool --outtree /home/user/cool_1.0\n\n\n\n\n\nLimitations\n\n\nThere are a few things to watch out for. Specifically:\n\n\n\n\nYou must manually fix any instances of \ntf.reverse()\n.\n   The \ntf_upgrade.py\n script will warn you about \ntf.reverse()\n in\n   stdout and in the \nreport.txt\n file.\n\n\nOn reordered arguments, \ntf_upgrade.py\n tries to minimally reformat\n   your code, so it cannot automatically change the actual argument order.\n   Instead, \ntf_upgrade.py\n makes your function invocations order-independent\n   by introducing keyword arguments.\n\n\nConstructions like \ntf.get_variable_scope().reuse_variables()\n\n   will likely not work. We recommend deleting those lines and replacing\n   them with lines such as the following:\n\n\n\n\n\n   with tf.variable_scope(tf.get_variable_scope(), reuse=True):\n     \n\n   \n\n\n\n\nAnalogously to \ntf.pack\n and  \ntf.unpack\n, we\nre renamed\n   \nTensorArray.pack\n and \nTensorArray.unpack\n to\n   \nTensorArray.stack\n and \nTensorArray.unstack\n. However, \nTensorArray.pack\n\n   and \nTensorArray.unpack\n cannot be detected lexically since they are\n   indirectly related to the \ntf\n namespace e.g.\n   \nfoo = tf.TensorArray(); foo.unpack()\n\n\n\n\nUpgrading your code manually\n\n\nInstead of running \ntf_upgrade.py\n, you may manually upgrade your code.\nThe remainder of this document provides a comprehensive list of\nall backward incompatible changes made in TensorFlow 1.0.\n\n\nVariables\n\n\nVariable functions have been made more consistent and less confusing.\n\n\n\n\ntf.VARIABLES\n\n\nshould be renamed to \ntf.GLOBAL_VARIABLES\n\n\n\n\n\n\ntf.all_variables\n\n\nshould be renamed to \ntf.global_variables\n\n\n\n\n\n\ntf.initialize_all_variables\n\n\nshould be renamed to \ntf.global_variables_initializer\n\n\n\n\n\n\ntf.initialize_local_variables\n\n\nshould be renamed to \ntf.local_variables_initializer\n\n\n\n\n\n\ntf.initialize_variables\n\n\nshould be renamed to \ntf.variables_initializer\n\n\n\n\n\n\n\n\nSummary functions\n\n\nSummary functions have been consolidated under the \ntf.summary\n namespace.\n\n\n\n\ntf.audio_summary\n\n\nshould be renamed to \ntf.summary.audio\n\n\n\n\n\n\ntf.contrib.deprecated.histogram_summary\n\n\nshould be renamed to \ntf.summary.histogram\n\n\n\n\n\n\ntf.contrib.deprecated.scalar_summary\n\n\nshould be renamed to \ntf.summary.scalar\n\n\n\n\n\n\ntf.histogram_summary\n\n\nshould be renamed to \ntf.summary.histogram\n\n\n\n\n\n\ntf.image_summary\n\n\nshould be renamed to \ntf.summary.image\n\n\n\n\n\n\ntf.merge_all_summaries\n\n\nshould be renamed to \ntf.summary.merge_all\n\n\n\n\n\n\ntf.merge_summary\n\n\nshould be renamed to \ntf.summary.merge\n\n\n\n\n\n\ntf.scalar_summary\n\n\nshould be renamed to \ntf.summary.scalar\n\n\n\n\n\n\ntf.train.SummaryWriter\n\n\nshould be renamed to \ntf.summary.FileWriter\n\n\n\n\n\n\n\n\nNumeric differences\n\n\nInteger division and \ntf.floordiv\n now uses flooring semantics. This is to\nmake the results of \nnp.divide\n and \nnp.mod\n consistent with \ntf.divide\n and\n\ntf.mod\n, respectively. In addition we have changed the rounding algorithm\nused by \ntf.round\n to match NumPy.\n\n\n\n\n\n\ntf.div\n\n\n\n\n\n\nThe semantics of \ntf.divide\n division have been changed to match Python\nsemantics completely. That is, \n/\n in Python 3     and future division mode in\nPython 2 will produce floating point numbers always, \n//\n will produce floored\ndivision.     However, even \ntf.div\n will produce floored integer division.\nTo force C-style truncation semantics, you must use \ntf.truncatediv\n.\n\n\n\n\n\n\nConsider changing your code to use \ntf.divide\n, which follows Python semantics for promotion.\n\n\n\n\n\n\n\n\n\n\ntf.mod\n\n\n\n\nThe semantics of \ntf.mod\n have been changed to match Python semantics. In\nparticular, flooring semantics are used for     integers. If you wish to have\nC-style truncation mod (remainders), you can use \ntf.truncatemod\n\n\n\n\n\n\n\n\nThe old and new behavior of division can be summarized with this table:\n\n\n\n\n\n\n\n\nExpr\n\n\nTF 0.11 (py2)\n\n\nTF 0.11 (py3)\n\n\nTF 1.0 (py2)\n\n\nTF 1.0 (py3)\n\n\n\n\n\n\n\n\n\n\ntf.div(3,4)\n\n\n0\n\n\n0\n\n\n0\n\n\n0\n\n\n\n\n\n\ntf.div(-3,4)\n\n\n0\n\n\n0\n\n\n-1\n\n\n-1\n\n\n\n\n\n\ntf.mod(-3,4)\n\n\n-3\n\n\n-3\n\n\n1\n\n\n1\n\n\n\n\n\n\n-3/4\n\n\n0\n\n\n-0.75\n\n\n-1\n\n\n-0.75\n\n\n\n\n\n\n-3/4tf.divide(-3,4)\n\n\nN/A\n\n\nN/A\n\n\n-0.75\n\n\n-1\n\n\n\n\n\n\n\n\nThe old and new behavior of rounding can be summarized with this table:\n\n\n\n\n\n\n\n\nInput\n\n\nPython\n\n\nNumPy\n\n\nC++ round()\n\n\nTensorFlow 0.11(floor(x+.5))\n\n\nTensorFlow 1.0\n\n\n\n\n\n\n\n\n\n\n-3.5\n\n\n-4\n\n\n-4\n\n\n-4\n\n\n-3\n\n\n-4\n\n\n\n\n\n\n-2.5\n\n\n-2\n\n\n-2\n\n\n-3\n\n\n-2\n\n\n-2\n\n\n\n\n\n\n-1.5\n\n\n-2\n\n\n-2\n\n\n-2\n\n\n-1\n\n\n-2\n\n\n\n\n\n\n-0.5\n\n\n0\n\n\n0\n\n\n-1\n\n\n0\n\n\n0\n\n\n\n\n\n\n0.5\n\n\n0\n\n\n0\n\n\n1\n\n\n1\n\n\n0\n\n\n\n\n\n\n1.5\n\n\n2\n\n\n2\n\n\n2\n\n\n2\n\n\n2\n\n\n\n\n\n\n2.5\n\n\n2\n\n\n2\n\n\n3\n\n\n3\n\n\n2\n\n\n\n\n\n\n3.5\n\n\n4\n\n\n4\n\n\n4\n\n\n4\n\n\n4\n\n\n\n\n\n\n\n\nNumPy matching names\n\n\nMany functions have been renamed to match NumPy. This was done to make the\ntransition between NumPy and TensorFlow as easy as possible. There are still\nnumerous cases where functions do not match, so this is far from a hard and\nfast rule, but we have removed several commonly noticed inconsistencies.\n\n\n\n\ntf.inv\n\n\nshould be renamed to \ntf.reciprocal\n\n\nThis was done to avoid confusion with NumPy\ns matrix inverse \nnp.inv\n\n\n\n\n\n\ntf.list_diff\n\n\nshould be renamed to \ntf.setdiff1d\n\n\n\n\n\n\ntf.listdiff\n\n\nshould be renamed to \ntf.setdiff1d\n\n\n\n\n\n\ntf.mul\n\n\nshould be renamed to \ntf.multiply\n\n\n\n\n\n\ntf.neg\n\n\nshould be renamed to \ntf.negative\n\n\n\n\n\n\ntf.select\n\n\nshould be renamed to \ntf.where\n\n\ntf.where\n now takes 3 arguments or 1 argument, just like \nnp.where\n\n\n\n\n\n\ntf.sub\n\n\nshould be renamed to \ntf.subtract\n\n\n\n\n\n\n\n\nNumPy matching arguments\n\n\nArguments for certain TensorFlow 1.0 methods now match arguments in certain\nNumPy methods.  To achieve this, TensorFlow 1.0 has changed keyword arguments\nand reordered some arguments. Notably, TensorFlow 1.0 now uses \naxis\n rather\nthan \ndimension\n. TensorFlow 1.0 aims to keep the tensor argument first on\noperations that modify Tensors. (see the \ntf.concat\n change).\n\n\n\n\ntf.argmax\n\n\nkeyword argument \ndimension\n should be renamed to \naxis\n\n\n\n\n\n\ntf.argmin\n\n\nkeyword argument \ndimension\n should be renamed to \naxis\n\n\n\n\n\n\ntf.concat\n\n\nkeyword argument \nconcat_dim\n should be renamed to \naxis\n\n\narguments have been reordered to \ntf.concat(values, axis, name='concat')\n.\n\n\n\n\n\n\ntf.count_nonzero\n\n\nkeyword argument \nreduction_indices\n should be renamed to \naxis\n\n\n\n\n\n\ntf.expand_dims\n\n\nkeyword argument \ndim\n should be renamed to \naxis\n\n\n\n\n\n\ntf.reduce_all\n\n\nkeyword argument \nreduction_indices\n should be renamed to \naxis\n\n\n\n\n\n\ntf.reduce_any\n\n\nkeyword argument \nreduction_indices\n should be renamed to \naxis\n\n\n\n\n\n\ntf.reduce_join\n\n\nkeyword argument \nreduction_indices\n should be renamed to \naxis\n\n\n\n\n\n\ntf.reduce_logsumexp\n\n\nkeyword argument \nreduction_indices\n should be renamed to \naxis\n\n\n\n\n\n\ntf.reduce_max\n\n\nkeyword argument \nreduction_indices\n should be renamed to \naxis\n\n\n\n\n\n\ntf.reduce_mean\n\n\nkeyword argument \nreduction_indices\n should be renamed to \naxis\n\n\n\n\n\n\ntf.reduce_min\n\n\nkeyword argument \nreduction_indices\n should be renamed to \naxis\n\n\n\n\n\n\ntf.reduce_prod\n\n\nkeyword argument \nreduction_indices\n should be renamed to \naxis\n\n\n\n\n\n\ntf.reduce_sum\n\n\nkeyword argument \nreduction_indices\n should be renamed to \naxis\n\n\n\n\n\n\ntf.reverse\n\n\ntf.reverse\n used to take a 1D \nbool\n tensor to control which dimensions were reversed. Now we use a Tensor of axis indices.\n\n\nFor example \ntf.reverse(a, [True, False, True])\n now must be \ntf.reverse(a, [0, 2])\n\n\n\n\n\n\ntf.reverse_sequence\n\n\nkeyword argument \nbatch_dim\n should be renamed to \nbatch_axis\n\n\nkeyword argument \nseq_dim\n should be renamed to \nseq_axis\n\n\n\n\n\n\ntf.sparse_concat\n\n\nkeyword argument \nconcat_dim\n should be renamed to \naxis\n\n\n\n\n\n\ntf.sparse_reduce_sum\n\n\nkeyword argument \nreduction_axes\n should be renamed to \naxis\n\n\n\n\n\n\ntf.sparse_reduce_sum_sparse\n\n\nkeyword argument \nreduction_axes\n should be renamed to \naxis\n\n\n\n\n\n\ntf.sparse_split\n\n\nkeyword argument \nsplit_dim\n should be renamed to \naxis\n\n\narguments have been reordered to \ntf.sparse_split(keyword_required=KeywordRequired(), sp_input=None, num_split=None, axis=None, name=None, split_dim=None)\n.\n\n\n\n\n\n\ntf.split\n\n\nkeyword argument \nsplit_dim\n should be renamed to \naxis\n\n\nkeyword argument \nnum_split\n should be renamed to \nnum_or_size_splits\n\n\narguments have been reordered to \ntf.split(value, num_or_size_splits, axis=0, num=None, name='split')\n.\n\n\n\n\n\n\ntf.squeeze\n\n\nkeyword argument \nsqueeze_dims\n should be renamed to \naxis\n\n\n\n\n\n\ntf.svd\n\n\narguments have been reordered to \ntf.svd(tensor, full_matrices=False, compute_uv=True, name=None)\n.\n\n\n\n\n\n\n\n\nSimplified math variants\n\n\nBatched versions of math operations have been removed. Now the functionality is\ncontained in the non-batched versions. Similarly,\ntf.complex_abs\n has had its\nfunctionality moved to \ntf.abs\n\n\n\n\ntf.batch_band_part\n\n\nshould be renamed to \ntf.band_part\n\n\n\n\n\n\ntf.batch_cholesky\n\n\nshould be renamed to \ntf.cholesky\n\n\n\n\n\n\ntf.batch_cholesky_solve\n\n\nshould be renamed to \ntf.cholesky_solve\n\n\n\n\n\n\ntf.batch_fft\n\n\nshould be renamed to \ntf.fft\n\n\n\n\n\n\ntf.batch_fft3d\n\n\nshould be renamed to \ntf.fft3d\n\n\n\n\n\n\ntf.batch_ifft\n\n\nshould be renamed to \ntf.ifft\n\n\n\n\n\n\ntf.batch_ifft2d\n\n\nshould be renamed to \ntf.ifft2d\n\n\n\n\n\n\ntf.batch_ifft3d\n\n\nshould be renamed to \ntf.ifft3d\n\n\n\n\n\n\ntf.batch_matmul\n\n\nshould be renamed to \ntf.matmul\n\n\n\n\n\n\ntf.batch_matrix_determinant\n\n\nshould be renamed to \ntf.matrix_determinant\n\n\n\n\n\n\ntf.batch_matrix_diag\n\n\nshould be renamed to \ntf.matrix_diag\n\n\n\n\n\n\ntf.batch_matrix_inverse\n\n\nshould be renamed to \ntf.matrix_inverse\n\n\n\n\n\n\ntf.batch_matrix_solve\n\n\nshould be renamed to \ntf.matrix_solve\n\n\n\n\n\n\ntf.batch_matrix_solve_ls\n\n\nshould be renamed to \ntf.matrix_solve_ls\n\n\n\n\n\n\ntf.batch_matrix_transpose\n\n\nshould be renamed to \ntf.matrix_transpose\n\n\n\n\n\n\ntf.batch_matrix_triangular_solve\n\n\nshould be renamed to \ntf.matrix_triangular_solve\n\n\n\n\n\n\ntf.batch_self_adjoint_eig\n\n\nshould be renamed to \ntf.self_adjoint_eig\n\n\n\n\n\n\ntf.batch_self_adjoint_eigvals\n\n\nshould be renamed to \ntf.self_adjoint_eigvals\n\n\n\n\n\n\ntf.batch_set_diag\n\n\nshould be renamed to \ntf.set_diag\n\n\n\n\n\n\ntf.batch_svd\n\n\nshould be renamed to \ntf.svd\n\n\n\n\n\n\ntf.complex_abs\n\n\nshould be renamed to \ntf.abs\n\n\n\n\n\n\n\n\nMisc Changes\n\n\nSeveral other changes have been made, including the following:\n\n\n\n\ntf.image.per_image_whitening\n\n\nshould be renamed to \ntf.image.per_image_standardization\n\n\n\n\n\n\ntf.nn.sigmoid_cross_entropy_with_logits\n\n\narguments have been reordered to \ntf.nn.sigmoid_cross_entropy_with_logits(_sentinel=None, labels=None, logits=None, name=None)\n.\n\n\n\n\n\n\ntf.nn.softmax_cross_entropy_with_logits\n\n\narguments have been reordered to \ntf.nn.softmax_cross_entropy_with_logits(_sentinel=None, labels=None, logits=None, dim=-1, name=None)\n.\n\n\n\n\n\n\ntf.nn.sparse_softmax_cross_entropy_with_logits\n\n\narguments have been reordered to \ntf.nn.sparse_softmax_cross_entropy_with_logits(_sentinel=None, labels=None, logits=None, name=None)\n.\n\n\n\n\n\n\ntf.ones_initializer\n\n\nshould be changed to a function call i.e. \ntf.ones_initializer()\n\n\n\n\n\n\ntf.pack\n\n\nshould be renamed to \ntf.stack\n\n\n\n\n\n\ntf.round\n\n\nThe semantics of \ntf.round\n now match Banker\ns rounding.\n\n\n\n\n\n\ntf.unpack\n\n\nshould be renamed to \ntf.unstack\n\n\n\n\n\n\ntf.zeros_initializer\n\n\nshould be changed to a function call i.e. \ntf.zeros_initializer()", 
            "title": "1.6 \u8fc1\u79fb\u5230TensorFlow 1.0"
        }, 
        {
            "location": "/install/migration/#transitioning-to-tensorflow-10", 
            "text": "The APIs in TensorFlow 1.0 have changed in ways that are not all backwards\ncompatible.  That is, TensorFlow programs that worked on TensorFlow 0.n won t\nnecessarily work on TensorFlow 1.0.  We have made this API changes to ensure an\ninternally-consistent API, and do not plan to make backwards-breaking changes\nthroughout the 1.N lifecycle.  This guide walks you through the major changes in the API and how to\nautomatically upgrade your programs for TensorFlow 1.0.  This guide not\nonly steps you through the changes but also explains why we ve made them.", 
            "title": "Transitioning to TensorFlow 1.0"
        }, 
        {
            "location": "/install/migration/#how-to-upgrade", 
            "text": "If you would like to automatically  port your code to 1.0, you can try our tf_upgrade.py  script. While this script handles many cases, manual changes\nare sometimes necessary.\n  Get this script from our GitHub tree .  To convert a single 0.n TensorFlow source file to 1.0, enter a\ncommand of the following format:  \n$  python tf_upgrade.py --infile   InputFile   --outfile   OutputFile   For example, the following command converts a 0.n TensorFlow\nprogram named  test.py  to a 1.0 TensorFlow program named  test_1.0.py :  \n$  python tf_upgrade.py --infile test.py --outfile test_1.0.py   The  tf_upgrade.py  script also generates a file named  report.txt , which\ndetails all the changes it performed and makes additional suggestions about\nchanges you might need to make manually.  To upgrade a whole directory of 0.n TensorFlow programs to 1.0,\nenter a command having the following format:  \n$  python tf_upgrade.py --intree   InputDir   --outtree   OutputDir   For example, the following command converts all the 0.n TensorFlow programs\nin the  /home/user/cool  directory, creating their 1.0 equivalents in\nthe  /home/user/cool_1.0  directory:  \n$  python tf_upgrade.py --intree /home/user/cool --outtree /home/user/cool_1.0", 
            "title": "How to upgrade"
        }, 
        {
            "location": "/install/migration/#limitations", 
            "text": "There are a few things to watch out for. Specifically:   You must manually fix any instances of  tf.reverse() .\n   The  tf_upgrade.py  script will warn you about  tf.reverse()  in\n   stdout and in the  report.txt  file.  On reordered arguments,  tf_upgrade.py  tries to minimally reformat\n   your code, so it cannot automatically change the actual argument order.\n   Instead,  tf_upgrade.py  makes your function invocations order-independent\n   by introducing keyword arguments.  Constructions like  tf.get_variable_scope().reuse_variables() \n   will likely not work. We recommend deleting those lines and replacing\n   them with lines such as the following:   \n   with tf.variable_scope(tf.get_variable_scope(), reuse=True):\n      \n      Analogously to  tf.pack  and   tf.unpack , we re renamed\n    TensorArray.pack  and  TensorArray.unpack  to\n    TensorArray.stack  and  TensorArray.unstack . However,  TensorArray.pack \n   and  TensorArray.unpack  cannot be detected lexically since they are\n   indirectly related to the  tf  namespace e.g.\n    foo = tf.TensorArray(); foo.unpack()", 
            "title": "Limitations"
        }, 
        {
            "location": "/install/migration/#upgrading-your-code-manually", 
            "text": "Instead of running  tf_upgrade.py , you may manually upgrade your code.\nThe remainder of this document provides a comprehensive list of\nall backward incompatible changes made in TensorFlow 1.0.", 
            "title": "Upgrading your code manually"
        }, 
        {
            "location": "/install/migration/#variables", 
            "text": "Variable functions have been made more consistent and less confusing.   tf.VARIABLES  should be renamed to  tf.GLOBAL_VARIABLES    tf.all_variables  should be renamed to  tf.global_variables    tf.initialize_all_variables  should be renamed to  tf.global_variables_initializer    tf.initialize_local_variables  should be renamed to  tf.local_variables_initializer    tf.initialize_variables  should be renamed to  tf.variables_initializer", 
            "title": "Variables"
        }, 
        {
            "location": "/install/migration/#summary-functions", 
            "text": "Summary functions have been consolidated under the  tf.summary  namespace.   tf.audio_summary  should be renamed to  tf.summary.audio    tf.contrib.deprecated.histogram_summary  should be renamed to  tf.summary.histogram    tf.contrib.deprecated.scalar_summary  should be renamed to  tf.summary.scalar    tf.histogram_summary  should be renamed to  tf.summary.histogram    tf.image_summary  should be renamed to  tf.summary.image    tf.merge_all_summaries  should be renamed to  tf.summary.merge_all    tf.merge_summary  should be renamed to  tf.summary.merge    tf.scalar_summary  should be renamed to  tf.summary.scalar    tf.train.SummaryWriter  should be renamed to  tf.summary.FileWriter", 
            "title": "Summary functions"
        }, 
        {
            "location": "/install/migration/#numeric-differences", 
            "text": "Integer division and  tf.floordiv  now uses flooring semantics. This is to\nmake the results of  np.divide  and  np.mod  consistent with  tf.divide  and tf.mod , respectively. In addition we have changed the rounding algorithm\nused by  tf.round  to match NumPy.    tf.div    The semantics of  tf.divide  division have been changed to match Python\nsemantics completely. That is,  /  in Python 3     and future division mode in\nPython 2 will produce floating point numbers always,  //  will produce floored\ndivision.     However, even  tf.div  will produce floored integer division.\nTo force C-style truncation semantics, you must use  tf.truncatediv .    Consider changing your code to use  tf.divide , which follows Python semantics for promotion.      tf.mod   The semantics of  tf.mod  have been changed to match Python semantics. In\nparticular, flooring semantics are used for     integers. If you wish to have\nC-style truncation mod (remainders), you can use  tf.truncatemod     The old and new behavior of division can be summarized with this table:     Expr  TF 0.11 (py2)  TF 0.11 (py3)  TF 1.0 (py2)  TF 1.0 (py3)      tf.div(3,4)  0  0  0  0    tf.div(-3,4)  0  0  -1  -1    tf.mod(-3,4)  -3  -3  1  1    -3/4  0  -0.75  -1  -0.75    -3/4tf.divide(-3,4)  N/A  N/A  -0.75  -1     The old and new behavior of rounding can be summarized with this table:     Input  Python  NumPy  C++ round()  TensorFlow 0.11(floor(x+.5))  TensorFlow 1.0      -3.5  -4  -4  -4  -3  -4    -2.5  -2  -2  -3  -2  -2    -1.5  -2  -2  -2  -1  -2    -0.5  0  0  -1  0  0    0.5  0  0  1  1  0    1.5  2  2  2  2  2    2.5  2  2  3  3  2    3.5  4  4  4  4  4", 
            "title": "Numeric differences"
        }, 
        {
            "location": "/install/migration/#numpy-matching-names", 
            "text": "Many functions have been renamed to match NumPy. This was done to make the\ntransition between NumPy and TensorFlow as easy as possible. There are still\nnumerous cases where functions do not match, so this is far from a hard and\nfast rule, but we have removed several commonly noticed inconsistencies.   tf.inv  should be renamed to  tf.reciprocal  This was done to avoid confusion with NumPy s matrix inverse  np.inv    tf.list_diff  should be renamed to  tf.setdiff1d    tf.listdiff  should be renamed to  tf.setdiff1d    tf.mul  should be renamed to  tf.multiply    tf.neg  should be renamed to  tf.negative    tf.select  should be renamed to  tf.where  tf.where  now takes 3 arguments or 1 argument, just like  np.where    tf.sub  should be renamed to  tf.subtract", 
            "title": "NumPy matching names"
        }, 
        {
            "location": "/install/migration/#numpy-matching-arguments", 
            "text": "Arguments for certain TensorFlow 1.0 methods now match arguments in certain\nNumPy methods.  To achieve this, TensorFlow 1.0 has changed keyword arguments\nand reordered some arguments. Notably, TensorFlow 1.0 now uses  axis  rather\nthan  dimension . TensorFlow 1.0 aims to keep the tensor argument first on\noperations that modify Tensors. (see the  tf.concat  change).   tf.argmax  keyword argument  dimension  should be renamed to  axis    tf.argmin  keyword argument  dimension  should be renamed to  axis    tf.concat  keyword argument  concat_dim  should be renamed to  axis  arguments have been reordered to  tf.concat(values, axis, name='concat') .    tf.count_nonzero  keyword argument  reduction_indices  should be renamed to  axis    tf.expand_dims  keyword argument  dim  should be renamed to  axis    tf.reduce_all  keyword argument  reduction_indices  should be renamed to  axis    tf.reduce_any  keyword argument  reduction_indices  should be renamed to  axis    tf.reduce_join  keyword argument  reduction_indices  should be renamed to  axis    tf.reduce_logsumexp  keyword argument  reduction_indices  should be renamed to  axis    tf.reduce_max  keyword argument  reduction_indices  should be renamed to  axis    tf.reduce_mean  keyword argument  reduction_indices  should be renamed to  axis    tf.reduce_min  keyword argument  reduction_indices  should be renamed to  axis    tf.reduce_prod  keyword argument  reduction_indices  should be renamed to  axis    tf.reduce_sum  keyword argument  reduction_indices  should be renamed to  axis    tf.reverse  tf.reverse  used to take a 1D  bool  tensor to control which dimensions were reversed. Now we use a Tensor of axis indices.  For example  tf.reverse(a, [True, False, True])  now must be  tf.reverse(a, [0, 2])    tf.reverse_sequence  keyword argument  batch_dim  should be renamed to  batch_axis  keyword argument  seq_dim  should be renamed to  seq_axis    tf.sparse_concat  keyword argument  concat_dim  should be renamed to  axis    tf.sparse_reduce_sum  keyword argument  reduction_axes  should be renamed to  axis    tf.sparse_reduce_sum_sparse  keyword argument  reduction_axes  should be renamed to  axis    tf.sparse_split  keyword argument  split_dim  should be renamed to  axis  arguments have been reordered to  tf.sparse_split(keyword_required=KeywordRequired(), sp_input=None, num_split=None, axis=None, name=None, split_dim=None) .    tf.split  keyword argument  split_dim  should be renamed to  axis  keyword argument  num_split  should be renamed to  num_or_size_splits  arguments have been reordered to  tf.split(value, num_or_size_splits, axis=0, num=None, name='split') .    tf.squeeze  keyword argument  squeeze_dims  should be renamed to  axis    tf.svd  arguments have been reordered to  tf.svd(tensor, full_matrices=False, compute_uv=True, name=None) .", 
            "title": "NumPy matching arguments"
        }, 
        {
            "location": "/install/migration/#simplified-math-variants", 
            "text": "Batched versions of math operations have been removed. Now the functionality is\ncontained in the non-batched versions. Similarly, tf.complex_abs  has had its\nfunctionality moved to  tf.abs   tf.batch_band_part  should be renamed to  tf.band_part    tf.batch_cholesky  should be renamed to  tf.cholesky    tf.batch_cholesky_solve  should be renamed to  tf.cholesky_solve    tf.batch_fft  should be renamed to  tf.fft    tf.batch_fft3d  should be renamed to  tf.fft3d    tf.batch_ifft  should be renamed to  tf.ifft    tf.batch_ifft2d  should be renamed to  tf.ifft2d    tf.batch_ifft3d  should be renamed to  tf.ifft3d    tf.batch_matmul  should be renamed to  tf.matmul    tf.batch_matrix_determinant  should be renamed to  tf.matrix_determinant    tf.batch_matrix_diag  should be renamed to  tf.matrix_diag    tf.batch_matrix_inverse  should be renamed to  tf.matrix_inverse    tf.batch_matrix_solve  should be renamed to  tf.matrix_solve    tf.batch_matrix_solve_ls  should be renamed to  tf.matrix_solve_ls    tf.batch_matrix_transpose  should be renamed to  tf.matrix_transpose    tf.batch_matrix_triangular_solve  should be renamed to  tf.matrix_triangular_solve    tf.batch_self_adjoint_eig  should be renamed to  tf.self_adjoint_eig    tf.batch_self_adjoint_eigvals  should be renamed to  tf.self_adjoint_eigvals    tf.batch_set_diag  should be renamed to  tf.set_diag    tf.batch_svd  should be renamed to  tf.svd    tf.complex_abs  should be renamed to  tf.abs", 
            "title": "Simplified math variants"
        }, 
        {
            "location": "/install/migration/#misc-changes", 
            "text": "Several other changes have been made, including the following:   tf.image.per_image_whitening  should be renamed to  tf.image.per_image_standardization    tf.nn.sigmoid_cross_entropy_with_logits  arguments have been reordered to  tf.nn.sigmoid_cross_entropy_with_logits(_sentinel=None, labels=None, logits=None, name=None) .    tf.nn.softmax_cross_entropy_with_logits  arguments have been reordered to  tf.nn.softmax_cross_entropy_with_logits(_sentinel=None, labels=None, logits=None, dim=-1, name=None) .    tf.nn.sparse_softmax_cross_entropy_with_logits  arguments have been reordered to  tf.nn.sparse_softmax_cross_entropy_with_logits(_sentinel=None, labels=None, logits=None, name=None) .    tf.ones_initializer  should be changed to a function call i.e.  tf.ones_initializer()    tf.pack  should be renamed to  tf.stack    tf.round  The semantics of  tf.round  now match Banker s rounding.    tf.unpack  should be renamed to  tf.unstack    tf.zeros_initializer  should be changed to a function call i.e.  tf.zeros_initializer()", 
            "title": "Misc Changes"
        }, 
        {
            "location": "/install/install_java/", 
            "text": "Installing TensorFlow for Java\n\n\nTensorFlow provides APIs for use in Java programs. These APIs are particularly\nwell-suited to loading models created in Python and executing them within a\nJava application. This guide explains how to install\n\nTensorFlow for Java\n\nand use it in a Java application.\n\n\nWARNING:\n The TensorFlow Java API is \nnot\n covered by the TensorFlow\n\nAPI stability guarantees\n.\n\n\nSupported Platforms\n\n\nTensorFlow for Java is supported on the following operating systems:\n\n\n\n\nLinux\n\n\nMac OS X\n\n\nWindows\n\n\nAndroid\n\n\n\n\nThe installation instructions for Android are in a separate\n\nAndroid TensorFlow Support page\n.\nAfter installation, please see this\n\ncomplete example\n\nof TensorFlow on Android.\n\n\nUsing TensorFlow with a Maven project\n\n\nIf your project uses \nApache Maven\n, then add the\nfollowing to the project\ns \npom.xml\n to use the TensorFlow Java APIs:\n\n\ndependency\n\n  \ngroupId\norg.tensorflow\n/groupId\n\n  \nartifactId\ntensorflow\n/artifactId\n\n  \nversion\n1.3.0\n/version\n\n\n/dependency\n\n\n\n\n\nThat\ns all.\n\n\nExample\n\n\nAs an example, these steps will create a Maven project that uses TensorFlow:\n\n\n\n\n\n\nCreate the project\ns \npom.xml\n:\n\n\n \nproject\n\n     \nmodelVersion\n4.0.0\n/modelVersion\n\n     \ngroupId\norg.myorg\n/groupId\n\n     \nartifactId\nhellotf\n/artifactId\n\n     \nversion\n1.0-SNAPSHOT\n/version\n\n     \nproperties\n\n       \nexec.mainClass\nHelloTF\n/exec.mainClass\n\n       \n!-- The sample code requires at least JDK 1.7. --\n\n       \n!-- The maven compiler plugin defaults to a lower version --\n\n       \nmaven.compiler.source\n1.7\n/maven.compiler.source\n\n       \nmaven.compiler.target\n1.7\n/maven.compiler.target\n\n     \n/properties\n\n     \ndependencies\n\n       \ndependency\n\n         \ngroupId\norg.tensorflow\n/groupId\n\n         \nartifactId\ntensorflow\n/artifactId\n\n         \nversion\n1.3.0\n/version\n\n       \n/dependency\n\n     \n/dependencies\n\n \n/project\n\n\n\n\n\n\n\n\nCreate the source file (\nsrc/main/java/HelloTF.java\n):\n\n\nimport org.tensorflow.Graph;\nimport org.tensorflow.Session;\nimport org.tensorflow.Tensor;\nimport org.tensorflow.TensorFlow;\n\npublic class HelloTF {\n  public static void main(String[] args) throws Exception {\n    try (Graph g = new Graph()) {\n      final String value = \"Hello from \" + TensorFlow.version();\n\n      // Construct the computation graph with a single operation, a constant\n      // named \"MyConst\" with a value \"value\".\n      try (Tensor t = Tensor.create(value.getBytes(\"UTF-8\"))) {\n        // The Java API doesn't yet include convenience functions for adding operations.\n        g.opBuilder(\"Const\", \"MyConst\").setAttr(\"dtype\", t.dataType()).setAttr(\"value\", t).build();\n      }\n\n      // Execute the \"MyConst\" operation in a Session.\n      try (Session s = new Session(g);\n           Tensor output = s.runner().fetch(\"MyConst\").run().get(0)) {\n        System.out.println(new String(output.bytesValue(), \"UTF-8\"));\n      }\n    }\n  }\n}\n\n\n\n\n\n\n\nCompile and execute:\n\n\n # Use -q to hide logging from the mvn tool\n \nmvn -q compile exec:java\n\n\n\n\n\n\nThe preceding command should output \nHello from \nversion\n. If it\ndoes, you\nve successfully set up TensorFlow for Java and are ready to use it in\nMaven projects. If not, check\n\nStack Overflow\n\nfor possible solutions.  You can skip reading the rest of this document.\n\n\nUsing TensorFlow with JDK\n\n\nThis section describes how to use TensorFlow using the \njava\n and \njavac\n\ncommands from a JDK installation. If your project uses Apache Maven, then\nrefer to the simpler instructions above instead.\n\n\nInstall on Linux or Mac OS\n\n\nTake the following steps to install TensorFlow for Java on Linux or Mac OS:\n\n\n\n\n\n\nDownload\n     \nlibtensorflow.jar\n,\n     which is the TensorFlow Java Archive (JAR).\n\n\n\n\n\n\nDecide whether you will run TensorFlow for Java on CPU(s) only or with\n     the help of GPU(s). To help you decide, read the section entitled\n     \nDetermine which TensorFlow to install\n in one of the following guides:\n\n\n\n\n@{$install_linux#determine_which_tensorflow_to_install$Installing TensorFlow on Linux}\n\n\n@{$install_mac#determine_which_tensorflow_to_install$Installing TensorFlow on Mac OS}\n\n\n\n\n\n\n\n\nDownload and extract the appropriate Java Native Interface (JNI)\n     file for your operating system and processor support by running the\n     following shell commands:\n\n\n TF_TYPE=\"cpu\" # Default processor is CPU. If you want GPU, set to \"gpu\"\n OS=$(uname -s | tr '[:upper:]' '[:lower:]')\n mkdir -p ./jni\n curl -L \\\n   \"https://storage.googleapis.com/tensorflow/libtensorflow/libtensorflow_jni-${TF_TYPE}-${OS}-x86_64-1.3.0.tar.gz\" |\n   tar -xz -C ./jni\n\n\n\n\n\n\n\nInstall on Windows\n\n\nTake the following steps to install TensorFlow for Java on Windows:\n\n\n\n\nDownload\n     \nlibtensorflow.jar\n,\n     which is the TensorFlow Java Archive (JAR).\n\n\nDownload the following Java Native Interface (JNI) file appropriate for\n     \nTensorFlow for Java on Windows\n.\n\n\nExtract this .zip file.\n\n\n\n\nValidate the installation\n\n\nAfter installing TensorFlow for Java, validate your installation by entering\nthe following code into a file named \nHelloTF.java\n:\n\n\nimport org.tensorflow.Graph;\nimport org.tensorflow.Session;\nimport org.tensorflow.Tensor;\nimport org.tensorflow.TensorFlow;\n\npublic class HelloTF {\n  public static void main(String[] args) throws Exception {\n    try (Graph g = new Graph()) {\n      final String value = \nHello from \n + TensorFlow.version();\n\n      // Construct the computation graph with a single operation, a constant\n      // named \nMyConst\n with a value \nvalue\n.\n      try (Tensor t = Tensor.create(value.getBytes(\nUTF-8\n))) {\n        // The Java API doesn't yet include convenience functions for adding operations.\n        g.opBuilder(\nConst\n, \nMyConst\n).setAttr(\ndtype\n, t.dataType()).setAttr(\nvalue\n, t).build();\n      }\n\n      // Execute the \nMyConst\n operation in a Session.\n      try (Session s = new Session(g);\n           Tensor output = s.runner().fetch(\nMyConst\n).run().get(0)) {\n        System.out.println(new String(output.bytesValue(), \nUTF-8\n));\n      }\n    }\n  }\n}\n\n\n\n\nAnd use the instructions below to compile and run \nHelloTF.java\n.\n\n\nCompiling\n\n\nWhen compiling a Java program that uses TensorFlow, the downloaded \n.jar\n\nmust be part of your \nclasspath\n. For example, you can include the\ndownloaded \n.jar\n in your \nclasspath\n by using the \n-cp\n compilation flag\nas follows:\n\n\njavac -cp libtensorflow-1.3.0.jar HelloTF.java\n\n\n\nRunning\n\n\nTo execute a Java program that depends on TensorFlow, ensure that the following\ntwo files are available to the JVM:\n\n\n\n\nthe downloaded \n.jar\n file\n\n\nthe extracted JNI library\n\n\n\n\nFor example, the following command line executes the \nHelloTF\n program on Linux\nand Mac OS X:\n\n\njava -cp libtensorflow-1.3.0.jar:. -Djava.library.path=./jni HelloTF\n\n\n\nAnd the following command line executes the \nHelloTF\n program on Windows:\n\n\njava -cp libtensorflow-1.3.0.jar;. -Djava.library.path=jni HelloTF\n\n\n\nIf the program prints \nHello from \nversion\n, you\nve successfully\ninstalled TensorFlow for Java and are ready to use the API.  If the program\noutputs something else, check\n\nStack Overflow\n for\npossible solutions.\n\n\nAdvanced Example\n\n\nFor a more sophisticated example, see\n\nLabelImage.java\n,\nwhich recognizes objects in an image.\n\n\nBuilding from source code\n\n\nTensorFlow is open-source. You may build TensorFlow for Java from the\nTensorFlow source code by following the instructions in a\n\nseparate document\n.", 
            "title": "1.7 \u5b89\u88c5TensorFlow for Java"
        }, 
        {
            "location": "/install/install_java/#installing-tensorflow-for-java", 
            "text": "TensorFlow provides APIs for use in Java programs. These APIs are particularly\nwell-suited to loading models created in Python and executing them within a\nJava application. This guide explains how to install TensorFlow for Java \nand use it in a Java application.  WARNING:  The TensorFlow Java API is  not  covered by the TensorFlow API stability guarantees .", 
            "title": "Installing TensorFlow for Java"
        }, 
        {
            "location": "/install/install_java/#supported-platforms", 
            "text": "TensorFlow for Java is supported on the following operating systems:   Linux  Mac OS X  Windows  Android   The installation instructions for Android are in a separate Android TensorFlow Support page .\nAfter installation, please see this complete example \nof TensorFlow on Android.", 
            "title": "Supported Platforms"
        }, 
        {
            "location": "/install/install_java/#using-tensorflow-with-a-maven-project", 
            "text": "If your project uses  Apache Maven , then add the\nfollowing to the project s  pom.xml  to use the TensorFlow Java APIs:  dependency \n   groupId org.tensorflow /groupId \n   artifactId tensorflow /artifactId \n   version 1.3.0 /version  /dependency   That s all.", 
            "title": "Using TensorFlow with a Maven project"
        }, 
        {
            "location": "/install/install_java/#example", 
            "text": "As an example, these steps will create a Maven project that uses TensorFlow:    Create the project s  pom.xml :    project \n      modelVersion 4.0.0 /modelVersion \n      groupId org.myorg /groupId \n      artifactId hellotf /artifactId \n      version 1.0-SNAPSHOT /version \n      properties \n        exec.mainClass HelloTF /exec.mainClass \n        !-- The sample code requires at least JDK 1.7. -- \n        !-- The maven compiler plugin defaults to a lower version -- \n        maven.compiler.source 1.7 /maven.compiler.source \n        maven.compiler.target 1.7 /maven.compiler.target \n      /properties \n      dependencies \n        dependency \n          groupId org.tensorflow /groupId \n          artifactId tensorflow /artifactId \n          version 1.3.0 /version \n        /dependency \n      /dependencies \n  /project     Create the source file ( src/main/java/HelloTF.java ):  import org.tensorflow.Graph;\nimport org.tensorflow.Session;\nimport org.tensorflow.Tensor;\nimport org.tensorflow.TensorFlow;\n\npublic class HelloTF {\n  public static void main(String[] args) throws Exception {\n    try (Graph g = new Graph()) {\n      final String value = \"Hello from \" + TensorFlow.version();\n\n      // Construct the computation graph with a single operation, a constant\n      // named \"MyConst\" with a value \"value\".\n      try (Tensor t = Tensor.create(value.getBytes(\"UTF-8\"))) {\n        // The Java API doesn't yet include convenience functions for adding operations.\n        g.opBuilder(\"Const\", \"MyConst\").setAttr(\"dtype\", t.dataType()).setAttr(\"value\", t).build();\n      }\n\n      // Execute the \"MyConst\" operation in a Session.\n      try (Session s = new Session(g);\n           Tensor output = s.runner().fetch(\"MyConst\").run().get(0)) {\n        System.out.println(new String(output.bytesValue(), \"UTF-8\"));\n      }\n    }\n  }\n}    Compile and execute:   # Use -q to hide logging from the mvn tool\n  mvn -q compile exec:java    The preceding command should output  Hello from  version . If it\ndoes, you ve successfully set up TensorFlow for Java and are ready to use it in\nMaven projects. If not, check Stack Overflow \nfor possible solutions.  You can skip reading the rest of this document.", 
            "title": "Example"
        }, 
        {
            "location": "/install/install_java/#using-tensorflow-with-jdk", 
            "text": "This section describes how to use TensorFlow using the  java  and  javac \ncommands from a JDK installation. If your project uses Apache Maven, then\nrefer to the simpler instructions above instead.", 
            "title": "Using TensorFlow with JDK"
        }, 
        {
            "location": "/install/install_java/#install-on-linux-or-mac-os", 
            "text": "Take the following steps to install TensorFlow for Java on Linux or Mac OS:    Download\n      libtensorflow.jar ,\n     which is the TensorFlow Java Archive (JAR).    Decide whether you will run TensorFlow for Java on CPU(s) only or with\n     the help of GPU(s). To help you decide, read the section entitled\n      Determine which TensorFlow to install  in one of the following guides:   @{$install_linux#determine_which_tensorflow_to_install$Installing TensorFlow on Linux}  @{$install_mac#determine_which_tensorflow_to_install$Installing TensorFlow on Mac OS}     Download and extract the appropriate Java Native Interface (JNI)\n     file for your operating system and processor support by running the\n     following shell commands:   TF_TYPE=\"cpu\" # Default processor is CPU. If you want GPU, set to \"gpu\"\n OS=$(uname -s | tr '[:upper:]' '[:lower:]')\n mkdir -p ./jni\n curl -L \\\n   \"https://storage.googleapis.com/tensorflow/libtensorflow/libtensorflow_jni-${TF_TYPE}-${OS}-x86_64-1.3.0.tar.gz\" |\n   tar -xz -C ./jni", 
            "title": "Install on Linux or Mac OS"
        }, 
        {
            "location": "/install/install_java/#install-on-windows", 
            "text": "Take the following steps to install TensorFlow for Java on Windows:   Download\n      libtensorflow.jar ,\n     which is the TensorFlow Java Archive (JAR).  Download the following Java Native Interface (JNI) file appropriate for\n      TensorFlow for Java on Windows .  Extract this .zip file.", 
            "title": "Install on Windows"
        }, 
        {
            "location": "/install/install_java/#validate-the-installation", 
            "text": "After installing TensorFlow for Java, validate your installation by entering\nthe following code into a file named  HelloTF.java :  import org.tensorflow.Graph;\nimport org.tensorflow.Session;\nimport org.tensorflow.Tensor;\nimport org.tensorflow.TensorFlow;\n\npublic class HelloTF {\n  public static void main(String[] args) throws Exception {\n    try (Graph g = new Graph()) {\n      final String value =  Hello from   + TensorFlow.version();\n\n      // Construct the computation graph with a single operation, a constant\n      // named  MyConst  with a value  value .\n      try (Tensor t = Tensor.create(value.getBytes( UTF-8 ))) {\n        // The Java API doesn't yet include convenience functions for adding operations.\n        g.opBuilder( Const ,  MyConst ).setAttr( dtype , t.dataType()).setAttr( value , t).build();\n      }\n\n      // Execute the  MyConst  operation in a Session.\n      try (Session s = new Session(g);\n           Tensor output = s.runner().fetch( MyConst ).run().get(0)) {\n        System.out.println(new String(output.bytesValue(),  UTF-8 ));\n      }\n    }\n  }\n}  And use the instructions below to compile and run  HelloTF.java .", 
            "title": "Validate the installation"
        }, 
        {
            "location": "/install/install_java/#compiling", 
            "text": "When compiling a Java program that uses TensorFlow, the downloaded  .jar \nmust be part of your  classpath . For example, you can include the\ndownloaded  .jar  in your  classpath  by using the  -cp  compilation flag\nas follows:  javac -cp libtensorflow-1.3.0.jar HelloTF.java", 
            "title": "Compiling"
        }, 
        {
            "location": "/install/install_java/#running", 
            "text": "To execute a Java program that depends on TensorFlow, ensure that the following\ntwo files are available to the JVM:   the downloaded  .jar  file  the extracted JNI library   For example, the following command line executes the  HelloTF  program on Linux\nand Mac OS X:  java -cp libtensorflow-1.3.0.jar:. -Djava.library.path=./jni HelloTF  And the following command line executes the  HelloTF  program on Windows:  java -cp libtensorflow-1.3.0.jar;. -Djava.library.path=jni HelloTF  If the program prints  Hello from  version , you ve successfully\ninstalled TensorFlow for Java and are ready to use the API.  If the program\noutputs something else, check Stack Overflow  for\npossible solutions.", 
            "title": "Running"
        }, 
        {
            "location": "/install/install_java/#advanced-example", 
            "text": "For a more sophisticated example, see LabelImage.java ,\nwhich recognizes objects in an image.", 
            "title": "Advanced Example"
        }, 
        {
            "location": "/install/install_java/#building-from-source-code", 
            "text": "TensorFlow is open-source. You may build TensorFlow for Java from the\nTensorFlow source code by following the instructions in a separate document .", 
            "title": "Building from source code"
        }, 
        {
            "location": "/install/install_c/", 
            "text": "Installing TensorFlow for C\n\n\nTensorFlow provides a C API defined in\n\nc_api.h\n,\nwhich is suitable for\n\nbuilding bindings for other languages\n.\nThe API leans towards simplicity and uniformity rather than convenience.\n\n\nSupported Platforms\n\n\nYou may install TensorFlow for C on the following operating systems:\n\n\n\n\nLinux\n\n\nMac OS X\n\n\n\n\nInstallation\n\n\nTake the following steps to install the TensorFlow for C library and\nenable TensorFlow for C:\n\n\n\n\n\n\nDecide whether you will run TensorFlow for C on CPU(s) only or\n     with the help of GPU(s). To help you decide, read the section\n     entitled \nDetermine which TensorFlow to install\n in one of the\n     following guides:\n\n\n\n\n@{$install_linux#determine_which_tensorflow_to_install$Installing TensorFlow on Linux}\n\n\n@{$install_mac#determine_which_tensorflow_to_install$Installing TensorFlow on Mac OS}\n\n\n\n\n\n\n\n\nDownload and extract the TensorFlow C library into \n/usr/local/lib\n by\n     invoking the following shell commands:\n\n\n TF_TYPE=\"cpu\" # Change to \"gpu\" for GPU support\n OS=\"linux\" # Change to \"darwin\" for Mac OS\n TARGET_DIRECTORY=\"/usr/local\"\n curl -L \\\n   \"https://storage.googleapis.com/tensorflow/libtensorflow/libtensorflow-${TF_TYPE}-${OS}-x86_64-1.3.0.tar.gz\" |\n   sudo tar -C $TARGET_DIRECTORY -xz\n\n\n\nThe \ntar\n command extracts the TensorFlow C library into the \nlib\n\n subdirectory of \nTARGET_DIRECTORY\n. For example, specifying \n/usr/local\n\n as \nTARGET_DIRECTORY\n causes \ntar\n to extract the TensorFlow C library\n into \n/usr/local/lib\n.\n\n\nIf you\nd prefer to extract the library into a different directory,\n adjust \nTARGET_DIRECTORY\n accordingly.\n\n\n\n\n\n\nIn Step 2, if you specified a system directory (for example, \n/usr/local\n)\n     as the \nTARGET_DIRECTORY\n, then run \nldconfig\n to configure the linker.\n     For example:\n\n\nsudo ldconfig\n\n\nIf you assigned a \nTARGET_DIRECTORY\n other than a system\n directory (for example, \n~/mydir\n), then you must append the extraction\n directory (for example, \n~/mydir/lib\n) to two environment variables.\n For example:\n\n\n \nexport LIBRARY_PATH=$LIBRARY_PATH:~/mydir/lib\n # For both Linux and Mac OS X\n \nexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:~/mydir/lib\n # For Linux only\n \nexport DYLD_LIBRARY_PATH=$DYLD_LIBRARY_PATH:~/mydir/lib\n # For Mac OS X only\n\n\n\n\n\n\nValidate your installation\n\n\nAfter installing TensorFlow for C, enter the following code into a file named\n\nhello_tf.c\n:\n\n\n#include \nstdio.h\n\n#include \ntensorflow/c/c_api.h\n\n\nint main() {\n  printf(\nHello from TensorFlow C library version %s\\n\n, TF_Version());\n  return 0;\n}\n\n\n\n\nBuild and Run\n\n\nBuild \nhello_tf.c\n by invoking the following command:\n\n\ngcc hello_tf.c\n\n\n\nRunning the resulting executable should output the following message:\n\n\na.out\n\nHello from TensorFlow C library version \nnumber\n\n\n\nTroubleshooting\n\n\nIf building the program fails, the most likely culprit is that \ngcc\n cannot\nfind the TensorFlow C library.  One way to fix this problem is to specify\nthe \n-I\n and \n-L\n options to \ngcc\n.  For example, if the \nTARGET_LIBRARY\n\nwas \n/usr/local\n, you would invoke \ngcc\n as follows:\n\n\ngcc -I/usr/local/include -L/usr/local/lib hello_tf.c -ltensorflow\n\n\n\nIf executing \na.out\n fails, ask yourself the following questions:\n\n\n\n\nDid the program build without error?\n\n\nHave you assigned the correct directory to the environment variables\n    noted in Step 3 of \nInstallation\n?\n\n\nDid you export those environment variables?\n\n\n\n\nIf you are still seeing build or execution error messages, search (or post to)\n\nStackOverflow\n for\npossible solutions.", 
            "title": "1.8 \u5b89\u88c5TensorFlow for C"
        }, 
        {
            "location": "/install/install_c/#installing-tensorflow-for-c", 
            "text": "TensorFlow provides a C API defined in c_api.h ,\nwhich is suitable for building bindings for other languages .\nThe API leans towards simplicity and uniformity rather than convenience.", 
            "title": "Installing TensorFlow for C"
        }, 
        {
            "location": "/install/install_c/#supported-platforms", 
            "text": "You may install TensorFlow for C on the following operating systems:   Linux  Mac OS X", 
            "title": "Supported Platforms"
        }, 
        {
            "location": "/install/install_c/#installation", 
            "text": "Take the following steps to install the TensorFlow for C library and\nenable TensorFlow for C:    Decide whether you will run TensorFlow for C on CPU(s) only or\n     with the help of GPU(s). To help you decide, read the section\n     entitled  Determine which TensorFlow to install  in one of the\n     following guides:   @{$install_linux#determine_which_tensorflow_to_install$Installing TensorFlow on Linux}  @{$install_mac#determine_which_tensorflow_to_install$Installing TensorFlow on Mac OS}     Download and extract the TensorFlow C library into  /usr/local/lib  by\n     invoking the following shell commands:   TF_TYPE=\"cpu\" # Change to \"gpu\" for GPU support\n OS=\"linux\" # Change to \"darwin\" for Mac OS\n TARGET_DIRECTORY=\"/usr/local\"\n curl -L \\\n   \"https://storage.googleapis.com/tensorflow/libtensorflow/libtensorflow-${TF_TYPE}-${OS}-x86_64-1.3.0.tar.gz\" |\n   sudo tar -C $TARGET_DIRECTORY -xz  The  tar  command extracts the TensorFlow C library into the  lib \n subdirectory of  TARGET_DIRECTORY . For example, specifying  /usr/local \n as  TARGET_DIRECTORY  causes  tar  to extract the TensorFlow C library\n into  /usr/local/lib .  If you d prefer to extract the library into a different directory,\n adjust  TARGET_DIRECTORY  accordingly.    In Step 2, if you specified a system directory (for example,  /usr/local )\n     as the  TARGET_DIRECTORY , then run  ldconfig  to configure the linker.\n     For example:  sudo ldconfig  If you assigned a  TARGET_DIRECTORY  other than a system\n directory (for example,  ~/mydir ), then you must append the extraction\n directory (for example,  ~/mydir/lib ) to two environment variables.\n For example:    export LIBRARY_PATH=$LIBRARY_PATH:~/mydir/lib  # For both Linux and Mac OS X\n  export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:~/mydir/lib  # For Linux only\n  export DYLD_LIBRARY_PATH=$DYLD_LIBRARY_PATH:~/mydir/lib  # For Mac OS X only", 
            "title": "Installation"
        }, 
        {
            "location": "/install/install_c/#validate-your-installation", 
            "text": "After installing TensorFlow for C, enter the following code into a file named hello_tf.c :  #include  stdio.h \n#include  tensorflow/c/c_api.h \n\nint main() {\n  printf( Hello from TensorFlow C library version %s\\n , TF_Version());\n  return 0;\n}", 
            "title": "Validate your installation"
        }, 
        {
            "location": "/install/install_c/#build-and-run", 
            "text": "Build  hello_tf.c  by invoking the following command:  gcc hello_tf.c  Running the resulting executable should output the following message:  a.out \nHello from TensorFlow C library version  number", 
            "title": "Build and Run"
        }, 
        {
            "location": "/install/install_c/#troubleshooting", 
            "text": "If building the program fails, the most likely culprit is that  gcc  cannot\nfind the TensorFlow C library.  One way to fix this problem is to specify\nthe  -I  and  -L  options to  gcc .  For example, if the  TARGET_LIBRARY \nwas  /usr/local , you would invoke  gcc  as follows:  gcc -I/usr/local/include -L/usr/local/lib hello_tf.c -ltensorflow  If executing  a.out  fails, ask yourself the following questions:   Did the program build without error?  Have you assigned the correct directory to the environment variables\n    noted in Step 3 of  Installation ?  Did you export those environment variables?   If you are still seeing build or execution error messages, search (or post to) StackOverflow  for\npossible solutions.", 
            "title": "Troubleshooting"
        }, 
        {
            "location": "/install/install_go/", 
            "text": "Installing TensorFlow for Go\n\n\nTensorFlow provides APIs for use in Go programs. These APIs are particularly\nwell-suited to loading models created in Python and executing them within\na Go application. This guide explains how to install and set up the\n\nTensorFlow Go package\n.\n\n\nWARNING:\n The TensorFlow Go API is \nnot\n covered by the TensorFlow\n\nAPI stability guarantees\n.\n\n\nSupported Platforms\n\n\nYou may install TensorFlow for Go on the following operating systems:\n\n\n\n\nLinux\n\n\nMac OS X\n\n\n\n\nInstallation\n\n\nTensorFlow for Go depends on the TensorFlow C library. Take the following\nsteps to install this library and enable TensorFlow for Go:\n\n\n\n\n\n\nDecide whether you will run TensorFlow for Go on CPU(s) only or with\n     the help of GPU(s). To help you decide, read the section entitled\n     \nDetermine which TensorFlow to install\n in one of the following guides:\n\n\n\n\n@{$install_linux#determine_which_tensorflow_to_install$Installing TensorFlow on Linux}\n\n\n@{$install_mac#determine_which_tensorflow_to_install$Installing TensorFlow on Mac OS}\n\n\n\n\n\n\n\n\nDownload and extract the TensorFlow C library into \n/usr/local/lib\n by\n     invoking the following shell commands:\n\n\n TF_TYPE=\"cpu\" # Change to \"gpu\" for GPU support\n TARGET_DIRECTORY='/usr/local'\n curl -L \\\n   \"https://storage.googleapis.com/tensorflow/libtensorflow/libtensorflow-${TF_TYPE}-$(go env GOOS)-x86_64-1.3.0.tar.gz\" |\n sudo tar -C $TARGET_DIRECTORY -xz\n\n\n\nThe \ntar\n command extracts the TensorFlow C library into the \nlib\n\n subdirectory of \nTARGET_DIRECTORY\n. For example, specifying \n/usr/local\n\n as \nTARGET_DIRECTORY\n causes \ntar\n to extract the TensorFlow C library\n into \n/usr/local/lib\n.\n\n\nIf you\nd prefer to extract the library into a different directory,\n adjust \nTARGET_DIRECTORY\n accordingly.\n\n\n\n\n\n\nIn Step 2, if you specified a system directory (for example, \n/usr/local\n)\n     as the \nTARGET_DIRECTORY\n, then run \nldconfig\n to configure the linker.\n     For example:\n\n\nsudo ldconfig\n\n\nIf you assigned a \nTARGET_DIRECTORY\n other than a system\n directory (for example, \n~/mydir\n), then you must append the extraction\n directory (for example, \n~/mydir/lib\n) to two environment variables\n as follows:\n\n\n \nexport LIBRARY_PATH=$LIBRARY_PATH:~/mydir/lib\n # For both Linux and Mac OS X\n \nexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:~/mydir/lib\n # For Linux only\n \nexport DYLD_LIBRARY_PATH=$DYLD_LIBRARY_PATH:~/mydir/lib\n # For Mac OS X only\n\n\n\n\n\n\nNow that the TensorFlow C library is installed, invoke \ngo get\n as follows\n     to download the appropriate packages and their dependencies:\n\n\ngo get github.com/tensorflow/tensorflow/tensorflow/go\n\n\n\n\n\n\nInvoke \ngo test\n as follows to validate the TensorFlow for Go\n     installation:\n\n\ngo test github.com/tensorflow/tensorflow/tensorflow/go\n\n\n\n\n\n\nIf \ngo get\n or \ngo test\n generate error messages, search (or post to)\n\nStackOverflow\n\nfor possible solutions.\n\n\nHello World\n\n\nAfter installing TensorFlow for Go, enter the following code into a\nfile named \nhello_tf.go\n:\n\n\npackage main\n\nimport (\n    tf \ngithub.com/tensorflow/tensorflow/tensorflow/go\n\n    \ngithub.com/tensorflow/tensorflow/tensorflow/go/op\n\n    \nfmt\n\n)\n\nfunc main() {\n    // Construct a graph with an operation that produces a string constant.\n    s := op.NewScope()\n    c := op.Const(s, \nHello from TensorFlow version \n + tf.Version())\n    graph, err := s.Finalize()\n    if err != nil {\n        panic(err)\n    }\n\n    // Execute the graph in a session.\n    sess, err := tf.NewSession(graph, nil)\n    if err != nil {\n        panic(err)\n    }\n    output, err := sess.Run(nil, []tf.Output{c}, nil)\n    if err != nil {\n        panic(err)\n    }\n    fmt.Println(output[0].Value())\n}\n\n\n\n\nFor a more advanced example of TensorFlow in Go, look at the\n\nexample in the API documentation\n,\nwhich uses a pre-trained TensorFlow model to label contents of an image.\n\n\nRunning\n\n\nRun \nhello_tf.go\n by invoking the following command:\n\n\ngo run hello_tf.go\n\nHello from TensorFlow version \nnumber\n\n\n\nThe program might also generate multiple warning messages of the\nfollowing form, which you can ignore:\n\n\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library\nwasn't compiled to use *Type* instructions, but these are available on your\nmachine and could speed up CPU computations.\n\n\n\nBuilding from source code\n\n\nTensorFlow is open-source. You may build TensorFlow for Go from the\nTensorFlow source code by following the instructions in a\n\nseparate document\n.", 
            "title": "1.9 \u5b89\u88c5TensorFlow for Go"
        }, 
        {
            "location": "/install/install_go/#installing-tensorflow-for-go", 
            "text": "TensorFlow provides APIs for use in Go programs. These APIs are particularly\nwell-suited to loading models created in Python and executing them within\na Go application. This guide explains how to install and set up the TensorFlow Go package .  WARNING:  The TensorFlow Go API is  not  covered by the TensorFlow API stability guarantees .", 
            "title": "Installing TensorFlow for Go"
        }, 
        {
            "location": "/install/install_go/#supported-platforms", 
            "text": "You may install TensorFlow for Go on the following operating systems:   Linux  Mac OS X", 
            "title": "Supported Platforms"
        }, 
        {
            "location": "/install/install_go/#installation", 
            "text": "TensorFlow for Go depends on the TensorFlow C library. Take the following\nsteps to install this library and enable TensorFlow for Go:    Decide whether you will run TensorFlow for Go on CPU(s) only or with\n     the help of GPU(s). To help you decide, read the section entitled\n      Determine which TensorFlow to install  in one of the following guides:   @{$install_linux#determine_which_tensorflow_to_install$Installing TensorFlow on Linux}  @{$install_mac#determine_which_tensorflow_to_install$Installing TensorFlow on Mac OS}     Download and extract the TensorFlow C library into  /usr/local/lib  by\n     invoking the following shell commands:   TF_TYPE=\"cpu\" # Change to \"gpu\" for GPU support\n TARGET_DIRECTORY='/usr/local'\n curl -L \\\n   \"https://storage.googleapis.com/tensorflow/libtensorflow/libtensorflow-${TF_TYPE}-$(go env GOOS)-x86_64-1.3.0.tar.gz\" |\n sudo tar -C $TARGET_DIRECTORY -xz  The  tar  command extracts the TensorFlow C library into the  lib \n subdirectory of  TARGET_DIRECTORY . For example, specifying  /usr/local \n as  TARGET_DIRECTORY  causes  tar  to extract the TensorFlow C library\n into  /usr/local/lib .  If you d prefer to extract the library into a different directory,\n adjust  TARGET_DIRECTORY  accordingly.    In Step 2, if you specified a system directory (for example,  /usr/local )\n     as the  TARGET_DIRECTORY , then run  ldconfig  to configure the linker.\n     For example:  sudo ldconfig  If you assigned a  TARGET_DIRECTORY  other than a system\n directory (for example,  ~/mydir ), then you must append the extraction\n directory (for example,  ~/mydir/lib ) to two environment variables\n as follows:    export LIBRARY_PATH=$LIBRARY_PATH:~/mydir/lib  # For both Linux and Mac OS X\n  export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:~/mydir/lib  # For Linux only\n  export DYLD_LIBRARY_PATH=$DYLD_LIBRARY_PATH:~/mydir/lib  # For Mac OS X only    Now that the TensorFlow C library is installed, invoke  go get  as follows\n     to download the appropriate packages and their dependencies:  go get github.com/tensorflow/tensorflow/tensorflow/go    Invoke  go test  as follows to validate the TensorFlow for Go\n     installation:  go test github.com/tensorflow/tensorflow/tensorflow/go    If  go get  or  go test  generate error messages, search (or post to) StackOverflow \nfor possible solutions.", 
            "title": "Installation"
        }, 
        {
            "location": "/install/install_go/#hello-world", 
            "text": "After installing TensorFlow for Go, enter the following code into a\nfile named  hello_tf.go :  package main\n\nimport (\n    tf  github.com/tensorflow/tensorflow/tensorflow/go \n     github.com/tensorflow/tensorflow/tensorflow/go/op \n     fmt \n)\n\nfunc main() {\n    // Construct a graph with an operation that produces a string constant.\n    s := op.NewScope()\n    c := op.Const(s,  Hello from TensorFlow version   + tf.Version())\n    graph, err := s.Finalize()\n    if err != nil {\n        panic(err)\n    }\n\n    // Execute the graph in a session.\n    sess, err := tf.NewSession(graph, nil)\n    if err != nil {\n        panic(err)\n    }\n    output, err := sess.Run(nil, []tf.Output{c}, nil)\n    if err != nil {\n        panic(err)\n    }\n    fmt.Println(output[0].Value())\n}  For a more advanced example of TensorFlow in Go, look at the example in the API documentation ,\nwhich uses a pre-trained TensorFlow model to label contents of an image.", 
            "title": "Hello World"
        }, 
        {
            "location": "/install/install_go/#running", 
            "text": "Run  hello_tf.go  by invoking the following command:  go run hello_tf.go \nHello from TensorFlow version  number  The program might also generate multiple warning messages of the\nfollowing form, which you can ignore:  W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library\nwasn't compiled to use *Type* instructions, but these are available on your\nmachine and could speed up CPU computations.", 
            "title": "Running"
        }, 
        {
            "location": "/install/install_go/#building-from-source-code", 
            "text": "TensorFlow is open-source. You may build TensorFlow for Go from the\nTensorFlow source code by following the instructions in a separate document .", 
            "title": "Building from source code"
        }, 
        {
            "location": "/develop/getstarted/", 
            "text": "Getting Started\n\n\nFor a brief overview of TensorFlow programming fundamentals, see the following\nguide:\n\n\n\n\n@{$get_started/get_started$Getting Started with TensorFlow}\n\n\n\n\nMNIST has become the canonical dataset for trying out a new machine learning\ntoolkit.  We offer three guides that each demonstrate a different approach\nto training an MNIST model on TensorFlow:\n\n\n\n\n@{$mnist/beginners$MNIST for ML Beginners}, which introduces MNIST through\n    the high-level API.\n\n\n@{$mnist/pros$Deep MNIST for Experts}, which is more-in depth than\n    \nMNIST for ML Beginners,\n and assumes some familiarity with machine\n    learning concepts.\n\n\n@{$mnist/mechanics$TensorFlow Mechanics 101}, which introduces MNIST through\n    the low-level API.\n\n\n\n\nFor developers new to TensorFlow, the high-level API is a good place to start.\nTo learn about the high-level API, read the following guides:\n\n\n\n\n@{$get_started/estimator$tf.estimator Quickstart}, which introduces this\n    API.\n\n\n@{$get_started/input_fn$Building Input Functions},\n    which takes you into a somewhat more sophisticated use of this API.\n\n\n\n\nTensorBoard is a utility to visualize different aspects of machine learning.\nThe following guides explain how to use TensorBoard:\n\n\n\n\n@{$get_started/summaries_and_tensorboard$TensorBoard: Visualizing Learning},\n    which gets you started.\n\n\n@{$get_started/graph_viz$TensorBoard: Graph Visualization}, which explains\n    how to visualize the computational graph.  Graph visualization is typically\n    more useful for programmers using the low-level API.", 
            "title": "2.1.1 \u5feb\u901f\u5165\u95e8"
        }, 
        {
            "location": "/develop/getstarted/#getting-started", 
            "text": "For a brief overview of TensorFlow programming fundamentals, see the following\nguide:   @{$get_started/get_started$Getting Started with TensorFlow}   MNIST has become the canonical dataset for trying out a new machine learning\ntoolkit.  We offer three guides that each demonstrate a different approach\nto training an MNIST model on TensorFlow:   @{$mnist/beginners$MNIST for ML Beginners}, which introduces MNIST through\n    the high-level API.  @{$mnist/pros$Deep MNIST for Experts}, which is more-in depth than\n     MNIST for ML Beginners,  and assumes some familiarity with machine\n    learning concepts.  @{$mnist/mechanics$TensorFlow Mechanics 101}, which introduces MNIST through\n    the low-level API.   For developers new to TensorFlow, the high-level API is a good place to start.\nTo learn about the high-level API, read the following guides:   @{$get_started/estimator$tf.estimator Quickstart}, which introduces this\n    API.  @{$get_started/input_fn$Building Input Functions},\n    which takes you into a somewhat more sophisticated use of this API.   TensorBoard is a utility to visualize different aspects of machine learning.\nThe following guides explain how to use TensorBoard:   @{$get_started/summaries_and_tensorboard$TensorBoard: Visualizing Learning},\n    which gets you started.  @{$get_started/graph_viz$TensorBoard: Graph Visualization}, which explains\n    how to visualize the computational graph.  Graph visualization is typically\n    more useful for programmers using the low-level API.", 
            "title": "Getting Started"
        }, 
        {
            "location": "/develop/getstarted/getting-started-with-tensorflow/", 
            "text": "Getting Started With TensorFlow\n\n\nThis guide gets you started programming in TensorFlow. Before using this guide,\n@{$install$install TensorFlow}. To get the most out of\nthis guide, you should know the following:\n\n\n\n\nHow to program in Python.\n\n\nAt least a little bit about arrays.\n\n\nIdeally, something about machine learning. However, if you know little or\n    nothing about machine learning, then this is still the first guide you\n    should read.\n\n\n\n\nTensorFlow provides multiple APIs. The lowest level API\nTensorFlow Core\n\nprovides you with complete programming control. We recommend TensorFlow Core for\nmachine learning researchers and others who require fine levels of control over\ntheir models. The higher level APIs are built on top of TensorFlow Core. These\nhigher level APIs are typically easier to learn and use than TensorFlow Core. In\naddition, the higher level APIs make repetitive tasks easier and more consistent\nbetween different users. A high-level API like tf.estimator helps you manage\ndata sets, estimators, training and inference.\n\n\nThis guide begins with a tutorial on TensorFlow Core. Later, we\ndemonstrate how to implement the same model in tf.estimator. Knowing\nTensorFlow Core principles will give you a great mental model of how things are\nworking internally when you use the more compact higher level API.\n\n\nTensors\n\n\nThe central unit of data in TensorFlow is the \ntensor\n. A tensor consists of a\nset of primitive values shaped into an array of any number of dimensions. A\ntensor\ns \nrank\n is its number of dimensions. Here are some examples of\ntensors:\n\n\n3 # a rank 0 tensor; a scalar with shape []\n[1., 2., 3.] # a rank 1 tensor; a vector with shape [3]\n[[1., 2., 3.], [4., 5., 6.]] # a rank 2 tensor; a matrix with shape [2, 3]\n[[[1., 2., 3.]], [[7., 8., 9.]]] # a rank 3 tensor with shape [2, 1, 3]\n\n\n\n\nTensorFlow Core tutorial\n\n\nImporting TensorFlow\n\n\nThe canonical import statement for TensorFlow programs is as follows:\n\n\nimport tensorflow as tf\n\n\n\n\nThis gives Python access to all of TensorFlow\ns classes, methods, and symbols.\nMost of the documentation assumes you have already done this.\n\n\nThe Computational Graph\n\n\nYou might think of TensorFlow Core programs as consisting of two discrete\nsections:\n\n\n\n\nBuilding the computational graph.\n\n\nRunning the computational graph.\n\n\n\n\nA \ncomputational graph\n is a series of TensorFlow operations arranged into a\ngraph of nodes.\nLet\ns build a simple computational graph. Each node takes zero\nor more tensors as inputs and produces a tensor as an output. One type of node\nis a constant. Like all TensorFlow constants, it takes no inputs, and it outputs\na value it stores internally. We can create two floating point Tensors \nnode1\n\nand \nnode2\n as follows:\n\n\nnode1 = tf.constant(3.0, dtype=tf.float32)\nnode2 = tf.constant(4.0) # also tf.float32 implicitly\nprint(node1, node2)\n\n\n\n\nThe final print statement produces\n\n\nTensor(\nConst:0\n, shape=(), dtype=float32) Tensor(\nConst_1:0\n, shape=(), dtype=float32)\n\n\n\n\nNotice that printing the nodes does not output the values \n3.0\n and \n4.0\n as you\nmight expect. Instead, they are nodes that, when evaluated, would produce 3.0\nand 4.0, respectively. To actually evaluate the nodes, we must run the\ncomputational graph within a \nsession\n. A session encapsulates the control and\nstate of the TensorFlow runtime.\n\n\nThe following code creates a \nSession\n object and then invokes its \nrun\n method\nto run enough of the computational graph to evaluate \nnode1\n and \nnode2\n. By\nrunning the computational graph in a session as follows:\n\n\nsess = tf.Session()\nprint(sess.run([node1, node2]))\n\n\n\n\nwe see the expected values of 3.0 and 4.0:\n\n\n[3.0, 4.0]\n\n\n\n\nWe can build more complicated computations by combining \nTensor\n nodes with\noperations (Operations are also nodes). For example, we can add our two\nconstant nodes and produce a new graph as follows:\n\n\nfrom __future__ import print_function\nnode3 = tf.add(node1, node2)\nprint(\nnode3:\n, node3)\nprint(\nsess.run(node3):\n, sess.run(node3))\n\n\n\n\nThe last two print statements produce\n\n\nnode3: Tensor(\nAdd:0\n, shape=(), dtype=float32)\nsess.run(node3): 7.0\n\n\n\n\nTensorFlow provides a utility called TensorBoard that can display a picture of\nthe computational graph. Here is a screenshot showing how TensorBoard\nvisualizes the graph:\n\n\n\n\nAs it stands, this graph is not especially interesting because it always\nproduces a constant result. A graph can be parameterized to accept external\ninputs, known as \nplaceholders\n. A \nplaceholder\n is a promise to provide a\nvalue later.\n\n\na = tf.placeholder(tf.float32)\nb = tf.placeholder(tf.float32)\nadder_node = a + b  # + provides a shortcut for tf.add(a, b)\n\n\n\n\nThe preceding three lines are a bit like a function or a lambda in which we\ndefine two input parameters (a and b) and then an operation on them. We can\nevaluate this graph with multiple inputs by using the feed_dict argument to\nthe \nrun method\n\nto feed concrete values to the placeholders:\n\n\nprint(sess.run(adder_node, {a: 3, b: 4.5}))\nprint(sess.run(adder_node, {a: [1, 3], b: [2, 4]}))\n\n\n\n\nresulting in the output\n\n\n7.5\n[ 3.  7.]\n\n\n\n\nIn TensorBoard, the graph looks like this:\n\n\n\n\nWe can make the computational graph more complex by adding another operation.\nFor example,\n\n\nadd_and_triple = adder_node * 3.\nprint(sess.run(add_and_triple, {a: 3, b: 4.5}))\n\n\n\n\nproduces the output\n\n\n22.5\n\n\n\n\nThe preceding computational graph would look as follows in TensorBoard:\n\n\n\n\nIn machine learning we will typically want a model that can take arbitrary\ninputs, such as the one above.  To make the model trainable, we need to be able\nto modify the graph to get new outputs with the same input.  \nVariables\n allow\nus to add trainable parameters to a graph.  They are constructed with a type and\ninitial value:\n\n\nW = tf.Variable([.3], dtype=tf.float32)\nb = tf.Variable([-.3], dtype=tf.float32)\nx = tf.placeholder(tf.float32)\nlinear_model = W*x + b\n\n\n\n\nConstants are initialized when you call \ntf.constant\n, and their value can never\nchange. By contrast, variables are not initialized when you call \ntf.Variable\n.\nTo initialize all the variables in a TensorFlow program, you must explicitly\ncall a special operation as follows:\n\n\ninit = tf.global_variables_initializer()\nsess.run(init)\n\n\n\n\nIt is important to realize \ninit\n is a handle to the TensorFlow sub-graph that\ninitializes all the global variables. Until we call \nsess.run\n, the variables\nare uninitialized.\n\n\nSince \nx\n is a placeholder, we can evaluate \nlinear_model\n for several values of\n\nx\n simultaneously as follows:\n\n\nprint(sess.run(linear_model, {x: [1, 2, 3, 4]}))\n\n\n\n\nto produce the output\n\n\n[ 0.          0.30000001  0.60000002  0.90000004]\n\n\n\n\nWe\nve created a model, but we don\nt know how good it is yet. To evaluate the\nmodel on training data, we need a \ny\n placeholder to provide the desired values,\nand we need to write a loss function.\n\n\nA loss function measures how far apart the\ncurrent model is from the provided data. We\nll use a standard loss model for\nlinear regression, which sums the squares of the deltas between the current\nmodel and the provided data. \nlinear_model - y\n creates a vector where each\nelement is the corresponding example\ns error delta. We call \ntf.square\n to\nsquare that error. Then, we sum all the squared errors to create a single scalar\nthat abstracts the error of all examples using \ntf.reduce_sum\n:\n\n\ny = tf.placeholder(tf.float32)\nsquared_deltas = tf.square(linear_model - y)\nloss = tf.reduce_sum(squared_deltas)\nprint(sess.run(loss, {x: [1, 2, 3, 4], y: [0, -1, -2, -3]}))\n\n\n\n\nproducing the loss value\n\n\n23.66\n\n\n\n\nWe could improve this manually by reassigning the values of \nW\n and \nb\n to the\nperfect values of -1 and 1. A variable is initialized to the value provided to\n\ntf.Variable\n but can be changed using operations like \ntf.assign\n. For example,\n\nW=-1\n and \nb=1\n are the optimal parameters for our model. We can change \nW\n and\n\nb\n accordingly:\n\n\nfixW = tf.assign(W, [-1.])\nfixb = tf.assign(b, [1.])\nsess.run([fixW, fixb])\nprint(sess.run(loss, {x: [1, 2, 3, 4], y: [0, -1, -2, -3]}))\n\n\n\n\nThe final print shows the loss now is zero.\n\n\n0.0\n\n\n\n\nWe guessed the \nperfect\n values of \nW\n and \nb\n, but the whole point of machine\nlearning is to find the correct model parameters automatically.  We will show\nhow to accomplish this in the next section.\n\n\ntf.train API\n\n\nA complete discussion of machine learning is out of the scope of this tutorial.\nHowever, TensorFlow provides \noptimizers\n that slowly change each variable in\norder to minimize the loss function. The simplest optimizer is \ngradient\ndescent\n. It modifies each variable according to the magnitude of the\nderivative of loss with respect to that variable. In general, computing symbolic\nderivatives manually is tedious and error-prone. Consequently, TensorFlow can\nautomatically produce derivatives given only a description of the model using\nthe function \ntf.gradients\n. For simplicity, optimizers typically do this\nfor you. For example,\n\n\noptimizer = tf.train.GradientDescentOptimizer(0.01)\ntrain = optimizer.minimize(loss)\n\n\n\n\nsess.run(init) # reset values to incorrect defaults.\nfor i in range(1000):\n  sess.run(train, {x: [1, 2, 3, 4], y: [0, -1, -2, -3]})\n\nprint(sess.run([W, b]))\n\n\n\n\nresults in the final model parameters:\n\n\n[array([-0.9999969], dtype=float32), array([ 0.99999082], dtype=float32)]\n\n\n\n\nNow we have done actual machine learning!  Although this simple linear\nregression model does not require much TensorFlow core code, more complicated\nmodels and methods to feed data into your models necessitate more code. Thus,\nTensorFlow provides higher level abstractions for common patterns, structures,\nand functionality. We will learn how to use some of these abstractions in the\nnext section.\n\n\nComplete program\n\n\nThe completed trainable linear regression model is shown here:\n\n\nimport tensorflow as tf\n\n# Model parameters\nW = tf.Variable([.3], dtype=tf.float32)\nb = tf.Variable([-.3], dtype=tf.float32)\n# Model input and output\nx = tf.placeholder(tf.float32)\nlinear_model = W*x + b\ny = tf.placeholder(tf.float32)\n\n# loss\nloss = tf.reduce_sum(tf.square(linear_model - y)) # sum of the squares\n# optimizer\noptimizer = tf.train.GradientDescentOptimizer(0.01)\ntrain = optimizer.minimize(loss)\n\n# training data\nx_train = [1, 2, 3, 4]\ny_train = [0, -1, -2, -3]\n# training loop\ninit = tf.global_variables_initializer()\nsess = tf.Session()\nsess.run(init) # reset values to wrong\nfor i in range(1000):\n  sess.run(train, {x: x_train, y: y_train})\n\n# evaluate training accuracy\ncurr_W, curr_b, curr_loss = sess.run([W, b, loss], {x: x_train, y: y_train})\nprint(\nW: %s b: %s loss: %s\n%(curr_W, curr_b, curr_loss))\n\n\n\n\nWhen run, it produces\n\n\nW: [-0.9999969] b: [ 0.99999082] loss: 5.69997e-11\n\n\n\n\nNotice that the loss is a very small number (very close to zero). If you run\nthis program, your loss may not be exactly the same as the aforementioned loss\nbecause the model is initialized with pseudorandom values.\n\n\nThis more complicated program can still be visualized in TensorBoard\n\n\n\ntf.estimator\n\n\ntf.estimator\n is a high-level TensorFlow library that simplifies the\nmechanics of machine learning, including the following:\n\n\n\n\nrunning training loops\n\n\nrunning evaluation loops\n\n\nmanaging data sets\n\n\n\n\ntf.estimator defines many common models.\n\n\nBasic usage\n\n\nNotice how much simpler the linear regression program becomes with\n\ntf.estimator\n:\n\n\n# NumPy is often used to load, manipulate and preprocess data.\nimport numpy as np\nimport tensorflow as tf\n\n# Declare list of features. We only have one numeric feature. There are many\n# other types of columns that are more complicated and useful.\nfeature_columns = [tf.feature_column.numeric_column(\nx\n, shape=[1])]\n\n# An estimator is the front end to invoke training (fitting) and evaluation\n# (inference). There are many predefined types like linear regression,\n# linear classification, and many neural network classifiers and regressors.\n# The following code provides an estimator that does linear regression.\nestimator = tf.estimator.LinearRegressor(feature_columns=feature_columns)\n\n# TensorFlow provides many helper methods to read and set up data sets.\n# Here we use two data sets: one for training and one for evaluation\n# We have to tell the function how many batches\n# of data (num_epochs) we want and how big each batch should be.\nx_train = np.array([1., 2., 3., 4.])\ny_train = np.array([0., -1., -2., -3.])\nx_eval = np.array([2., 5., 8., 1.])\ny_eval = np.array([-1.01, -4.1, -7, 0.])\ninput_fn = tf.estimator.inputs.numpy_input_fn(\n    {\nx\n: x_train}, y_train, batch_size=4, num_epochs=None, shuffle=True)\ntrain_input_fn = tf.estimator.inputs.numpy_input_fn(\n    {\nx\n: x_train}, y_train, batch_size=4, num_epochs=1000, shuffle=False)\neval_input_fn = tf.estimator.inputs.numpy_input_fn(\n    {\nx\n: x_eval}, y_eval, batch_size=4, num_epochs=1000, shuffle=False)\n\n# We can invoke 1000 training steps by invoking the  method and passing the\n# training data set.\nestimator.train(input_fn=input_fn, steps=1000)\n\n# Here we evaluate how well our model did.\ntrain_metrics = estimator.evaluate(input_fn=train_input_fn)\neval_metrics = estimator.evaluate(input_fn=eval_input_fn)\nprint(\ntrain metrics: %r\n% train_metrics)\nprint(\neval metrics: %r\n% eval_metrics)\n\n\n\n\nWhen run, it produces something like\n\n\ntrain metrics: {'average_loss': 1.4833182e-08, 'global_step': 1000, 'loss': 5.9332727e-08}\neval metrics: {'average_loss': 0.0025353201, 'global_step': 1000, 'loss': 0.01014128}\n\n\n\n\nNotice how our eval data has a higher loss, but it is still close to zero.\nThat means we are learning properly.\n\n\nA custom model\n\n\ntf.estimator\n does not lock you into its predefined models. Suppose we\nwanted to create a custom model that is not built into TensorFlow. We can still\nretain the high level abstraction of data set, feeding, training, etc. of\n\ntf.estimator\n. For illustration, we will show how to implement our own\nequivalent model to \nLinearRegressor\n using our knowledge of the lower level\nTensorFlow API.\n\n\nTo define a custom model that works with \ntf.estimator\n, we need to use\n\ntf.estimator.Estimator\n. \ntf.estimator.LinearRegressor\n is actually\na sub-class of \ntf.estimator.Estimator\n. Instead of sub-classing\n\nEstimator\n, we simply provide \nEstimator\n a function \nmodel_fn\n that tells\n\ntf.estimator\n how it can evaluate predictions, training steps, and\nloss. The code is as follows:\n\n\nimport numpy as np\nimport tensorflow as tf\n\n# Declare list of features, we only have one real-valued feature\ndef model_fn(features, labels, mode):\n  # Build a linear model and predict values\n  W = tf.get_variable(\nW\n, [1], dtype=tf.float64)\n  b = tf.get_variable(\nb\n, [1], dtype=tf.float64)\n  y = W*features['x'] + b\n  # Loss sub-graph\n  loss = tf.reduce_sum(tf.square(y - labels))\n  # Training sub-graph\n  global_step = tf.train.get_global_step()\n  optimizer = tf.train.GradientDescentOptimizer(0.01)\n  train = tf.group(optimizer.minimize(loss),\n                   tf.assign_add(global_step, 1))\n  # EstimatorSpec connects subgraphs we built to the\n  # appropriate functionality.\n  return tf.estimator.EstimatorSpec(\n      mode=mode,\n      predictions=y,\n      loss=loss,\n      train_op=train)\n\nestimator = tf.estimator.Estimator(model_fn=model_fn)\n# define our data sets\nx_train = np.array([1., 2., 3., 4.])\ny_train = np.array([0., -1., -2., -3.])\nx_eval = np.array([2., 5., 8., 1.])\ny_eval = np.array([-1.01, -4.1, -7., 0.])\ninput_fn = tf.estimator.inputs.numpy_input_fn(\n    {\nx\n: x_train}, y_train, batch_size=4, num_epochs=None, shuffle=True)\ntrain_input_fn = tf.estimator.inputs.numpy_input_fn(\n    {\nx\n: x_train}, y_train, batch_size=4, num_epochs=1000, shuffle=False)\neval_input_fn = tf.estimator.inputs.numpy_input_fn(\n    {\nx\n: x_eval}, y_eval, batch_size=4, num_epochs=1000, shuffle=False)\n\n# train\nestimator.train(input_fn=input_fn, steps=1000)\n# Here we evaluate how well our model did.\ntrain_metrics = estimator.evaluate(input_fn=train_input_fn)\neval_metrics = estimator.evaluate(input_fn=eval_input_fn)\nprint(\ntrain metrics: %r\n% train_metrics)\nprint(\neval metrics: %r\n% eval_metrics)\n\n\n\n\nWhen run, it produces\n\n\ntrain metrics: {'loss': 1.227995e-11, 'global_step': 1000}\neval metrics: {'loss': 0.01010036, 'global_step': 1000}\n\n\n\n\nNotice how the contents of the custom \nmodel_fn()\n function are very similar\nto our manual model training loop from the lower level API.\n\n\nNext steps\n\n\nNow you have a working knowledge of the basics of TensorFlow. We have several\nmore tutorials that you can look at to learn more. If you are a beginner in\nmachine learning see @{$beginners$MNIST for beginners},\notherwise see @{$pros$Deep MNIST for experts}.", 
            "title": "2.1.2 TensorFlow\u5feb\u901f\u5165\u95e8"
        }, 
        {
            "location": "/develop/getstarted/getting-started-with-tensorflow/#getting-started-with-tensorflow", 
            "text": "This guide gets you started programming in TensorFlow. Before using this guide,\n@{$install$install TensorFlow}. To get the most out of\nthis guide, you should know the following:   How to program in Python.  At least a little bit about arrays.  Ideally, something about machine learning. However, if you know little or\n    nothing about machine learning, then this is still the first guide you\n    should read.   TensorFlow provides multiple APIs. The lowest level API TensorFlow Core \nprovides you with complete programming control. We recommend TensorFlow Core for\nmachine learning researchers and others who require fine levels of control over\ntheir models. The higher level APIs are built on top of TensorFlow Core. These\nhigher level APIs are typically easier to learn and use than TensorFlow Core. In\naddition, the higher level APIs make repetitive tasks easier and more consistent\nbetween different users. A high-level API like tf.estimator helps you manage\ndata sets, estimators, training and inference.  This guide begins with a tutorial on TensorFlow Core. Later, we\ndemonstrate how to implement the same model in tf.estimator. Knowing\nTensorFlow Core principles will give you a great mental model of how things are\nworking internally when you use the more compact higher level API.", 
            "title": "Getting Started With TensorFlow"
        }, 
        {
            "location": "/develop/getstarted/getting-started-with-tensorflow/#tensors", 
            "text": "The central unit of data in TensorFlow is the  tensor . A tensor consists of a\nset of primitive values shaped into an array of any number of dimensions. A\ntensor s  rank  is its number of dimensions. Here are some examples of\ntensors:  3 # a rank 0 tensor; a scalar with shape []\n[1., 2., 3.] # a rank 1 tensor; a vector with shape [3]\n[[1., 2., 3.], [4., 5., 6.]] # a rank 2 tensor; a matrix with shape [2, 3]\n[[[1., 2., 3.]], [[7., 8., 9.]]] # a rank 3 tensor with shape [2, 1, 3]", 
            "title": "Tensors"
        }, 
        {
            "location": "/develop/getstarted/getting-started-with-tensorflow/#tensorflow-core-tutorial", 
            "text": "", 
            "title": "TensorFlow Core tutorial"
        }, 
        {
            "location": "/develop/getstarted/getting-started-with-tensorflow/#importing-tensorflow", 
            "text": "The canonical import statement for TensorFlow programs is as follows:  import tensorflow as tf  This gives Python access to all of TensorFlow s classes, methods, and symbols.\nMost of the documentation assumes you have already done this.", 
            "title": "Importing TensorFlow"
        }, 
        {
            "location": "/develop/getstarted/getting-started-with-tensorflow/#the-computational-graph", 
            "text": "You might think of TensorFlow Core programs as consisting of two discrete\nsections:   Building the computational graph.  Running the computational graph.   A  computational graph  is a series of TensorFlow operations arranged into a\ngraph of nodes.\nLet s build a simple computational graph. Each node takes zero\nor more tensors as inputs and produces a tensor as an output. One type of node\nis a constant. Like all TensorFlow constants, it takes no inputs, and it outputs\na value it stores internally. We can create two floating point Tensors  node1 \nand  node2  as follows:  node1 = tf.constant(3.0, dtype=tf.float32)\nnode2 = tf.constant(4.0) # also tf.float32 implicitly\nprint(node1, node2)  The final print statement produces  Tensor( Const:0 , shape=(), dtype=float32) Tensor( Const_1:0 , shape=(), dtype=float32)  Notice that printing the nodes does not output the values  3.0  and  4.0  as you\nmight expect. Instead, they are nodes that, when evaluated, would produce 3.0\nand 4.0, respectively. To actually evaluate the nodes, we must run the\ncomputational graph within a  session . A session encapsulates the control and\nstate of the TensorFlow runtime.  The following code creates a  Session  object and then invokes its  run  method\nto run enough of the computational graph to evaluate  node1  and  node2 . By\nrunning the computational graph in a session as follows:  sess = tf.Session()\nprint(sess.run([node1, node2]))  we see the expected values of 3.0 and 4.0:  [3.0, 4.0]  We can build more complicated computations by combining  Tensor  nodes with\noperations (Operations are also nodes). For example, we can add our two\nconstant nodes and produce a new graph as follows:  from __future__ import print_function\nnode3 = tf.add(node1, node2)\nprint( node3: , node3)\nprint( sess.run(node3): , sess.run(node3))  The last two print statements produce  node3: Tensor( Add:0 , shape=(), dtype=float32)\nsess.run(node3): 7.0  TensorFlow provides a utility called TensorBoard that can display a picture of\nthe computational graph. Here is a screenshot showing how TensorBoard\nvisualizes the graph:   As it stands, this graph is not especially interesting because it always\nproduces a constant result. A graph can be parameterized to accept external\ninputs, known as  placeholders . A  placeholder  is a promise to provide a\nvalue later.  a = tf.placeholder(tf.float32)\nb = tf.placeholder(tf.float32)\nadder_node = a + b  # + provides a shortcut for tf.add(a, b)  The preceding three lines are a bit like a function or a lambda in which we\ndefine two input parameters (a and b) and then an operation on them. We can\nevaluate this graph with multiple inputs by using the feed_dict argument to\nthe  run method \nto feed concrete values to the placeholders:  print(sess.run(adder_node, {a: 3, b: 4.5}))\nprint(sess.run(adder_node, {a: [1, 3], b: [2, 4]}))  resulting in the output  7.5\n[ 3.  7.]  In TensorBoard, the graph looks like this:   We can make the computational graph more complex by adding another operation.\nFor example,  add_and_triple = adder_node * 3.\nprint(sess.run(add_and_triple, {a: 3, b: 4.5}))  produces the output  22.5  The preceding computational graph would look as follows in TensorBoard:   In machine learning we will typically want a model that can take arbitrary\ninputs, such as the one above.  To make the model trainable, we need to be able\nto modify the graph to get new outputs with the same input.   Variables  allow\nus to add trainable parameters to a graph.  They are constructed with a type and\ninitial value:  W = tf.Variable([.3], dtype=tf.float32)\nb = tf.Variable([-.3], dtype=tf.float32)\nx = tf.placeholder(tf.float32)\nlinear_model = W*x + b  Constants are initialized when you call  tf.constant , and their value can never\nchange. By contrast, variables are not initialized when you call  tf.Variable .\nTo initialize all the variables in a TensorFlow program, you must explicitly\ncall a special operation as follows:  init = tf.global_variables_initializer()\nsess.run(init)  It is important to realize  init  is a handle to the TensorFlow sub-graph that\ninitializes all the global variables. Until we call  sess.run , the variables\nare uninitialized.  Since  x  is a placeholder, we can evaluate  linear_model  for several values of x  simultaneously as follows:  print(sess.run(linear_model, {x: [1, 2, 3, 4]}))  to produce the output  [ 0.          0.30000001  0.60000002  0.90000004]  We ve created a model, but we don t know how good it is yet. To evaluate the\nmodel on training data, we need a  y  placeholder to provide the desired values,\nand we need to write a loss function.  A loss function measures how far apart the\ncurrent model is from the provided data. We ll use a standard loss model for\nlinear regression, which sums the squares of the deltas between the current\nmodel and the provided data.  linear_model - y  creates a vector where each\nelement is the corresponding example s error delta. We call  tf.square  to\nsquare that error. Then, we sum all the squared errors to create a single scalar\nthat abstracts the error of all examples using  tf.reduce_sum :  y = tf.placeholder(tf.float32)\nsquared_deltas = tf.square(linear_model - y)\nloss = tf.reduce_sum(squared_deltas)\nprint(sess.run(loss, {x: [1, 2, 3, 4], y: [0, -1, -2, -3]}))  producing the loss value  23.66  We could improve this manually by reassigning the values of  W  and  b  to the\nperfect values of -1 and 1. A variable is initialized to the value provided to tf.Variable  but can be changed using operations like  tf.assign . For example, W=-1  and  b=1  are the optimal parameters for our model. We can change  W  and b  accordingly:  fixW = tf.assign(W, [-1.])\nfixb = tf.assign(b, [1.])\nsess.run([fixW, fixb])\nprint(sess.run(loss, {x: [1, 2, 3, 4], y: [0, -1, -2, -3]}))  The final print shows the loss now is zero.  0.0  We guessed the  perfect  values of  W  and  b , but the whole point of machine\nlearning is to find the correct model parameters automatically.  We will show\nhow to accomplish this in the next section.", 
            "title": "The Computational Graph"
        }, 
        {
            "location": "/develop/getstarted/getting-started-with-tensorflow/#tftrain-api", 
            "text": "A complete discussion of machine learning is out of the scope of this tutorial.\nHowever, TensorFlow provides  optimizers  that slowly change each variable in\norder to minimize the loss function. The simplest optimizer is  gradient\ndescent . It modifies each variable according to the magnitude of the\nderivative of loss with respect to that variable. In general, computing symbolic\nderivatives manually is tedious and error-prone. Consequently, TensorFlow can\nautomatically produce derivatives given only a description of the model using\nthe function  tf.gradients . For simplicity, optimizers typically do this\nfor you. For example,  optimizer = tf.train.GradientDescentOptimizer(0.01)\ntrain = optimizer.minimize(loss)  sess.run(init) # reset values to incorrect defaults.\nfor i in range(1000):\n  sess.run(train, {x: [1, 2, 3, 4], y: [0, -1, -2, -3]})\n\nprint(sess.run([W, b]))  results in the final model parameters:  [array([-0.9999969], dtype=float32), array([ 0.99999082], dtype=float32)]  Now we have done actual machine learning!  Although this simple linear\nregression model does not require much TensorFlow core code, more complicated\nmodels and methods to feed data into your models necessitate more code. Thus,\nTensorFlow provides higher level abstractions for common patterns, structures,\nand functionality. We will learn how to use some of these abstractions in the\nnext section.", 
            "title": "tf.train API"
        }, 
        {
            "location": "/develop/getstarted/getting-started-with-tensorflow/#complete-program", 
            "text": "The completed trainable linear regression model is shown here:  import tensorflow as tf\n\n# Model parameters\nW = tf.Variable([.3], dtype=tf.float32)\nb = tf.Variable([-.3], dtype=tf.float32)\n# Model input and output\nx = tf.placeholder(tf.float32)\nlinear_model = W*x + b\ny = tf.placeholder(tf.float32)\n\n# loss\nloss = tf.reduce_sum(tf.square(linear_model - y)) # sum of the squares\n# optimizer\noptimizer = tf.train.GradientDescentOptimizer(0.01)\ntrain = optimizer.minimize(loss)\n\n# training data\nx_train = [1, 2, 3, 4]\ny_train = [0, -1, -2, -3]\n# training loop\ninit = tf.global_variables_initializer()\nsess = tf.Session()\nsess.run(init) # reset values to wrong\nfor i in range(1000):\n  sess.run(train, {x: x_train, y: y_train})\n\n# evaluate training accuracy\ncurr_W, curr_b, curr_loss = sess.run([W, b, loss], {x: x_train, y: y_train})\nprint( W: %s b: %s loss: %s %(curr_W, curr_b, curr_loss))  When run, it produces  W: [-0.9999969] b: [ 0.99999082] loss: 5.69997e-11  Notice that the loss is a very small number (very close to zero). If you run\nthis program, your loss may not be exactly the same as the aforementioned loss\nbecause the model is initialized with pseudorandom values.  This more complicated program can still be visualized in TensorBoard", 
            "title": "Complete program"
        }, 
        {
            "location": "/develop/getstarted/getting-started-with-tensorflow/#tfestimator", 
            "text": "tf.estimator  is a high-level TensorFlow library that simplifies the\nmechanics of machine learning, including the following:   running training loops  running evaluation loops  managing data sets   tf.estimator defines many common models.", 
            "title": "tf.estimator"
        }, 
        {
            "location": "/develop/getstarted/getting-started-with-tensorflow/#basic-usage", 
            "text": "Notice how much simpler the linear regression program becomes with tf.estimator :  # NumPy is often used to load, manipulate and preprocess data.\nimport numpy as np\nimport tensorflow as tf\n\n# Declare list of features. We only have one numeric feature. There are many\n# other types of columns that are more complicated and useful.\nfeature_columns = [tf.feature_column.numeric_column( x , shape=[1])]\n\n# An estimator is the front end to invoke training (fitting) and evaluation\n# (inference). There are many predefined types like linear regression,\n# linear classification, and many neural network classifiers and regressors.\n# The following code provides an estimator that does linear regression.\nestimator = tf.estimator.LinearRegressor(feature_columns=feature_columns)\n\n# TensorFlow provides many helper methods to read and set up data sets.\n# Here we use two data sets: one for training and one for evaluation\n# We have to tell the function how many batches\n# of data (num_epochs) we want and how big each batch should be.\nx_train = np.array([1., 2., 3., 4.])\ny_train = np.array([0., -1., -2., -3.])\nx_eval = np.array([2., 5., 8., 1.])\ny_eval = np.array([-1.01, -4.1, -7, 0.])\ninput_fn = tf.estimator.inputs.numpy_input_fn(\n    { x : x_train}, y_train, batch_size=4, num_epochs=None, shuffle=True)\ntrain_input_fn = tf.estimator.inputs.numpy_input_fn(\n    { x : x_train}, y_train, batch_size=4, num_epochs=1000, shuffle=False)\neval_input_fn = tf.estimator.inputs.numpy_input_fn(\n    { x : x_eval}, y_eval, batch_size=4, num_epochs=1000, shuffle=False)\n\n# We can invoke 1000 training steps by invoking the  method and passing the\n# training data set.\nestimator.train(input_fn=input_fn, steps=1000)\n\n# Here we evaluate how well our model did.\ntrain_metrics = estimator.evaluate(input_fn=train_input_fn)\neval_metrics = estimator.evaluate(input_fn=eval_input_fn)\nprint( train metrics: %r % train_metrics)\nprint( eval metrics: %r % eval_metrics)  When run, it produces something like  train metrics: {'average_loss': 1.4833182e-08, 'global_step': 1000, 'loss': 5.9332727e-08}\neval metrics: {'average_loss': 0.0025353201, 'global_step': 1000, 'loss': 0.01014128}  Notice how our eval data has a higher loss, but it is still close to zero.\nThat means we are learning properly.", 
            "title": "Basic usage"
        }, 
        {
            "location": "/develop/getstarted/getting-started-with-tensorflow/#a-custom-model", 
            "text": "tf.estimator  does not lock you into its predefined models. Suppose we\nwanted to create a custom model that is not built into TensorFlow. We can still\nretain the high level abstraction of data set, feeding, training, etc. of tf.estimator . For illustration, we will show how to implement our own\nequivalent model to  LinearRegressor  using our knowledge of the lower level\nTensorFlow API.  To define a custom model that works with  tf.estimator , we need to use tf.estimator.Estimator .  tf.estimator.LinearRegressor  is actually\na sub-class of  tf.estimator.Estimator . Instead of sub-classing Estimator , we simply provide  Estimator  a function  model_fn  that tells tf.estimator  how it can evaluate predictions, training steps, and\nloss. The code is as follows:  import numpy as np\nimport tensorflow as tf\n\n# Declare list of features, we only have one real-valued feature\ndef model_fn(features, labels, mode):\n  # Build a linear model and predict values\n  W = tf.get_variable( W , [1], dtype=tf.float64)\n  b = tf.get_variable( b , [1], dtype=tf.float64)\n  y = W*features['x'] + b\n  # Loss sub-graph\n  loss = tf.reduce_sum(tf.square(y - labels))\n  # Training sub-graph\n  global_step = tf.train.get_global_step()\n  optimizer = tf.train.GradientDescentOptimizer(0.01)\n  train = tf.group(optimizer.minimize(loss),\n                   tf.assign_add(global_step, 1))\n  # EstimatorSpec connects subgraphs we built to the\n  # appropriate functionality.\n  return tf.estimator.EstimatorSpec(\n      mode=mode,\n      predictions=y,\n      loss=loss,\n      train_op=train)\n\nestimator = tf.estimator.Estimator(model_fn=model_fn)\n# define our data sets\nx_train = np.array([1., 2., 3., 4.])\ny_train = np.array([0., -1., -2., -3.])\nx_eval = np.array([2., 5., 8., 1.])\ny_eval = np.array([-1.01, -4.1, -7., 0.])\ninput_fn = tf.estimator.inputs.numpy_input_fn(\n    { x : x_train}, y_train, batch_size=4, num_epochs=None, shuffle=True)\ntrain_input_fn = tf.estimator.inputs.numpy_input_fn(\n    { x : x_train}, y_train, batch_size=4, num_epochs=1000, shuffle=False)\neval_input_fn = tf.estimator.inputs.numpy_input_fn(\n    { x : x_eval}, y_eval, batch_size=4, num_epochs=1000, shuffle=False)\n\n# train\nestimator.train(input_fn=input_fn, steps=1000)\n# Here we evaluate how well our model did.\ntrain_metrics = estimator.evaluate(input_fn=train_input_fn)\neval_metrics = estimator.evaluate(input_fn=eval_input_fn)\nprint( train metrics: %r % train_metrics)\nprint( eval metrics: %r % eval_metrics)  When run, it produces  train metrics: {'loss': 1.227995e-11, 'global_step': 1000}\neval metrics: {'loss': 0.01010036, 'global_step': 1000}  Notice how the contents of the custom  model_fn()  function are very similar\nto our manual model training loop from the lower level API.", 
            "title": "A custom model"
        }, 
        {
            "location": "/develop/getstarted/getting-started-with-tensorflow/#next-steps", 
            "text": "Now you have a working knowledge of the basics of TensorFlow. We have several\nmore tutorials that you can look at to learn more. If you are a beginner in\nmachine learning see @{$beginners$MNIST for beginners},\notherwise see @{$pros$Deep MNIST for experts}.", 
            "title": "Next steps"
        }, 
        {
            "location": "/develop/getstarted/mnist-for-ml-beginners/", 
            "text": "", 
            "title": "2.1.3 MNIST\u5165\u95e8"
        }, 
        {
            "location": "/develop/getstarted/deep-mnist-for-experts/", 
            "text": "", 
            "title": "2.1.4 MNIST\u8fdb\u9636"
        }, 
        {
            "location": "/develop/getstarted/mechanics101/", 
            "text": "", 
            "title": "2.1.5 TensorFlow \u8fd0\u4f5c\u65b9\u5f0f 101"
        }, 
        {
            "location": "/develop/getstarted/tf-contrib-learn-quickstart/", 
            "text": "", 
            "title": "2.1.6 tf.contrib.learn\uff1a\u5feb\u901f\u5f00\u59cb"
        }, 
        {
            "location": "/develop/getstarted/tf-contrib-learn-function/", 
            "text": "", 
            "title": "2.1.7 tf.contrib.learn\uff1a\u521b\u5efa\u8f93\u5165\u51fd\u6570"
        }, 
        {
            "location": "/develop/getstarted/tensorboard-visualizing-learning/", 
            "text": "", 
            "title": "2.1.8 TensorBoard\uff1a\u53ef\u89c6\u5316\u5b66\u4e60"
        }, 
        {
            "location": "/develop/getstarted/tensorboard-embedding-visualization/", 
            "text": "", 
            "title": "2.1.9 TensorBoard\uff1a\u5185\u5d4c\u53ef\u89c6\u5316"
        }, 
        {
            "location": "/develop/getstarted/tensorboard-graph-visualization/", 
            "text": "", 
            "title": "2.1.10 TensorBoard\uff1a\u56fe\u8868\u53ef\u89c6\u5316"
        }, 
        {
            "location": "/develop/getstarted/tf-contrib-learn-logging-and-monitoring/", 
            "text": "", 
            "title": "2.1.11 tf.contrib.learn\uff1a\u65e5\u5fd7\u548c\u76d1\u63a7\u57fa\u7840"
        }, 
        {
            "location": "/develop/programmer/", 
            "text": "Programmer\ns Guide\n\n\nThe documents in this unit dive into the details of writing TensorFlow\ncode.  For TensorFlow 1.3, we revised this document extensively.\nThe units are now as follows:\n\n\n\n\n@{$programmers_guide/estimators$Estimators}, which introduces a high-level\n    TensorFlow API that greatly simplifies ML programming.\n\n\n@{$programmers_guide/tensors$Tensors}, which explains how to create,\n    manipulate, and access Tensors\nthe fundamental object in TensorFlow.\n\n\n@{$programmers_guide/variables$Variables}, which details how\n    to represent shared, persistent state in your program.\n\n\n@{$programmers_guide/graphs$Graphs and Sessions}, which explains:\n\n\ndataflow graphs, which are TensorFlow\ns representation of computations\n    as dependencies between operations.\n\n\nsessions, which are TensorFlow\ns mechanism for running dataflow graphs\n    across one or more local or remote devices.\nIf you are programming with the low-level TensorFlow API, this unit\nis essential. If you are programming with a high-level TensorFlow API\nsuch as Estimators or Keras, the high-level API creates and manages\ngraphs and sessions for you, but understanding graphs and sessions\ncan still be helpful.\n\n\n\n\n\n\n@{$programmers_guide/saved_model$Saving and Restoring}, which\n    explains how to save and restore variables and models.\n\n\n@{$programmers_guide/datasets$Input Pipelines}, which explains how to\n    set up data pipelines to read data sets into your TensorFlow program.\n\n\n@{$programmers_guide/embedding$Embeddings}, which introduces the concept\n    of embeddings, provides a simple example of training an embedding in\n    TensorFlow, and explains how to view embeddings with the TensorBoard\n    Embedding Projector.\n\n\n@{$programmers_guide/debugger$Debugging TensorFlow Programs}, which\n    explains how to use the TensorFlow debugger (tfdbg).\n\n\n@{$programmers_guide/version_compat$TensorFlow Version Compatibility},\n    which explains backward compatibility guarantees and non-guarantees.\n\n\n@{$programmers_guide/faq$FAQ}, which contains frequently asked\n    questions about TensorFlow. (We have not revised this document for v1.3,\n    except to remove some obsolete information.)", 
            "title": "2.2.1 \u7a0b\u5e8f\u5458\u624b\u518c"
        }, 
        {
            "location": "/develop/programmer/#programmers-guide", 
            "text": "The documents in this unit dive into the details of writing TensorFlow\ncode.  For TensorFlow 1.3, we revised this document extensively.\nThe units are now as follows:   @{$programmers_guide/estimators$Estimators}, which introduces a high-level\n    TensorFlow API that greatly simplifies ML programming.  @{$programmers_guide/tensors$Tensors}, which explains how to create,\n    manipulate, and access Tensors the fundamental object in TensorFlow.  @{$programmers_guide/variables$Variables}, which details how\n    to represent shared, persistent state in your program.  @{$programmers_guide/graphs$Graphs and Sessions}, which explains:  dataflow graphs, which are TensorFlow s representation of computations\n    as dependencies between operations.  sessions, which are TensorFlow s mechanism for running dataflow graphs\n    across one or more local or remote devices.\nIf you are programming with the low-level TensorFlow API, this unit\nis essential. If you are programming with a high-level TensorFlow API\nsuch as Estimators or Keras, the high-level API creates and manages\ngraphs and sessions for you, but understanding graphs and sessions\ncan still be helpful.    @{$programmers_guide/saved_model$Saving and Restoring}, which\n    explains how to save and restore variables and models.  @{$programmers_guide/datasets$Input Pipelines}, which explains how to\n    set up data pipelines to read data sets into your TensorFlow program.  @{$programmers_guide/embedding$Embeddings}, which introduces the concept\n    of embeddings, provides a simple example of training an embedding in\n    TensorFlow, and explains how to view embeddings with the TensorBoard\n    Embedding Projector.  @{$programmers_guide/debugger$Debugging TensorFlow Programs}, which\n    explains how to use the TensorFlow debugger (tfdbg).  @{$programmers_guide/version_compat$TensorFlow Version Compatibility},\n    which explains backward compatibility guarantees and non-guarantees.  @{$programmers_guide/faq$FAQ}, which contains frequently asked\n    questions about TensorFlow. (We have not revised this document for v1.3,\n    except to remove some obsolete information.)", 
            "title": "Programmer's Guide"
        }, 
        {
            "location": "/develop/programmer/reading-data/", 
            "text": "", 
            "title": "2.2.2 \u8bfb\u53d6\u6570\u636e"
        }, 
        {
            "location": "/develop/programmer/threading-and-queues/", 
            "text": "", 
            "title": "2.2.3 \u7ebf\u7a0b\u548c\u961f\u5217"
        }, 
        {
            "location": "/develop/programmer/sharing-variables/", 
            "text": "", 
            "title": "2.2.4 \u5171\u4eab\u53c2\u6570"
        }, 
        {
            "location": "/develop/programmer/version-semantics/", 
            "text": "", 
            "title": "2.2.5 TensorFlow\u7684\u7248\u672c\u8bed\u4e49"
        }, 
        {
            "location": "/develop/programmer/data-versioning-graphdefs-and-checkpoints/", 
            "text": "", 
            "title": "2.2.6 TensorFlow\u6570\u636e\u7248\u672c\u5316\uff1aGraphDefs and Checkpoints"
        }, 
        {
            "location": "/develop/programmer/supervisor-training-helper/", 
            "text": "", 
            "title": "2.2.7 Supervisor\uff1aTraining Helper for Days-Long Trainings"
        }, 
        {
            "location": "/develop/programmer/tfdbg-cli-tutorial/", 
            "text": "", 
            "title": "2.2.8 TensorFlow Debugger (tfdbg) \u547d\u4ee4\u884c\u6307\u5357\uff1aMNIST"
        }, 
        {
            "location": "/develop/programmer/how-to-use-tfdbg-with-tf-contib-learn/", 
            "text": "", 
            "title": "2.2.9 TensorFlow Debugger (tfdbg) \u4e0e tf.contrib.learn \u7ed3\u5408\u4f7f\u7528"
        }, 
        {
            "location": "/develop/programmer/exporting-and-importing-metagraph/", 
            "text": "", 
            "title": "2.2.10 \u5bfc\u5165\u5bfc\u51faMetaGraph"
        }, 
        {
            "location": "/develop/programmer/frequently-asked-questions/", 
            "text": "", 
            "title": "2.2.11 \u5e38\u89c1\u95ee\u9898"
        }, 
        {
            "location": "/develop/programmer/tensor-ranks-shapes-and-types/", 
            "text": "", 
            "title": "2.2.12 Tensor\u6392\u540d\u3001\u5f62\u72b6\u548c\u7c7b\u578b"
        }, 
        {
            "location": "/develop/programmer/variables-creation-initialization-saving-and-loading/", 
            "text": "", 
            "title": "2.2.13 \u53d8\u91cf\uff1a\u521b\u5efa\u3001\u521d\u59cb\u5316\u3001\u4fdd\u5b58\u548c\u52a0\u8f7d"
        }, 
        {
            "location": "/develop/tutorials/", 
            "text": "Tutorials\n\n\nThis section contains tutorials demonstrating how to do specific tasks\nin TensorFlow.  If you are new to TensorFlow, we recommend reading the\ndocuments in the \nGet Started\n section before reading these tutorials.\n\n\nThe following tutorial explains the interaction of CPUs and GPUs on a\nTensorFlow system:\n\n\n\n\n@{$using_gpu$Using GPUs}\n\n\n\n\nThe following tutorials cover different aspects of image recognition:\n\n\n\n\n@{$image_recognition$Image Recognition}, which introduces the field of\n    image recognition and a model (Inception) for recognizing images.\n\n\n@{$image_retraining$How to Retrain Inception\ns Final Layer for New Categories},\n    which has a wonderfully self-explanatory title.\n\n\n@{$layers$A Guide to TF Layers: Building a Convolutional Neural Network},\n    which introduces convolutional neural networks (CNNs) and demonstrates how\n    to build a CNN in TensorFlow.\n\n\n@{$deep_cnn$Convolutional Neural Networks}, which demonstrates how to\n    build a small CNN for recognizing images.  This tutorial is aimed at\n    advanced TensorFlow users.\n\n\n\n\nThe following tutorials focus on machine learning problems in human language:\n\n\n\n\n@{$word2vec$Vector Representations of Words}, which demonstrates how to\n    create an embedding for words.\n\n\n@{$recurrent$Recurrent Neural Networks}, which demonstrates how to use a\n    recurrent neural network to predict the next word in a sentence.\n\n\n@{$seq2seq$Sequence-to-Sequence Models}, which demonstrates how to use a\n    sequence-to-sequence model to translate text from English to French.\n\n\n\n\nThe following tutorials focus on linear models:\n\n\n\n\n@{$linear$Large-Scale Linear Models with TensorFlow}, which introduces\n    linear models and demonstrates how to build them with the high-level API.\n\n\n@{$wide$TensorFlow Linear Model Tutorial}, which demonstrates how to solve\n    a binary classification problem in TensorFlow.\n\n\n@{$wide_and_deep$TensorFlow Wide \n Deep Learning Tutorial}, which explains\n    how to use the high-level API to jointly train both a wide linear model\n    and a deep feed-forward neural network.\n\n\n@{$kernel_methods$Improving Linear Models Using Explicit Kernel Methods},\n    which shows how to improve the quality of a linear model by using explicit\n    kernel mappings.\n\n\n@{$audio_recognition$Simple Audio Recognition}, which shows how to\n    build a basic speech recognition network.\n\n\n\n\nAlthough TensorFlow specializes in machine learning, you may also use\nTensorFlow to solve other kinds of math problems.  For example:\n\n\n\n\n@{$mandelbrot$Mandelbrot Set}\n\n\n@{$pdes$Partial Differential Equations}", 
            "title": "2.3.1 \u6559\u7a0b"
        }, 
        {
            "location": "/develop/tutorials/#tutorials", 
            "text": "This section contains tutorials demonstrating how to do specific tasks\nin TensorFlow.  If you are new to TensorFlow, we recommend reading the\ndocuments in the  Get Started  section before reading these tutorials.  The following tutorial explains the interaction of CPUs and GPUs on a\nTensorFlow system:   @{$using_gpu$Using GPUs}   The following tutorials cover different aspects of image recognition:   @{$image_recognition$Image Recognition}, which introduces the field of\n    image recognition and a model (Inception) for recognizing images.  @{$image_retraining$How to Retrain Inception s Final Layer for New Categories},\n    which has a wonderfully self-explanatory title.  @{$layers$A Guide to TF Layers: Building a Convolutional Neural Network},\n    which introduces convolutional neural networks (CNNs) and demonstrates how\n    to build a CNN in TensorFlow.  @{$deep_cnn$Convolutional Neural Networks}, which demonstrates how to\n    build a small CNN for recognizing images.  This tutorial is aimed at\n    advanced TensorFlow users.   The following tutorials focus on machine learning problems in human language:   @{$word2vec$Vector Representations of Words}, which demonstrates how to\n    create an embedding for words.  @{$recurrent$Recurrent Neural Networks}, which demonstrates how to use a\n    recurrent neural network to predict the next word in a sentence.  @{$seq2seq$Sequence-to-Sequence Models}, which demonstrates how to use a\n    sequence-to-sequence model to translate text from English to French.   The following tutorials focus on linear models:   @{$linear$Large-Scale Linear Models with TensorFlow}, which introduces\n    linear models and demonstrates how to build them with the high-level API.  @{$wide$TensorFlow Linear Model Tutorial}, which demonstrates how to solve\n    a binary classification problem in TensorFlow.  @{$wide_and_deep$TensorFlow Wide   Deep Learning Tutorial}, which explains\n    how to use the high-level API to jointly train both a wide linear model\n    and a deep feed-forward neural network.  @{$kernel_methods$Improving Linear Models Using Explicit Kernel Methods},\n    which shows how to improve the quality of a linear model by using explicit\n    kernel mappings.  @{$audio_recognition$Simple Audio Recognition}, which shows how to\n    build a basic speech recognition network.   Although TensorFlow specializes in machine learning, you may also use\nTensorFlow to solve other kinds of math problems.  For example:   @{$mandelbrot$Mandelbrot Set}  @{$pdes$Partial Differential Equations}", 
            "title": "Tutorials"
        }, 
        {
            "location": "/develop/tutorials/mandelbrot-set/", 
            "text": "", 
            "title": "2.3.2 \u66fc\u5fb7\u5e03\u6d1b\u7279(Mandelbrot)\u96c6\u5408"
        }, 
        {
            "location": "/develop/tutorials/partial-differential-equations/", 
            "text": "", 
            "title": "2.3.3 \u504f\u5fae\u5206\u65b9\u7a0b(PDEs)"
        }, 
        {
            "location": "/develop/tutorials/convolutional-neural-networks/", 
            "text": "", 
            "title": "2.3.4 \u5377\u79ef\u795e\u7ecf\u7f51\u7edc"
        }, 
        {
            "location": "/develop/tutorials/image-recognition/", 
            "text": "", 
            "title": "2.3.5 \u56fe\u50cf\u8bc6\u522b"
        }, 
        {
            "location": "/develop/tutorials/how-to-retrain-inceptions-final-layer-for-new-categories/", 
            "text": "", 
            "title": "2.3.6 \u5982\u4f55\u8bad\u7ec3 Inception\u2019s Final Layer for New Categories"
        }, 
        {
            "location": "/develop/tutorials/vector-representations-of-words/", 
            "text": "", 
            "title": "2.3.7 \u5b57\u8bcd\u7684\u5411\u91cf\u8868\u793a"
        }, 
        {
            "location": "/develop/tutorials/recurrent-neural-networks/", 
            "text": "", 
            "title": "2.3.8 \u9012\u5f52\u795e\u7ecf\u7f51\u7edc"
        }, 
        {
            "location": "/develop/tutorials/sequence-to-sequence-models/", 
            "text": "", 
            "title": "2.3.9 Sequence-to-Sequence \u6a21\u578b"
        }, 
        {
            "location": "/develop/tutorials/a-guide-to-tf-layers-buiding-a-convolutional-neural-network/", 
            "text": "", 
            "title": "2.3.10 TF Layers \u6307\u5357\uff1a\u521b\u5efa\u5377\u79ef\u795e\u7ecf\u7f51\u7edc"
        }, 
        {
            "location": "/develop/tutorials/large-scale-linear-models-with-tensorflow/", 
            "text": "", 
            "title": "2.3.11 \u5927\u89c4\u6a21\u7ebf\u6027\u6a21\u578b\u4e0e TensorFlow"
        }, 
        {
            "location": "/develop/tutorials/tensorflow-linear-model-tutorial/", 
            "text": "", 
            "title": "2.3.12 TensorFlow \u7ebf\u6027\u6a21\u578b\u6307\u5bfc"
        }, 
        {
            "location": "/develop/tutorials/tensorflow-wide-deep-learning-tutorial/", 
            "text": "", 
            "title": "2.3.13 TensorFlow \u5e7f\u5ea6\u4e0e\u6df1\u5ea6\u5b66\u4e60\u6307\u5bfc"
        }, 
        {
            "location": "/develop/tutorials/using-gpus/", 
            "text": "", 
            "title": "2.3.14 \u4f7f\u7528 GPU"
        }, 
        {
            "location": "/develop/performance/", 
            "text": "Performance\n\n\nPerformance is often a significant issue when training a machine learning\nmodel.  This section explains various ways to optimize performance.  Start\nyour investigation with the @{$performance_guide$Performance Guide} and then go\ndeeper with techniques detailed in @{$performance_models$High-Performance Models}:\n\n\n\n\n\n\n@{$performance_guide$Performance Guide}, which contains a collection of best\n    practices for optimizing your TensorFlow code.\n\n\n\n\n\n\n@{$performance_models$High-Performance Models}, which contains a collection\n    of advanced techniques to build highly scalable models targeting different\n    system types and network topologies.\n\n\n\n\n\n\n@{$performance/benchmarks$Benchmarks}, which contains a collection of\n    benchmark results.\n\n\n\n\n\n\nXLA (Accelerated Linear Algebra) is an experimental compiler for linear\nalgebra that optimizes TensorFlow computations. The following guides explore\nXLA:\n\n\n\n\n@{$xla$XLA Overview}, which introduces XLA.\n\n\n@{$broadcasting$Broadcasting Semantics}, which describes XLA\ns\n    broadcasting semantics.\n\n\n@{$developing_new_backend$Developing a new back end for XLA}, which\n    explains how to re-target TensorFlow in order to optimize the performance\n    of the computational graph for particular hardware.\n\n\n@{$jit$Using JIT Compilation}, which describes the XLA JIT compiler that\n    compiles and runs parts of TensorFlow graphs via XLA in order to optimize\n    performance.\n\n\n@{$operation_semantics$Operation Semantics}, which is a reference manual\n    describing the semantics of operations in the \nComputationBuilder\n\n    interface.\n\n\n@{$shapes$Shapes and Layout}, which details the \nShape\n protocol buffer.\n\n\n@{$tfcompile$Using AOT compilation}, which explains \ntfcompile\n, a\n    standalone tool that compiles TensorFlow graphs into executable code in\n    order to optimize performance.\n\n\n\n\nAnd finally, we offer the following guide:\n\n\n\n\n@{$quantization$How to Quantize Neural Networks with TensorFlow}, which\n    can explains how to use quantization to reduce model size, both in storage\n    and at runtime. Quantization can improve performance, especially on\n    mobile hardware.", 
            "title": "2.4.1 \u6027\u80fd\u4f18\u5316"
        }, 
        {
            "location": "/develop/performance/#performance", 
            "text": "Performance is often a significant issue when training a machine learning\nmodel.  This section explains various ways to optimize performance.  Start\nyour investigation with the @{$performance_guide$Performance Guide} and then go\ndeeper with techniques detailed in @{$performance_models$High-Performance Models}:    @{$performance_guide$Performance Guide}, which contains a collection of best\n    practices for optimizing your TensorFlow code.    @{$performance_models$High-Performance Models}, which contains a collection\n    of advanced techniques to build highly scalable models targeting different\n    system types and network topologies.    @{$performance/benchmarks$Benchmarks}, which contains a collection of\n    benchmark results.    XLA (Accelerated Linear Algebra) is an experimental compiler for linear\nalgebra that optimizes TensorFlow computations. The following guides explore\nXLA:   @{$xla$XLA Overview}, which introduces XLA.  @{$broadcasting$Broadcasting Semantics}, which describes XLA s\n    broadcasting semantics.  @{$developing_new_backend$Developing a new back end for XLA}, which\n    explains how to re-target TensorFlow in order to optimize the performance\n    of the computational graph for particular hardware.  @{$jit$Using JIT Compilation}, which describes the XLA JIT compiler that\n    compiles and runs parts of TensorFlow graphs via XLA in order to optimize\n    performance.  @{$operation_semantics$Operation Semantics}, which is a reference manual\n    describing the semantics of operations in the  ComputationBuilder \n    interface.  @{$shapes$Shapes and Layout}, which details the  Shape  protocol buffer.  @{$tfcompile$Using AOT compilation}, which explains  tfcompile , a\n    standalone tool that compiles TensorFlow graphs into executable code in\n    order to optimize performance.   And finally, we offer the following guide:   @{$quantization$How to Quantize Neural Networks with TensorFlow}, which\n    can explains how to use quantization to reduce model size, both in storage\n    and at runtime. Quantization can improve performance, especially on\n    mobile hardware.", 
            "title": "Performance"
        }, 
        {
            "location": "/develop/performance/performance/", 
            "text": "", 
            "title": "2.4.2 \u6307\u5357"
        }, 
        {
            "location": "/develop/performance/xla-overview/", 
            "text": "", 
            "title": "2.4.3 XLA \u6982\u89c8"
        }, 
        {
            "location": "/develop/performance/broadcasting-semantics/", 
            "text": "", 
            "title": "2.4.4 \u5e7f\u64ad\u8bed\u4e49"
        }, 
        {
            "location": "/develop/performance/developing-a-new-backend-for-xla/", 
            "text": "", 
            "title": "2.4.5 \u5f00\u53d1\u65b0\u7684 XLA \u540e\u7aef"
        }, 
        {
            "location": "/develop/performance/using-jit-compilation/", 
            "text": "", 
            "title": "2.4.6 \u4f7f\u7528 JIT \u7f16\u8bd1"
        }, 
        {
            "location": "/develop/performance/operation-semantics/", 
            "text": "", 
            "title": "2.4.7 \u8fd0\u7b97\u8bed\u4e49"
        }, 
        {
            "location": "/develop/performance/shapes-and-layout/", 
            "text": "", 
            "title": "2.4.8 Shapes and Layout"
        }, 
        {
            "location": "/develop/performance/using-aot-compilation/", 
            "text": "", 
            "title": "2.4.9 \u4f7f\u7528 AOT \u7f16\u8bd1"
        }, 
        {
            "location": "/develop/performance/how-to-quantize-neural-networks-with-tensorflow/", 
            "text": "", 
            "title": "2.4.10 \u5982\u4f55\u91cf\u5316\u795e\u7ecf\u7f51\u7edc"
        }, 
        {
            "location": "/apidoc/overview/", 
            "text": "", 
            "title": "3.1 \u6982\u89c8 r1.0"
        }, 
        {
            "location": "/apidoc/python-api/", 
            "text": "", 
            "title": "3.2 Python API r1.0"
        }, 
        {
            "location": "/apidoc/cpp-api/", 
            "text": "", 
            "title": "3.3 C++ API r1.0"
        }, 
        {
            "location": "/apidoc/java-api/", 
            "text": "", 
            "title": "3.4 Java API r1.0"
        }, 
        {
            "location": "/apidoc/go-api/", 
            "text": "", 
            "title": "3.5 Go API"
        }, 
        {
            "location": "/deploy/", 
            "text": "Deploy\n\n\nThis section focuses on deploying real-world models.  It contains\nthe following documents:\n\n\n\n\n@{$distributed$Distributed TensorFlow}, which explains how to create\n    a cluster of TensorFlow servers.\n\n\n@{$hadoop$How to run TensorFlow on Hadoop}, which has a highly\n    self-explanatory title.\n\n\nThe entire document set for \nTensorFlow serving\n, an open-source,\n    flexible, high-performance serving system for machine-learned models\n    designed for production environments. TensorFlow Serving provides\n    out-of-the-box integration with TensorFlow models.\n    \nSource code for TensorFlow Serving\n\n    is available on Github.", 
            "title": "4.1 \u90e8\u7f72"
        }, 
        {
            "location": "/deploy/#deploy", 
            "text": "This section focuses on deploying real-world models.  It contains\nthe following documents:   @{$distributed$Distributed TensorFlow}, which explains how to create\n    a cluster of TensorFlow servers.  @{$hadoop$How to run TensorFlow on Hadoop}, which has a highly\n    self-explanatory title.  The entire document set for  TensorFlow serving , an open-source,\n    flexible, high-performance serving system for machine-learned models\n    designed for production environments. TensorFlow Serving provides\n    out-of-the-box integration with TensorFlow models.\n     Source code for TensorFlow Serving \n    is available on Github.", 
            "title": "Deploy"
        }, 
        {
            "location": "/deploy/how-to-run-tensorflow-on-hadoop/", 
            "text": "", 
            "title": "4.2 \u5728Hadoop\u4e0a\u8fd0\u884cTensorFlow"
        }, 
        {
            "location": "/deploy/distributed-tensorflow/", 
            "text": "", 
            "title": "4.3 \u5206\u5e03\u5f0f\u90e8\u7f72TensorFlow"
        }, 
        {
            "location": "/extend/", 
            "text": "Extend\n\n\nThis section explains how developers can add functionality to TensorFlow\ns\ncapabilities. Begin by reading the following architectural overview:\n\n\n\n\n@{$architecture$TensorFlow Architecture}\n\n\n\n\nThe following guides explain how to extend particular aspects of\nTensorFlow:\n\n\n\n\n@{$adding_an_op$Adding a New Op}, which explains how to create your own\n    operations.\n\n\n@{$add_filesys$Adding a Custom Filesystem Plugin}, which explains how to\n    add support for your own shared or distributed filesystem.\n\n\n@{$new_data_formats$Custom Data Readers}, which details how to add support\n    for your own file and record formats.\n\n\n@{$extend/estimators$Creating Estimators in tf.contrib.learn}, which explains how\n    to write your own custom Estimator.  For example, you could build your\n    own Estimator to implement some variation on standard linear regression.\n\n\n\n\nPython is currently the only language supported by TensorFlow\ns API stability\npromises.  However, TensorFlow also provides functionality in C++, Java, and Go,\nplus community support for \nHaskell\n and\n\nRust\n.  If you\nd like to create or\ndevelop TensorFlow features in a language other than these languages, read the\nfollowing guide:\n\n\n\n\n@{$language_bindings$TensorFlow in Other Languages}\n\n\n\n\nTo create tools compatible with TensorFlow\ns model format, read the following\nguide:\n\n\n\n\n@{$tool_developers$A Tool Developer\ns Guide to TensorFlow Model Files}", 
            "title": "5.1 \u6269\u5c55"
        }, 
        {
            "location": "/extend/#extend", 
            "text": "This section explains how developers can add functionality to TensorFlow s\ncapabilities. Begin by reading the following architectural overview:   @{$architecture$TensorFlow Architecture}   The following guides explain how to extend particular aspects of\nTensorFlow:   @{$adding_an_op$Adding a New Op}, which explains how to create your own\n    operations.  @{$add_filesys$Adding a Custom Filesystem Plugin}, which explains how to\n    add support for your own shared or distributed filesystem.  @{$new_data_formats$Custom Data Readers}, which details how to add support\n    for your own file and record formats.  @{$extend/estimators$Creating Estimators in tf.contrib.learn}, which explains how\n    to write your own custom Estimator.  For example, you could build your\n    own Estimator to implement some variation on standard linear regression.   Python is currently the only language supported by TensorFlow s API stability\npromises.  However, TensorFlow also provides functionality in C++, Java, and Go,\nplus community support for  Haskell  and Rust .  If you d like to create or\ndevelop TensorFlow features in a language other than these languages, read the\nfollowing guide:   @{$language_bindings$TensorFlow in Other Languages}   To create tools compatible with TensorFlow s model format, read the following\nguide:   @{$tool_developers$A Tool Developer s Guide to TensorFlow Model Files}", 
            "title": "Extend"
        }, 
        {
            "location": "/extend/architecture/", 
            "text": "", 
            "title": "5.2 TensorFlow\u67b6\u6784"
        }, 
        {
            "location": "/extend/adding-a-new-op/", 
            "text": "", 
            "title": "5.3 \u6dfb\u52a0\u65b0\u7684 Op"
        }, 
        {
            "location": "/extend/adding-a-custom-filesystem-plugin/", 
            "text": "", 
            "title": "5.4 \u6dfb\u52a0\u81ea\u5b9a\u4e49\u6587\u4ef6\u7cfb\u7edf\u63d2\u4ef6"
        }, 
        {
            "location": "/extend/tensorflow-in-other-languages/", 
            "text": "", 
            "title": "5.5 TensorFlow\u7ffb\u8bd1"
        }, 
        {
            "location": "/extend/custom-data-readers/", 
            "text": "", 
            "title": "5.6 \u81ea\u5b9a\u4e49\u6570\u636e\u8bfb\u53d6"
        }, 
        {
            "location": "/extend/creating-estimators-in-tf-contrib.learn/", 
            "text": "", 
            "title": "5.7 \u7528 tf.contrib.learn \u5efa\u7acb\u4f30\u91cf"
        }, 
        {
            "location": "/extend/a-tool-developers-guide-to-tensorflow-model-files/", 
            "text": "A Tool Developer\ns Guide to TensorFlow Model Files\n\n\nMost users shouldn\nt need to care about the internal details of how TensorFlow\nstores data on disk, but you might if you\nre a tool developer. For example, you\nmay want to analyze models, or convert back and forth between TensorFlow and\nother formats. This guide tries to explain some of the details of how you can\nwork with the main files that hold model data, to make it easier to develop\nthose kind of tools.\n\n\n\n\n\n\nA Tool Developer\ns Guide to TensorFlow Model Files\n\n\nProtocol Buffers\n\n\nGraphDef\n\n\nText or Binary?\n\n\nNodes\n\n\nname\n\n\nop\n\n\ninput\n\n\ndevice\n\n\nattr\n\n\n\n\n\n\nFreezing\n\n\nWeight Formats\n\n\n\n\n\n\n\n\n\n\nProtocol Buffers\n\n\nAll of TensorFlow\ns file formats are based on\n\nProtocol Buffers\n, so to\nstart it\ns worth getting familiar with how they work. The summary is that you\ndefine data structures in text files, and the protobuf tools generate classes in\nC, Python, and other languages that can load, save, and access the data in a\nfriendly way. We often refer to Protocol Buffers as protobufs, and I\nll use\nthat convention in this guide.\n\n\nGraphDef\n\n\nThe foundation of computation in TensorFlow is the \nGraph\n object. This holds a\nnetwork of nodes, each representing one operation, connected to each other as\ninputs and outputs. After you\nve created a \nGraph\n object, you can save it out\nby calling \nas_graph_def()\n, which returns a \nGraphDef\n object.\n\n\nThe GraphDef class is an object created by the ProtoBuf library from the\ndefinition in\n\ntensorflow/core/framework/graph.proto\n. The protobuf tools parse\nthis text file, and generate the code to load, store, and manipulate graph\ndefinitions. If you see a standalone TensorFlow file representing a model, it\ns\nlikely to contain a serialized version of one of these \nGraphDef\n objects\nsaved out by the protobuf code.\n\n\nThis generated code is used to save and load the GraphDef files from disk. The code that actually loads the model looks like this:\n\n\ngraph_def = graph_pb2.GraphDef()\n\n\n\n\nThis line creates an empty \nGraphDef\n object, the class that\ns been created\nfrom the textual definition in graph.proto. This is the object we\nre going to\npopulate with the data from our file.\n\n\nwith open(FLAGS.graph, \nrb\n) as f:\n\n\n\n\nHere we get a file handle for the path we\nve passed in to the script\n\n\n  if FLAGS.input_binary:\n    graph_def.ParseFromString(f.read())\n  else:\n    text_format.Merge(f.read(), graph_def)\n\n\n\n\nText or Binary?\n\n\nThere are actually two different formats that a ProtoBuf can be saved in.\nTextFormat is a human-readable form, which makes it nice for debugging and\nediting, but can get large when there\ns numerical data like weights stored in\nit. You can see a small example of that in\n\ngraph_run_run2.pbtxt\n.\n\n\nBinary format files are a lot smaller than their text equivalents, even though\nthey\nre not as readable for us. In this script, we ask the user to supply a\nflag indicating whether the input file is binary or text, so we know the right\nfunction to call. You can find an example of a large binary file inside the\n\ninception_v3 archive\n,\nas \ninception_v3_2016_08_28_frozen.pb\n.\n\n\nThe API itself can be a bit confusing - the binary call is actually\n\nParseFromString()\n, whereas you use a utility function from the \ntext_format\n\nmodule to load textual files.\n\n\nNodes\n\n\nOnce you\nve loaded a file into the \ngraph_def\n variable, you can now access the\ndata inside it. For most practical purposes, the important section is the list\nof nodes stored in the node member. Here\ns the code that loops through those:\n\n\nfor node in graph_def.node\n\n\n\n\nEach node is a \nNodeDef\n object, defined in\n\ntensorflow/core/framework/node_def.proto\n. These\nare the fundamental building blocks of TensorFlow graphs, with each one defining\na single operation along with its input connections. Here are the members of a\n\nNodeDef\n, and what they mean.\n\n\nname\n\n\nEvery node should have a unique identifier that\ns not used by any other nodes\nin the graph. If you don\nt specify one as you\nre building a graph using the\nPython API, one reflecting the name of operation, such as \nMatMul\n,\nconcatenated with a monotonically increasing number, such as \n5\n, will be\npicked for you. The name is used when defining the connections between nodes,\nand when setting inputs and outputs for the whole graph when it\ns run.\n\n\nop\n\n\nThis defines what operation to run, for example \n\"Add\"\n, \n\"MatMul\"\n, or\n\n\"Conv2D\"\n. When a graph is run, this op name is looked up in a registry to\nfind an implementation. The registry is populated by calls to the\n\nREGISTER_OP()\n macro, like those in\n\ntensorflow/core/ops/nn_ops.cc\n.\n\n\ninput\n\n\nA list of strings, each one of which is the name of another node, optionally\nfollowed by a colon and an output port number. For example, a node with two\ninputs might have a list like \n[\"some_node_name\", \"another_node_name\"]\n, which\nis equivalent to \n[\"some_node_name:0\", \"another_node_name:0\"]\n, and defines the\nnode\ns first input as the first output from the node with the name\n\n\"some_node_name\"\n, and a second input from the first output of\n\n\"another_node_name\"\n\n\ndevice\n\n\nIn most cases you can ignore this, since it defines where to run a node in a\ndistributed environment, or when you want to force the operation onto CPU or\nGPU.\n\n\nattr\n\n\nThis is a key/value store holding all the attributes of a node. These are the\npermanent properties of nodes, things that don\nt change at runtime such as the\nsize of filters for convolutions, or the values of constant ops. Because there\ncan be so many different types of attribute values, from strings, to ints, to\narrays of tensor values, there\ns a separate protobuf file defining the data\nstructure that holds them, in\n\ntensorflow/core/framework/attr_value.proto\n.\n\n\nEach attribute has a unique name string, and the expected attributes are listed\nwhen the operation is defined. If an attribute isn\nt present in a node, but it\nhas a default listed in the operation definition, that default is used when the\ngraph is created.\n\n\nYou can access all of these members by calling \nnode.name\n, \nnode.op\n, etc. in\nPython. The list of nodes stored in the \nGraphDef\n is a full definition of the\nmodel architecture.\n\n\nFreezing\n\n\nOne confusing part about this is that the weights usually aren\nt stored inside\nthe file format during training. Instead, they\nre held in separate checkpoint\nfiles, and there are \nVariable\n ops in the graph that load the latest values\nwhen they\nre initialized. It\ns often not very convenient to have separate files\nwhen you\nre deploying to production, so there\ns the\n\nfreeze_graph.py\n script that takes a graph definition and a set\nof checkpoints and freezes them together into a single file.\n\n\nWhat this does is load the \nGraphDef\n, pull in the values for all the variables\nfrom the latest checkpoint file, and then replace each \nVariable\n op with a\n\nConst\n that has the numerical data for the weights stored in its attributes\nIt then strips away all the extraneous nodes that aren\nt used for forward\ninference, and saves out the resulting \nGraphDef\n into an output file.\n\n\nWeight Formats\n\n\nIf you\nre dealing with TensorFlow models that represent neural networks, one of\nthe most common problems is extracting and interpreting the weight values. A\ncommon way to store them, for example in graphs created by the freeze_graph\nscript, is as \nConst\n ops containing the weights as \nTensors\n. These are\ndefined in\n\ntensorflow/core/framework/tensor.proto\n, and contain information\nabout the size and type of the data, as well as the values themselves. In\nPython, you get a \nTensorProto\n object from a \nNodeDef\n representing a \nConst\n\nop by calling something like \nsome_node_def.attr['value'].tensor\n.\n\n\nThis will give you an object representing the weights data. The data itself\nwill be stored in one of the lists with the suffix _val as indicated by the\ntype of the object, for example \nfloat_val\n for 32-bit float data types.\n\n\nThe ordering of convolution weight values is often tricky to deal with when\nconverting between different frameworks. In TensorFlow, the filter weights for\nthe \nConv2D\n operation are stored on the second input, and are expected to be\nin the order \n[filter_height, filter_width, input_depth, output_depth]\n, where\nfilter_count increasing by one means moving to an adjacent value in memory.\n\n\nHopefully this rundown gives you a better idea of what\ns going on inside\nTensorFlow model files, and will help you if you ever need to manipulate them.", 
            "title": "5.8 TensorFlow\u6a21\u578b\u6587\u4ef6\u7684\u5de5\u5177\u5f00\u53d1\u8005\u6307\u5357"
        }, 
        {
            "location": "/extend/a-tool-developers-guide-to-tensorflow-model-files/#a-tool-developers-guide-to-tensorflow-model-files", 
            "text": "Most users shouldn t need to care about the internal details of how TensorFlow\nstores data on disk, but you might if you re a tool developer. For example, you\nmay want to analyze models, or convert back and forth between TensorFlow and\nother formats. This guide tries to explain some of the details of how you can\nwork with the main files that hold model data, to make it easier to develop\nthose kind of tools.    A Tool Developer s Guide to TensorFlow Model Files  Protocol Buffers  GraphDef  Text or Binary?  Nodes  name  op  input  device  attr    Freezing  Weight Formats", 
            "title": "A Tool Developer's Guide to TensorFlow Model Files"
        }, 
        {
            "location": "/extend/a-tool-developers-guide-to-tensorflow-model-files/#protocol-buffers", 
            "text": "All of TensorFlow s file formats are based on Protocol Buffers , so to\nstart it s worth getting familiar with how they work. The summary is that you\ndefine data structures in text files, and the protobuf tools generate classes in\nC, Python, and other languages that can load, save, and access the data in a\nfriendly way. We often refer to Protocol Buffers as protobufs, and I ll use\nthat convention in this guide.", 
            "title": "Protocol Buffers"
        }, 
        {
            "location": "/extend/a-tool-developers-guide-to-tensorflow-model-files/#graphdef", 
            "text": "The foundation of computation in TensorFlow is the  Graph  object. This holds a\nnetwork of nodes, each representing one operation, connected to each other as\ninputs and outputs. After you ve created a  Graph  object, you can save it out\nby calling  as_graph_def() , which returns a  GraphDef  object.  The GraphDef class is an object created by the ProtoBuf library from the\ndefinition in tensorflow/core/framework/graph.proto . The protobuf tools parse\nthis text file, and generate the code to load, store, and manipulate graph\ndefinitions. If you see a standalone TensorFlow file representing a model, it s\nlikely to contain a serialized version of one of these  GraphDef  objects\nsaved out by the protobuf code.  This generated code is used to save and load the GraphDef files from disk. The code that actually loads the model looks like this:  graph_def = graph_pb2.GraphDef()  This line creates an empty  GraphDef  object, the class that s been created\nfrom the textual definition in graph.proto. This is the object we re going to\npopulate with the data from our file.  with open(FLAGS.graph,  rb ) as f:  Here we get a file handle for the path we ve passed in to the script    if FLAGS.input_binary:\n    graph_def.ParseFromString(f.read())\n  else:\n    text_format.Merge(f.read(), graph_def)", 
            "title": "GraphDef"
        }, 
        {
            "location": "/extend/a-tool-developers-guide-to-tensorflow-model-files/#text-or-binary", 
            "text": "There are actually two different formats that a ProtoBuf can be saved in.\nTextFormat is a human-readable form, which makes it nice for debugging and\nediting, but can get large when there s numerical data like weights stored in\nit. You can see a small example of that in graph_run_run2.pbtxt .  Binary format files are a lot smaller than their text equivalents, even though\nthey re not as readable for us. In this script, we ask the user to supply a\nflag indicating whether the input file is binary or text, so we know the right\nfunction to call. You can find an example of a large binary file inside the inception_v3 archive ,\nas  inception_v3_2016_08_28_frozen.pb .  The API itself can be a bit confusing - the binary call is actually ParseFromString() , whereas you use a utility function from the  text_format \nmodule to load textual files.", 
            "title": "Text or Binary?"
        }, 
        {
            "location": "/extend/a-tool-developers-guide-to-tensorflow-model-files/#nodes", 
            "text": "Once you ve loaded a file into the  graph_def  variable, you can now access the\ndata inside it. For most practical purposes, the important section is the list\nof nodes stored in the node member. Here s the code that loops through those:  for node in graph_def.node  Each node is a  NodeDef  object, defined in tensorflow/core/framework/node_def.proto . These\nare the fundamental building blocks of TensorFlow graphs, with each one defining\na single operation along with its input connections. Here are the members of a NodeDef , and what they mean.", 
            "title": "Nodes"
        }, 
        {
            "location": "/extend/a-tool-developers-guide-to-tensorflow-model-files/#name", 
            "text": "Every node should have a unique identifier that s not used by any other nodes\nin the graph. If you don t specify one as you re building a graph using the\nPython API, one reflecting the name of operation, such as  MatMul ,\nconcatenated with a monotonically increasing number, such as  5 , will be\npicked for you. The name is used when defining the connections between nodes,\nand when setting inputs and outputs for the whole graph when it s run.", 
            "title": "name"
        }, 
        {
            "location": "/extend/a-tool-developers-guide-to-tensorflow-model-files/#op", 
            "text": "This defines what operation to run, for example  \"Add\" ,  \"MatMul\" , or \"Conv2D\" . When a graph is run, this op name is looked up in a registry to\nfind an implementation. The registry is populated by calls to the REGISTER_OP()  macro, like those in tensorflow/core/ops/nn_ops.cc .", 
            "title": "op"
        }, 
        {
            "location": "/extend/a-tool-developers-guide-to-tensorflow-model-files/#input", 
            "text": "A list of strings, each one of which is the name of another node, optionally\nfollowed by a colon and an output port number. For example, a node with two\ninputs might have a list like  [\"some_node_name\", \"another_node_name\"] , which\nis equivalent to  [\"some_node_name:0\", \"another_node_name:0\"] , and defines the\nnode s first input as the first output from the node with the name \"some_node_name\" , and a second input from the first output of \"another_node_name\"", 
            "title": "input"
        }, 
        {
            "location": "/extend/a-tool-developers-guide-to-tensorflow-model-files/#device", 
            "text": "In most cases you can ignore this, since it defines where to run a node in a\ndistributed environment, or when you want to force the operation onto CPU or\nGPU.", 
            "title": "device"
        }, 
        {
            "location": "/extend/a-tool-developers-guide-to-tensorflow-model-files/#attr", 
            "text": "This is a key/value store holding all the attributes of a node. These are the\npermanent properties of nodes, things that don t change at runtime such as the\nsize of filters for convolutions, or the values of constant ops. Because there\ncan be so many different types of attribute values, from strings, to ints, to\narrays of tensor values, there s a separate protobuf file defining the data\nstructure that holds them, in tensorflow/core/framework/attr_value.proto .  Each attribute has a unique name string, and the expected attributes are listed\nwhen the operation is defined. If an attribute isn t present in a node, but it\nhas a default listed in the operation definition, that default is used when the\ngraph is created.  You can access all of these members by calling  node.name ,  node.op , etc. in\nPython. The list of nodes stored in the  GraphDef  is a full definition of the\nmodel architecture.", 
            "title": "attr"
        }, 
        {
            "location": "/extend/a-tool-developers-guide-to-tensorflow-model-files/#freezing", 
            "text": "One confusing part about this is that the weights usually aren t stored inside\nthe file format during training. Instead, they re held in separate checkpoint\nfiles, and there are  Variable  ops in the graph that load the latest values\nwhen they re initialized. It s often not very convenient to have separate files\nwhen you re deploying to production, so there s the freeze_graph.py  script that takes a graph definition and a set\nof checkpoints and freezes them together into a single file.  What this does is load the  GraphDef , pull in the values for all the variables\nfrom the latest checkpoint file, and then replace each  Variable  op with a Const  that has the numerical data for the weights stored in its attributes\nIt then strips away all the extraneous nodes that aren t used for forward\ninference, and saves out the resulting  GraphDef  into an output file.", 
            "title": "Freezing"
        }, 
        {
            "location": "/extend/a-tool-developers-guide-to-tensorflow-model-files/#weight-formats", 
            "text": "If you re dealing with TensorFlow models that represent neural networks, one of\nthe most common problems is extracting and interpreting the weight values. A\ncommon way to store them, for example in graphs created by the freeze_graph\nscript, is as  Const  ops containing the weights as  Tensors . These are\ndefined in tensorflow/core/framework/tensor.proto , and contain information\nabout the size and type of the data, as well as the values themselves. In\nPython, you get a  TensorProto  object from a  NodeDef  representing a  Const \nop by calling something like  some_node_def.attr['value'].tensor .  This will give you an object representing the weights data. The data itself\nwill be stored in one of the lists with the suffix _val as indicated by the\ntype of the object, for example  float_val  for 32-bit float data types.  The ordering of convolution weight values is often tricky to deal with when\nconverting between different frameworks. In TensorFlow, the filter weights for\nthe  Conv2D  operation are stored on the second input, and are expected to be\nin the order  [filter_height, filter_width, input_depth, output_depth] , where\nfilter_count increasing by one means moving to an adjacent value in memory.  Hopefully this rundown gives you a better idea of what s going on inside\nTensorFlow model files, and will help you if you ever need to manipulate them.", 
            "title": "Weight Formats"
        }, 
        {
            "location": "/resource/community/", 
            "text": "Community\n\n\nThis section contains the following documents:\n\n\n\n\n@{$welcome$Welcome to the TensorFlow Community}, which explains how\n    you can get involved, where to report issues, and where to join\n    like-minded TensorFlow enthusiasts online.\n\n\n@{$documentation$Writing TensorFlow Documentation}, which explains\n    TensorFlow\ns documentation conventions.  If you are modifying\n    TensorFlow source code or documentation, please read this guide.\n\n\n@{$style_guide$TensorFlow Style Guide}, which identifies coding style\n    conventions that TensorFlow developers and users should follow.\n\n\n@{$community/benchmarks$Benchmarks}, Benchmarks, a guide for defining and\n    running a TensorFlow benchmark.", 
            "title": "6.1.1 \u793e\u533a"
        }, 
        {
            "location": "/resource/community/#community", 
            "text": "This section contains the following documents:   @{$welcome$Welcome to the TensorFlow Community}, which explains how\n    you can get involved, where to report issues, and where to join\n    like-minded TensorFlow enthusiasts online.  @{$documentation$Writing TensorFlow Documentation}, which explains\n    TensorFlow s documentation conventions.  If you are modifying\n    TensorFlow source code or documentation, please read this guide.  @{$style_guide$TensorFlow Style Guide}, which identifies coding style\n    conventions that TensorFlow developers and users should follow.  @{$community/benchmarks$Benchmarks}, Benchmarks, a guide for defining and\n    running a TensorFlow benchmark.", 
            "title": "Community"
        }, 
        {
            "location": "/resource/community/welcome/", 
            "text": "Welcome to the TensorFlow Community\n\n\nTensorFlow is an open-source project.  This page explains how to contribute,\nwhere to ask questions, and how to help each other.\n\n\nDevelopment\n\n\nThe source code for TensorFlow is on\n\nGitHub\n.\n\n\nBefore contributing to TensorFlow source code, please review the\n\nContribution guidelines\n.\n\n\nProjects developed by the TensorFlow community\n\n\nThe TensorFlow community has created many great projects around TensorFlow, including:\n\n\n\n\nMachine Learning with TensorFlow (Book \n Code)\n\n\n@jtoy\ns awesome \nAwesome TensorFlow\n list of awesome things\n\n\nTensorFlow tutorials\n\n\nScikit Flow - Simplified Interface for TensorFlow\n\n\nCaffe to TensorFlow model converter\n\n\nBitfusion\ns GPU-enabled AWS EC2 TensorFlow AMI\n (\nLaunch AMI\n)\n\n\nRust language bindings\n\n\nOperator Vectorization Library\n\n\nSwift language bindings\n\n\nSublime Tensorflow - A plugin for Sublime Text\n\n\nEdward - A library for probabilistic modeling, inference, and criticism\n (\nGithub\n, \nForum\n)\n\n\nGPflow - Gaussian processes in TensorFlow\n\n\nCS 20SI: Tensorflow for Deep Learning Research\n - Please note, this course was designed with TensorFlow v0.12, so some of the notes may be out of date - but it\ns still a great resource.\n\n\n\n\nTensorFlow Communities Around the World\n\n\nAsia:\n\n\n\n\nTensorFlow Korea (TF-KR) User Group\n \n(Korean language)\n\n\nTensorFlow User Group Tokyo\n \n(Japanese Language)\n\n\nSoleil Data Dojo\n \n(Japanese language)\n\n\nTensorFlow User Group Utsunomiya\n\n\n\n\nEurope:\n\n\n\n\nTensorFlow Barcelona\n\n\nTensorFlow Madrid\n\n\n\n\nSupport\n\n\nTensorFlow provides multiple communication paths.  To pick the right path,\nplease read the following list carefully:\n\n\n\n\nTo ask or answer technical questions about TensorFlow, use\n    \nStack Overflow\n.\n    For example, ask or search Stack Overflow about a particular error message\n    you encountered during installation.\n\n\nTo join general discussions about TensorFlow development and directions,\n    please join the\n    \nTensorFlow discuss mailing list\n.\n    For example, use this mailing list to learn about new features in\n    upcoming releases of TensorFlow.\n\n\nTo report bugs or make feature requests, use the\n    \nTensorFlow issues tracker\n\n    on GitHub.  For example, use the issue tracker to request a\n    new operation in TensorFlow.", 
            "title": "6.1.2 \u6b22\u8fce\u6765\u5230TensorFlow\u793e\u533a"
        }, 
        {
            "location": "/resource/community/welcome/#welcome-to-the-tensorflow-community", 
            "text": "TensorFlow is an open-source project.  This page explains how to contribute,\nwhere to ask questions, and how to help each other.", 
            "title": "Welcome to the TensorFlow Community"
        }, 
        {
            "location": "/resource/community/welcome/#development", 
            "text": "The source code for TensorFlow is on GitHub .  Before contributing to TensorFlow source code, please review the Contribution guidelines .", 
            "title": "Development"
        }, 
        {
            "location": "/resource/community/welcome/#projects-developed-by-the-tensorflow-community", 
            "text": "The TensorFlow community has created many great projects around TensorFlow, including:   Machine Learning with TensorFlow (Book   Code)  @jtoy s awesome  Awesome TensorFlow  list of awesome things  TensorFlow tutorials  Scikit Flow - Simplified Interface for TensorFlow  Caffe to TensorFlow model converter  Bitfusion s GPU-enabled AWS EC2 TensorFlow AMI  ( Launch AMI )  Rust language bindings  Operator Vectorization Library  Swift language bindings  Sublime Tensorflow - A plugin for Sublime Text  Edward - A library for probabilistic modeling, inference, and criticism  ( Github ,  Forum )  GPflow - Gaussian processes in TensorFlow  CS 20SI: Tensorflow for Deep Learning Research  - Please note, this course was designed with TensorFlow v0.12, so some of the notes may be out of date - but it s still a great resource.", 
            "title": "Projects developed by the TensorFlow community"
        }, 
        {
            "location": "/resource/community/welcome/#tensorflow-communities-around-the-world", 
            "text": "Asia:   TensorFlow Korea (TF-KR) User Group   (Korean language)  TensorFlow User Group Tokyo   (Japanese Language)  Soleil Data Dojo   (Japanese language)  TensorFlow User Group Utsunomiya   Europe:   TensorFlow Barcelona  TensorFlow Madrid", 
            "title": "TensorFlow Communities Around the World"
        }, 
        {
            "location": "/resource/community/welcome/#support", 
            "text": "TensorFlow provides multiple communication paths.  To pick the right path,\nplease read the following list carefully:   To ask or answer technical questions about TensorFlow, use\n     Stack Overflow .\n    For example, ask or search Stack Overflow about a particular error message\n    you encountered during installation.  To join general discussions about TensorFlow development and directions,\n    please join the\n     TensorFlow discuss mailing list .\n    For example, use this mailing list to learn about new features in\n    upcoming releases of TensorFlow.  To report bugs or make feature requests, use the\n     TensorFlow issues tracker \n    on GitHub.  For example, use the issue tracker to request a\n    new operation in TensorFlow.", 
            "title": "Support"
        }, 
        {
            "location": "/resource/community/writing-tensorflow-docs/", 
            "text": "", 
            "title": "6.1.3 \u7f16\u5199TensorFlow\u6587\u6863"
        }, 
        {
            "location": "/resource/community/tensorflow-style-guide/", 
            "text": "", 
            "title": "6.1.4 TensorFlow\u98ce\u683c\u6307\u5357"
        }, 
        {
            "location": "/resource/community/benchmarks/", 
            "text": "Benchmarks\n\n\nThis guide contains instructions for defining and running a TensorFlow benchmark. These benchmarks store output in \nTestResults\n format. If these benchmarks are added to TensorFlow github repo, then we will run them daily with our continuous build and display a graph on our dashboard: https://benchmarks-dot-tensorflow-testing.appspot.com/.\n\n\n\n\n\n\nBenchmarks\n\n\nDefining a Benchmark\n\n\nAdding a bazel Target\n\n\n\n\n\n\n\n\n\n\nDefining a Benchmark\n\n\nDefining a TensorFlow benchmark requires extending from \ntf.test.Benchmark\n\nclass and calling \nself.report_benchmark\n method. For example, take a look at the sample benchmark code below:\n\n\nimport time\n\nimport tensorflow as tf\n\n\n# Define a class that extends from tf.test.Benchmark.\nclass SampleBenchmark(tf.test.Benchmark):\n\n  # Note: benchmark method name must start with `benchmark`.\n  def benchmarkSum(self):\n    with tf.Session() as sess:\n      x = tf.constant(10)\n      y = tf.constant(5)\n      result = tf.add(x, y)\n\n      iters = 100\n      start_time = time.time()\n      for _ in range(iters):\n        sess.run(result)\n      total_wall_time = time.time() - start_time\n\n      # Call report_benchmark to report a metric value.\n      self.report_benchmark(\n          name=\nsum_wall_time\n,\n          # This value should always be per iteration.\n          wall_time=total_wall_time/iters,\n          iters=iters)\n\nif __name__ == \n__main__\n:\n  tf.test.main()\n\n\n\n\nSee the full example for \nSampleBenchmark\n.\n\n\nKey points to note in the example above:\n\n\n\n\nBenchmark class extends from \ntf.test.Benchmark\n.\n\n\nEach benchmark method should start with \nbenchmark\n prefix.\n\n\nBenchmark method calls \nreport_benchmark\n to report the metric value.\n\n\n\n\nAdding a \nbazel\n Target\n\n\nWe have a special target called \ntf_py_logged_benchmark\n for benchmarks defined under TensorFlow github repo. \ntf_py_logged_benchmark\n should wrap around a regular \npy_test\n target. Running a \ntf_py_logged_benchmark\n would print a \nTestResults\n proto. Defining a \ntf_py_logged_benchmark\n also lets us run it with TensorFlow continuous build.\n\n\nFirst, define a regular \npy_test\n target. See example below:\n\n\npy_test(\n  name = \nsample_benchmark\n,\n  srcs = [\nsample_benchmark.py\n],\n  srcs_version = \nPY2AND3\n,\n  deps = [\n    \n//tensorflow:tensorflow_py\n,\n  ],\n)\n\n\n\n\nYou can run benchmarks in a \npy_test\n target by passing \n--benchmarks\n flag. The benchmark should just print out a \nBenchmarkEntries\n proto.\n\n\nbazel test :sample_benchmark --test_arg=--benchmarks=all\n\n\n\n\nNow, add the \ntf_py_logged_benchmark\n target (if available). This target would\npass in \n--benchmarks=all\n to the wrapped \npy_test\n target and provide a way to store output for our TensorFlow continuous build. \ntf_py_logged_benchmark\n target should be available in TensorFlow repository.\n\n\nload(\n//tensorflow/tools/test:performance.bzl\n, \ntf_py_logged_benchmark\n)\n\ntf_py_logged_benchmark(\n    name = \nsample_logged_benchmark\n,\n    target = \n//tensorflow/tools/test:sample_benchmark\n,\n)\n\n\n\n\nUse the following command to run the benchmark target:\n\n\nbazel test :sample_logged_benchmark", 
            "title": "6.1.5 \u57fa\u51c6\u6d4b\u8bd5"
        }, 
        {
            "location": "/resource/community/benchmarks/#benchmarks", 
            "text": "This guide contains instructions for defining and running a TensorFlow benchmark. These benchmarks store output in  TestResults  format. If these benchmarks are added to TensorFlow github repo, then we will run them daily with our continuous build and display a graph on our dashboard: https://benchmarks-dot-tensorflow-testing.appspot.com/.    Benchmarks  Defining a Benchmark  Adding a bazel Target", 
            "title": "Benchmarks"
        }, 
        {
            "location": "/resource/community/benchmarks/#defining-a-benchmark", 
            "text": "Defining a TensorFlow benchmark requires extending from  tf.test.Benchmark \nclass and calling  self.report_benchmark  method. For example, take a look at the sample benchmark code below:  import time\n\nimport tensorflow as tf\n\n\n# Define a class that extends from tf.test.Benchmark.\nclass SampleBenchmark(tf.test.Benchmark):\n\n  # Note: benchmark method name must start with `benchmark`.\n  def benchmarkSum(self):\n    with tf.Session() as sess:\n      x = tf.constant(10)\n      y = tf.constant(5)\n      result = tf.add(x, y)\n\n      iters = 100\n      start_time = time.time()\n      for _ in range(iters):\n        sess.run(result)\n      total_wall_time = time.time() - start_time\n\n      # Call report_benchmark to report a metric value.\n      self.report_benchmark(\n          name= sum_wall_time ,\n          # This value should always be per iteration.\n          wall_time=total_wall_time/iters,\n          iters=iters)\n\nif __name__ ==  __main__ :\n  tf.test.main()  See the full example for  SampleBenchmark .  Key points to note in the example above:   Benchmark class extends from  tf.test.Benchmark .  Each benchmark method should start with  benchmark  prefix.  Benchmark method calls  report_benchmark  to report the metric value.", 
            "title": "Defining a Benchmark"
        }, 
        {
            "location": "/resource/community/benchmarks/#adding-a-bazel-target", 
            "text": "We have a special target called  tf_py_logged_benchmark  for benchmarks defined under TensorFlow github repo.  tf_py_logged_benchmark  should wrap around a regular  py_test  target. Running a  tf_py_logged_benchmark  would print a  TestResults  proto. Defining a  tf_py_logged_benchmark  also lets us run it with TensorFlow continuous build.  First, define a regular  py_test  target. See example below:  py_test(\n  name =  sample_benchmark ,\n  srcs = [ sample_benchmark.py ],\n  srcs_version =  PY2AND3 ,\n  deps = [\n     //tensorflow:tensorflow_py ,\n  ],\n)  You can run benchmarks in a  py_test  target by passing  --benchmarks  flag. The benchmark should just print out a  BenchmarkEntries  proto.  bazel test :sample_benchmark --test_arg=--benchmarks=all  Now, add the  tf_py_logged_benchmark  target (if available). This target would\npass in  --benchmarks=all  to the wrapped  py_test  target and provide a way to store output for our TensorFlow continuous build.  tf_py_logged_benchmark  target should be available in TensorFlow repository.  load( //tensorflow/tools/test:performance.bzl ,  tf_py_logged_benchmark )\n\ntf_py_logged_benchmark(\n    name =  sample_logged_benchmark ,\n    target =  //tensorflow/tools/test:sample_benchmark ,\n)  Use the following command to run the benchmark target:  bazel test :sample_logged_benchmark", 
            "title": "Adding a bazel Target"
        }, 
        {
            "location": "/resource/about/", 
            "text": "About TensorFlow\n\n\nThis section provides a few documents about TensorFlow itself,\nincluding the following:\n\n\n\n\n@{$roadmap$Roadmap}, which summarizes upcoming additions to TensorFlow.\n\n\n@{$uses$TensorFlow in Use}, which provides a link to our model zoo and\n    lists some popular ways that TensorFlow is being used.\n\n\n@{$bib$TensorFlow White Papers}, which provides abstracts of white papers\n    about TensorFlow.\n\n\n@{$attribution$Attribution}, which specifies how to attribute and refer\n    to TensorFlow.", 
            "title": "6.2.1 \u5173\u4e8e"
        }, 
        {
            "location": "/resource/about/#about-tensorflow", 
            "text": "This section provides a few documents about TensorFlow itself,\nincluding the following:   @{$roadmap$Roadmap}, which summarizes upcoming additions to TensorFlow.  @{$uses$TensorFlow in Use}, which provides a link to our model zoo and\n    lists some popular ways that TensorFlow is being used.  @{$bib$TensorFlow White Papers}, which provides abstracts of white papers\n    about TensorFlow.  @{$attribution$Attribution}, which specifies how to attribute and refer\n    to TensorFlow.", 
            "title": "About TensorFlow"
        }, 
        {
            "location": "/resource/about/additional/", 
            "text": "", 
            "title": "6.2.1 \u66f4\u591aTF\u76f8\u5173\u8d44\u6e90"
        }, 
        {
            "location": "/resource/about/whitepaper/", 
            "text": "", 
            "title": "6.2.2 TensorFlow\u767d\u76ae\u4e66"
        }, 
        {
            "location": "/resource/about/tfuses/", 
            "text": "", 
            "title": "6.2.3 TensorFlow Uses"
        }, 
        {
            "location": "/version/", 
            "text": "", 
            "title": "7.1 TensorFlow\u7248\u672c\u5217\u8868"
        }, 
        {
            "location": "/version/master/", 
            "text": "", 
            "title": "7.2 master"
        }, 
        {
            "location": "/version/r1.0/", 
            "text": "", 
            "title": "7.3 r1.0"
        }, 
        {
            "location": "/version/r0.12/", 
            "text": "", 
            "title": "7.4 r0.12"
        }, 
        {
            "location": "/version/r0.11/", 
            "text": "", 
            "title": "7.5 r0.11"
        }, 
        {
            "location": "/version/r0.10/", 
            "text": "", 
            "title": "7.6 r0.10"
        }, 
        {
            "location": "/about/about-project/", 
            "text": "\u5173\u4e8e\u672c\u6587\u6863\u7ffb\u8bd1\u9879\u76ee\n\n\n\u9996\u5148\u7533\u660e\uff0c\u672c\u6587\u6863\u5e76\u975e\u5b98\u65b9\u6587\u6863\uff0c\u4e3a\u4e2a\u4eba\u5174\u8da3\u800c\u5efa\u7acb\u7684\u3002\u5982\u9700\u67e5\u8be2TensorFlow\u5b98\u65b9\u6587\u6863\uff0c\u8bf7\u81f3https://www.tensorflow.org/\uff0c\u6216\u8005\u5230TensorFlow\u4e2d\u6587\u793e\u533a\uff08http://www.tensorfly.cn/\uff09\u67e5\u8be2\u5b8c\u6574\u7684\u4e2d\u6587\u6587\u6863\u3002\n\n\n\u672c\u6587\u6863\u57fa\u4e8e\nTensorFlow\u5b98\u65b9\u6587\u6863\n \n1.0 \u7248\u672c\n\u8fdb\u884c\u7ffb\u8bd1\uff0c\u5c3d\u91cf\u4e0e\u5b98\u65b9\u7f51\u7ad9\u7684\u76ee\u5f55\u4fdd\u6301\u4e00\u81f4\u3002\n\n\n\u6587\u6863\u7ffb\u8bd1\u8fc7\u7a0b\u4e2d\u514b\u9686\u4e86\n\u5b98\u65b9\u6587\u6863\u5e93\n\uff08\u5c3d\u91cf\u4fdd\u6301\u8ddf\u968f\u6700\u65b0\u66f4\u65b0\uff09\uff0c\u540c\u65f6\u4e25\u91cd\u53c2\u8003\u4e86\nTensorFlow\u4e2d\u6587\u793e\u533a\n\u7684\u6587\u6863\uff08\u8be5\u793e\u533a\u7684\u6587\u6863\u4ecd\u4e3a0.5\u7248\uff0c\u8fd9\u4e5f\u662f\u4fc3\u4f7f\u672c\u6587\u6863\u9879\u76ee\u7684\u4e00\u4e2a\u539f\u56e0\uff09\u3002\n\n\n\u672c\u6587\u6863\u4f7f\u7528MkDocs\u6587\u6863\u7cfb\u7edf\nmkdocs.org\n\u6784\u5efa\uff0c\u754c\u9762\u4e3b\u9898\u4e3a\nRead the Docs\n\u3002\n\n\n\u672c\u6587\u6863\u9879\u76ee\u6e90\u4ee3\u7801\u90e8\u7f72\u5728\nGithub\n\u4e0a\uff0c\u5982\u6709\u5174\u8da3\u53c2\u4e0e\u8005\u8bf7\u5173\u6ce8\u6211\u7684Github Repo\uff1a\nhttps://github.com/isaron/tfdocs\n\u3002\n\n\n\u5b8c\u6574\u7684\u6587\u6863\u7ffb\u8bd1\u8ba1\u5212\u4f1a\u968f\u65f6\u66f4\u65b0\u5230\u6211\u7684\u535a\u5ba2\uff0c\u94fe\u63a5\u5728\u8fd9\u91cc\uff1a\nhttps://huangch.me/2017/02/23/TensorFlow-1-0-\u6587\u6863\u7ffb\u8bd1\u8ba1\u5212/\n\uff0c\u656c\u8bf7\u5173\u6ce8\u3002\n\n\n\u5185\u5bb9\u6765\u6e90\n\n\n\u82f1\u6587\u5b98\u65b9\u7f51\u7ad9\uff1a\n    https://www.tensorflow.org/\n\n\nTensorFlow\u4e2d\u6587\u793e\u533a:\n    http://www.tensorfly.cn\n\n\n\u6781\u5ba2\u5b66\u9662TensorFlow\u6587\u6863\u4e2d\u6587\u7248\u7ffb\u8bd1\u8ba1\u5212\uff1a\n    https://github.com/jikexueyuanwiki/tensorflow-zh", 
            "title": "8.1 \u5173\u4e8e\u672c\u6587\u6863"
        }, 
        {
            "location": "/about/about-project/#_1", 
            "text": "\u9996\u5148\u7533\u660e\uff0c\u672c\u6587\u6863\u5e76\u975e\u5b98\u65b9\u6587\u6863\uff0c\u4e3a\u4e2a\u4eba\u5174\u8da3\u800c\u5efa\u7acb\u7684\u3002\u5982\u9700\u67e5\u8be2TensorFlow\u5b98\u65b9\u6587\u6863\uff0c\u8bf7\u81f3https://www.tensorflow.org/\uff0c\u6216\u8005\u5230TensorFlow\u4e2d\u6587\u793e\u533a\uff08http://www.tensorfly.cn/\uff09\u67e5\u8be2\u5b8c\u6574\u7684\u4e2d\u6587\u6587\u6863\u3002  \u672c\u6587\u6863\u57fa\u4e8e TensorFlow\u5b98\u65b9\u6587\u6863   1.0 \u7248\u672c \u8fdb\u884c\u7ffb\u8bd1\uff0c\u5c3d\u91cf\u4e0e\u5b98\u65b9\u7f51\u7ad9\u7684\u76ee\u5f55\u4fdd\u6301\u4e00\u81f4\u3002  \u6587\u6863\u7ffb\u8bd1\u8fc7\u7a0b\u4e2d\u514b\u9686\u4e86 \u5b98\u65b9\u6587\u6863\u5e93 \uff08\u5c3d\u91cf\u4fdd\u6301\u8ddf\u968f\u6700\u65b0\u66f4\u65b0\uff09\uff0c\u540c\u65f6\u4e25\u91cd\u53c2\u8003\u4e86 TensorFlow\u4e2d\u6587\u793e\u533a \u7684\u6587\u6863\uff08\u8be5\u793e\u533a\u7684\u6587\u6863\u4ecd\u4e3a0.5\u7248\uff0c\u8fd9\u4e5f\u662f\u4fc3\u4f7f\u672c\u6587\u6863\u9879\u76ee\u7684\u4e00\u4e2a\u539f\u56e0\uff09\u3002  \u672c\u6587\u6863\u4f7f\u7528MkDocs\u6587\u6863\u7cfb\u7edf mkdocs.org \u6784\u5efa\uff0c\u754c\u9762\u4e3b\u9898\u4e3a Read the Docs \u3002  \u672c\u6587\u6863\u9879\u76ee\u6e90\u4ee3\u7801\u90e8\u7f72\u5728 Github \u4e0a\uff0c\u5982\u6709\u5174\u8da3\u53c2\u4e0e\u8005\u8bf7\u5173\u6ce8\u6211\u7684Github Repo\uff1a https://github.com/isaron/tfdocs \u3002  \u5b8c\u6574\u7684\u6587\u6863\u7ffb\u8bd1\u8ba1\u5212\u4f1a\u968f\u65f6\u66f4\u65b0\u5230\u6211\u7684\u535a\u5ba2\uff0c\u94fe\u63a5\u5728\u8fd9\u91cc\uff1a https://huangch.me/2017/02/23/TensorFlow-1-0-\u6587\u6863\u7ffb\u8bd1\u8ba1\u5212/ \uff0c\u656c\u8bf7\u5173\u6ce8\u3002", 
            "title": "\u5173\u4e8e\u672c\u6587\u6863\u7ffb\u8bd1\u9879\u76ee"
        }, 
        {
            "location": "/about/about-project/#_2", 
            "text": "\u82f1\u6587\u5b98\u65b9\u7f51\u7ad9\uff1a\n    https://www.tensorflow.org/  TensorFlow\u4e2d\u6587\u793e\u533a:\n    http://www.tensorfly.cn  \u6781\u5ba2\u5b66\u9662TensorFlow\u6587\u6863\u4e2d\u6587\u7248\u7ffb\u8bd1\u8ba1\u5212\uff1a\n    https://github.com/jikexueyuanwiki/tensorflow-zh", 
            "title": "\u5185\u5bb9\u6765\u6e90"
        }, 
        {
            "location": "/about/release-notes/", 
            "text": "\u66f4\u65b0\u8bb0\u5f55\n\n\n\n\n\n\n\n\nDate\n\n\nLogs\n\n\n\n\n\n\n\n\n\n\n2017.2.12\n\n\n\u5f00\u59cb TensorFlow 1.0 \u6587\u6863\u7ffb\u8bd1\u8ba1\u5212\n\n\n\n\n\n\n2017.3.7\n\n\n\u5b8c\u6210 TensorFlow 1.0 \u6587\u6863\u4e2d\u6587\u76ee\u5f55\u3001MkDocs \u5b9a\u5236\u3001\u6587\u6863\u90e8\u7f72\u521d\u59cb\u5316\n\n\n\n\n\n\n2017.8.20\n\n\n\u66f4\u65b0\u6587\u6863\u76ee\u5f55\u3001\u5b89\u88c5\u6587\u6863\u5230\u7248\u672c r1.3", 
            "title": "8.2 \u66f4\u65b0\u8bb0\u5f55"
        }, 
        {
            "location": "/about/release-notes/#_1", 
            "text": "Date  Logs      2017.2.12  \u5f00\u59cb TensorFlow 1.0 \u6587\u6863\u7ffb\u8bd1\u8ba1\u5212    2017.3.7  \u5b8c\u6210 TensorFlow 1.0 \u6587\u6863\u4e2d\u6587\u76ee\u5f55\u3001MkDocs \u5b9a\u5236\u3001\u6587\u6863\u90e8\u7f72\u521d\u59cb\u5316    2017.8.20  \u66f4\u65b0\u6587\u6863\u76ee\u5f55\u3001\u5b89\u88c5\u6587\u6863\u5230\u7248\u672c r1.3", 
            "title": "\u66f4\u65b0\u8bb0\u5f55"
        }, 
        {
            "location": "/about/contributing/", 
            "text": "", 
            "title": "8.3 Contributing"
        }, 
        {
            "location": "/about/license/", 
            "text": "", 
            "title": "8.4 License"
        }
    ]
}